{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JSRlxBoHIYoA"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import tensorflow.compat.v2 as tf\n",
        "tf.enable_v2_behavior()\n",
        "assert tf.executing_eagerly()\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "\n",
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "5jTZyFgtte1e"
      },
      "outputs": [],
      "source": [
        "# function to convert audio signal to numpy array\n",
        "def convert_audio_to_nd(audio_file):\n",
        "\n",
        "    y, sr = librosa.load(audio_file,sr = 16000)\n",
        "    print(\"Audio data type:\", type(y))\n",
        "    print(\"Audio data shape:\", y.shape)\n",
        "\n",
        "    \n",
        "    # audio_data = np.array(y)\n",
        "    audio_data = y / np.max(np.abs(y))\n",
        "\n",
        "    print(\"New audio data type:\", type(audio_data))\n",
        "    print(\"New audio data shape:\", audio_data.shape)\n",
        "\n",
        "\n",
        "    return audio_data,sr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "cdTcLW1FoYNN"
      },
      "outputs": [],
      "source": [
        "# function to convert audio signal numpy array to embeddings\n",
        "def get_audio_embeddings(audio_signal,sr):\n",
        "    # Load the module and run inference.\n",
        "    module = hub.load('https://tfhub.dev/google/nonsemantic-speech-benchmark/trill/2')\n",
        "    \n",
        "    # Reshape the input ndarray to have shape (num_samples,).\n",
        "    audio_signal = np.squeeze(audio_signal)\n",
        "    \n",
        "    # Resample the audio signal to 16kHz, if necessary.\n",
        "    # resampler = tf.signal.resample\n",
        "    # audio_signal = resampler(audio_signal, tf.constant([len(audio_signal) * 16000 // len(audio_signal)], dtype=tf.int32))\n",
        "    \n",
        "    #audio_signal = librosa.resample(audio_signal, sr, 16000)\n",
        "\n",
        "    # Normalize the audio signal to have values between -1 and 1.\n",
        "    audio_signal = np.asarray(audio_signal, dtype=np.float32)\n",
        "    assert audio_signal.ndim == 1\n",
        "    assert np.abs(audio_signal).max() <= 1.\n",
        "    audio_signal = np.clip(audio_signal, -1., 1.)\n",
        "    \n",
        "    # Generate the embeddings using the loaded module.\n",
        "    emb_dict = module(samples=audio_signal, sample_rate=16000)\n",
        "    emb = emb_dict['embedding']\n",
        "    emb_layer19 = emb_dict['layer19']\n",
        "    \n",
        "    # Return the embeddings as numpy ndarrays.\n",
        "    return emb.numpy(), emb_layer19.numpy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1vI30f421wdk"
      },
      "outputs": [],
      "source": [
        "# function to calculate FAD from test & reference embeddings\n",
        "def calc_fad(ref_emb,test_emb):\n",
        "\n",
        "    euclidean_sq = np.sum((ref_emb.mean(axis=0) - test_emb.mean(axis=0))**2)\n",
        "\n",
        "  \n",
        "    ref_var = np.var(ref_emb, axis=0)\n",
        "    test_var = np.var(test_emb, axis=0)\n",
        "    euclidean_var = np.sum(ref_var + test_var - 2*np.sqrt(ref_var*test_var))\n",
        "    euclidean_var /= ref_emb.shape[1]\n",
        "\n",
        "    # Compute the FrÃ©chet Audio Distance using the Euclidean distance.\n",
        "    fad = euclidean_sq + euclidean_var\n",
        "    fad = np.sqrt(fad)\n",
        "    return fad\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qibNLmeFCqod"
      },
      "outputs": [],
      "source": [
        "fad_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfHF9LzECqoe",
        "outputId": "63fc4250-4473-4697-d0e7-5943e72d2ce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (109227,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (109227,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (480000,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (480000,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (59579,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (59579,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (480000,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (480000,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (163840,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (163840,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (480000,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (480000,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (109227,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (109227,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (480000,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (480000,)\n"
          ]
        }
      ],
      "source": [
        "for i in range(1,5):\n",
        "  \n",
        "    test_audio,sr1 = convert_audio_to_nd(\"/content/generated/\"+str(i)+\".wav\") # modify this to take generated audio\n",
        "    ref_audio,sr2 = convert_audio_to_nd(\"/content/actual/\"+str(i)+\".flac\") \n",
        "    test_emb,test_emb_19 = get_audio_embeddings(test_audio,sr1)\n",
        "    ref_emb,ref_emb_19 = get_audio_embeddings(ref_audio,sr2)\n",
        "\n",
        "    fad = calc_fad(test_emb,ref_emb)\n",
        "    fad_list.append(fad)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fad_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrJU2j3qH214",
        "outputId": "dff4d11f-16ea-41ad-912c-ae7d263d173f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9711992994431712,\n",
              " 1.0611124096838642,\n",
              " 1.115067483416699,\n",
              " 1.0156717368465618,\n",
              " 0.9711992994431712,\n",
              " 1.0611124096838642,\n",
              " 1.115067483416699,\n",
              " 1.0156717368465618,\n",
              " 0.9711992994431712,\n",
              " 1.0611124096838642,\n",
              " 1.115067483416699,\n",
              " 1.0156717368465618,\n",
              " 0.9720172968293402,\n",
              " 1.0454869415705403,\n",
              " 1.1142205101030827,\n",
              " 1.0110736718570463]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# Get a list of all the audio files in the directories\n",
        "test_files = glob.glob(\"/content/generated/*.wav\")\n",
        "ref_files = glob.glob(\"/content/actual/*.flac\")\n",
        "\n",
        "# Loop over each pair of reference and test files and calculate FAD\n",
        "for i, (test_file, ref_file) in enumerate(zip(test_files, ref_files)):\n",
        "    test_audio, sr1 = convert_audio_to_nd(test_file)\n",
        "    ref_audio, sr2 = convert_audio_to_nd(ref_file) \n",
        "    test_emb, test_emb_19 = get_audio_embeddings(test_audio, sr1)\n",
        "    ref_emb, ref_emb_19 = get_audio_embeddings(ref_audio, sr2)\n",
        "    fad = calc_fad(test_emb, ref_emb)\n",
        "    print(\"FAD for pair {}: {}\".format(i, fad))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oI1-VnWmGiYZ",
        "outputId": "b20d585a-89fb-4cda-e632-bdf1c7d8e2f9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (163840,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (163840,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (480000,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (480000,)\n",
            "FAD for pair 0: 1.110425024550683\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (109227,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (109227,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (480000,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (480000,)\n",
            "FAD for pair 1: 1.0533965633823341\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (109227,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (109227,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (480000,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (480000,)\n",
            "FAD for pair 2: 1.0088698437544767\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (109227,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (109227,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (480000,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (480000,)\n",
            "FAD for pair 3: 0.9711992994431712\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (59579,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (59579,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (480000,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (480000,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-5f003768f67c>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mref_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_audio_to_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtest_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_emb_19\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_audio_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mref_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_emb_19\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_audio_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mfad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_fad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FAD for pair {}: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-f40feb2f2c93>\u001b[0m in \u001b[0;36mget_audio_embeddings\u001b[0;34m(audio_signal, sr)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0maudio_signal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_signal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0maudio_signal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_signal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0maudio_signal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_signal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all the audio files in the directories\n",
        "test_files = glob.glob(\"/content/generated/*.wav\")\n",
        "ref_files = glob.glob(\"/content/actual/*.flac\")\n",
        "\n",
        "# Get embeddings for all reference files\n",
        "ref_emb_list = []\n",
        "for ref_file in ref_files:\n",
        "    ref_audio, sr2 = convert_audio_to_nd(ref_file) \n",
        "    ref_emb, ref_emb_19 = get_audio_embeddings(ref_audio, sr2)\n",
        "    ref_emb_list.append(ref_emb)\n",
        "\n",
        "# Concatenate all reference embeddings into a single array\n",
        "ref_emb_all = np.concatenate(ref_emb_list, axis=0)\n",
        "\n",
        "# Get embeddings for all test files\n",
        "test_emb_list = []\n",
        "for test_file in test_files:\n",
        "    test_audio, sr1 = convert_audio_to_nd(test_file)\n",
        "    test_emb, test_emb_19 = get_audio_embeddings(test_audio, sr1)\n",
        "    test_emb_list.append(test_emb)\n",
        "\n",
        "# Concatenate all test embeddings into a single array\n",
        "test_emb_all = np.concatenate(test_emb_list, axis=0)\n",
        "\n",
        "# Calculate FAD between the two sets of embeddings\n",
        "fad = calc_fad(test_emb_all, ref_emb_all)\n",
        "\n",
        "print(\"FAD between generated and actual audio: {}\".format(fad))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82kBnRv8G_zd",
        "outputId": "c16c342b-5284-4f71-caed-29346090774b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (480000,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (480000,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (480000,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (480000,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (480000,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (480000,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (480000,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (480000,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (480000,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (480000,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (163840,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (163840,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (109227,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (109227,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (109227,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (109227,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (109227,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (109227,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (59579,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (59579,)\n",
            "FAD between generated and actual audio: 0.7701208455264686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fad_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmNoTUj3EWR6",
        "outputId": "21af255e-d3dc-4c19-a8e4-a78520573981"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9711992994431712,\n",
              " 1.0611124096838642,\n",
              " 1.115067483416699,\n",
              " 1.0156717368465618,\n",
              " 0.9711992994431712,\n",
              " 1.0611124096838642,\n",
              " 1.115067483416699,\n",
              " 1.0156717368465618,\n",
              " 0.9711992994431712,\n",
              " 1.0611124096838642,\n",
              " 1.115067483416699,\n",
              " 1.0156717368465618]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1M3MMxALj6s",
        "outputId": "b7e31929-2c70-4e32-abe1-b428ad1f244a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (160683,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (160683,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (95109,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (95109,)\n",
            "0.5838273918180972\n"
          ]
        }
      ],
      "source": [
        "# get reference & test audio, convert to embeddings and calculate FAD\n",
        "test_audio,sr1 = convert_audio_to_nd(\"/content/sample-0.mp3\") # modify this to take generated audio\n",
        "ref_audio,sr2 = convert_audio_to_nd(\"/content/real.mp3\") # modify this to take corrosponsing music caps audio\n",
        "\n",
        "test_emb,test_emb_19 = get_audio_embeddings(test_audio,sr1)\n",
        "ref_emb,ref_emb_19 = get_audio_embeddings(ref_audio,sr2)\n",
        "\n",
        "fad = calc_fad(test_emb,ref_emb)\n",
        "print(fad)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_audio,sr1 = convert_audio_to_nd(\"/content/generated/1.wav\") # modify this to take generated audio\n",
        "ref_audio,sr2 = convert_audio_to_nd(\"/content/generated/1.wav\") \n",
        "test_emb,test_emb_19 = get_audio_embeddings(test_audio,sr1)\n",
        "ref_emb,ref_emb_19 = get_audio_embeddings(ref_audio,sr2)\n",
        "\n",
        "fad = calc_fad(test_emb,ref_emb)\n",
        "print('fad',fad)\n",
        "# fad_list.append(fad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYU3QMzcEtUa",
        "outputId": "d3bfe2e9-1f3b-424b-ea02-55d3d77b49c7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (109227,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (109227,)\n",
            "Audio data type: <class 'numpy.ndarray'>\n",
            "Audio data shape: (109227,)\n",
            "New audio data type: <class 'numpy.ndarray'>\n",
            "New audio data shape: (109227,)\n",
            "fad 0.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "0bb1d34236350f2b4adbcfb855aa99771c031e6ffea95c93f2b7bdd9055bda2f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}