{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNPT3qp9FVEU0GZk2ShMyhb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"WI2VwXsjPfo2"},"outputs":[],"source":["!git clone https://github.com/LAION-AI/CLAP.git"]},{"cell_type":"code","source":["!pip install laion_clap --quiet"],"metadata":{"id":"ACVfwF4MPhfo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('./drive')"],"metadata":{"id":"3Pf0ivavPkWe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pydub"],"metadata":{"id":"YQlSoNuoPl8A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install webdataset"],"metadata":{"id":"tpOribduPpi_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# convert from .wav to .flac\n","from pydub import AudioSegment\n","import os\n","audio_files = os.listdir('/content/drive/MyDrive/Project/Processed Dataset')\n","for i in audio_files:\n","    if i[-4:] == '.wav':\n","        song = AudioSegment.from_wav(\"/content/drive/MyDrive/Project/Processed Dataset/\" + i)\n","        song.export(\"/content/drive/MyDrive/Project/Flac files/\" + i[:-4] + \".flac\",format = \"flac\")"],"metadata":{"id":"To4v5pvGPnpp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Making the tar file in Webdataset format\n","import librosa\n","import json\n","import webdataset as wds\n","import numpy as np\n","import os\n","import random\n","import io\n","from glob import glob\n","from itertools import islice\n","import scipy.signal as sps\n","import soundfile as sf\n","from tqdm import tqdm\n","import tarfile\n","\n","\n","def tardir(\n","    file_path, tar_name, n_entry_each, audio_ext=\".flac\", text_ext=\".json\", shuffle=True, start_idx=0, delete_file=False\n","):\n","    \"\"\"\n","    This function create the tars that includes the audio and text files in the same folder\n","    @param file_path      | string  | the path where audio and text files located\n","    @param tar_name       | string  | the tar name\n","    @param n_entry_each   | int     | how many pairs of (audio, text) will be in a tar\n","    @param audio_ext      | string  | the extension of the audio\n","    @param text_ext       | string  | the extension of the text\n","    @param shuffle        | boolean | True to shuffle the file sequence before packing up\n","    @param start_idx      | int     | the start index of the tar\n","    @param delete_file    | boolean | True to delete the audio and text files after packing up\n","    \"\"\"\n","    filelist = glob(file_path+'/*'+audio_ext)\n","\n","    if shuffle:\n","        random.shuffle(filelist)\n","    count = 0\n","    n_split = len(filelist) // n_entry_each\n","    if n_split * n_entry_each != len(filelist):\n","        n_split += 1\n","    size_dict = {\n","        os.path.basename(tar_name) + str(i) + \".tar\": n_entry_each\n","        for i in range(n_split)\n","    }\n","    if n_split * n_entry_each != len(filelist):\n","        size_dict[os.path.basename(tar_name) + str(n_split - 1) + \".tar\"] = (\n","            len(filelist) - (n_split - 1) * n_entry_each\n","        )\n","    for i in tqdm(range(start_idx, n_split + start_idx), desc='Creating .tar file:'):\n","        with tarfile.open(tar_name + str(i) + \".tar\", \"w\") as tar_handle:\n","            for j in range(count, len(filelist)):\n","                audio = filelist[j]\n","                basename = \".\".join(audio.split(\".\")[:-1])\n","                text_file_path = os.path.join(file_path, basename + text_ext)\n","                audio_file_path = os.path.join(file_path, audio)\n","                tar_handle.add(audio_file_path)\n","                tar_handle.add(text_file_path)\n","                if delete_file:\n","                    os.remove(audio_file_path)\n","                    os.remove(text_file_path)\n","                if (j + 1) % n_entry_each == 0:\n","                    count = j + 1\n","                    break\n","        tar_handle.close()\n","    # Serializing json\n","    json_object = json.dumps(size_dict, indent=4)\n","    # Writing to sample.json\n","    with open(os.path.join(os.path.dirname(tar_name), \"sizes.json\"), \"w\") as outfile:\n","        outfile.write(json_object)\n","    return size_dict\n","\n","def packup(input, output, filename, dataclass='all', num_element=512, start_idx=0, delete_file=False):\n","    if not os.path.exists(os.path.join(input, dataclass)):\n","        print(\n","            \"Dataclass {} does not exist, this folder does not exist. Skipping it.\".format(\n","                dataclass\n","            )\n","        )\n","        return\n","    if os.path.exists(os.path.join(output, dataclass)):\n","        tardir(\n","            os.path.join(input, dataclass),\n","            os.path.join(output, dataclass, filename),\n","            num_element,\n","            start_idx=start_idx,\n","            delete_file=delete_file,\n","        )\n","    else:\n","        os.makedirs(os.path.join(output, dataclass))\n","        tardir(\n","            os.path.join(input, dataclass),\n","            os.path.join(output, dataclass, filename),\n","            num_element,\n","            start_idx=start_idx,\n","            delete_file=delete_file,\n","        )\n","    return\n","\n","def load_from_tar(\n","    file_path,\n","    file_path_type=\"local\",\n","    audio_ext=\"flac\",\n","    text_ext=\"json\",\n","    samplerate=32000,\n","    mono=True,\n","    max_len=1000000,\n","    dtype=\"float64\",\n","    res_type=\"kaiser_best\",\n","):\n","    \"\"\"\n","    This function load the tar files to 3 entry tuple (audios, texts, names) accordingly\n","    @param file_path      | string  | the path where audio and text files located\n","    @param file_path_type | string  | this is meant to control the prefix of the address in case people forget to include it\n","                                      if file_path_type is \"local\" and 'file:\\\\' is not shown as a prefix, it will be added automatically\n","    @param audio_ext      | string  | the extension of the audio\n","    @param text_ext       | string  | the extension of the text\n","    @param samplerate     | int     | the sample rate of the audio\n","    @param mono           | boolean | if the audio is in mono channel\n","    @param max_len        | int     | max len of the audio, if exceed, will random crop; elif deficit, will pad\n","    @param dtype          | string  | the type of the dtype of the audio sample representation\n","    @param res_type       | string  | the resample method\n","    \"\"\"\n","    if file_path_type == \"local\" and (\"file:\\\\\" not in file_path):\n","        file_path = \"file:\\\\\" + file_path\n","    dataset = wds.WebDataset(file_path)\n","    audios = []\n","    texts = []\n","    names = []\n","    for sample in dataset:\n","        for key, value in sample.items():\n","            if key == audio_ext:\n","                audio_data, orig_sr = sf.read(io.BytesIO(value))\n","                if samplerate is not None:\n","                    audio_data = librosa.resample(\n","                        audio_data,\n","                        orig_sr=orig_sr,\n","                        target_sr=samplerate,\n","                        res_type=res_type,\n","                    )\n","                if len(audio_data) > max_len:\n","                    overflow = len(audio_data) - max_len\n","                    idx = np.random.randint(0, overflow + 1)\n","                    if np.random.rand() > 0.5:\n","                        audio_data = audio_data[idx : idx + max_len]\n","                    else:\n","                        audio_data = audio_data[\n","                            len(audio_data)\n","                            + 1\n","                            - idx\n","                            - max_len : len(audio_data)\n","                            + 1\n","                            - idx\n","                        ]\n","                else:\n","                    audio_data = np.pad(\n","                        audio_data,\n","                        (0, max_len - len(audio_data)),\n","                        mode=\"constant\",\n","                        constant_values=0,\n","                    )\n","                if mono:\n","                    audio_data = librosa.to_mono(audio_data)\n","                audios.append((audio_data, samplerate))\n","            elif key == text_ext:\n","                texts.append(value)\n","            elif key == \"__key__\":\n","                names.append(value)\n","    return audios, texts, names"],"metadata":{"id":"Ru2dpSruPr37"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# you'll need to create json files with the same name as audio files and store them in the same directory\n","# Path '/content/drive/MyDrive/Project/Flac files' contains audio files(.flac) and the json files\n","\n","tardir(file_path = \"/content/drive/MyDrive/Project/Flac files\", \n","       tar_name = \"/content/Dataset/MusicCaps/train/\", \n","       n_entry_each = 512, \n","       audio_ext=\".flac\", \n","       text_ext=\".json\", \n","       shuffle=True, \n","       start_idx=0, \n","       delete_file= False\n",")"],"metadata":{"id":"cCWTna2dPuPg"},"execution_count":null,"outputs":[]}]}