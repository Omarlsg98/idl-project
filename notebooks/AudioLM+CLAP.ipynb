{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txujENPmw_hW"
      },
      "source": [
        "#Configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAehkQc7s6R2",
        "outputId": "3f055974-4d36-4d18-9731-10b0dcd8820e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/gdrive/MyDrive/IDL_Project/data/releases\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HngJbRKrl2f6",
        "outputId": "79b2844c-0b8a-430e-8c1c-59396071cfc9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v1.0  v2_0.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ql8PXeeytRDh"
      },
      "outputs": [],
      "source": [
        "release_path = \"/content/gdrive/MyDrive/IDL_Project/data/releases/v2_0.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "PXKyOlMW8nyf"
      },
      "outputs": [],
      "source": [
        "!cp -r \"{release_path}\" ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"v2_0.zip\" -d /content"
      ],
      "metadata": {
        "id": "eRBOKjF1mpkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCIDUEgLtR_h",
        "outputId": "81b00d93-42cd-4da8-f80d-81ed3d43e287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00jcAFB7_pg_03d001.flac\n",
            "00jcAFB7_pg_03d002.flac\n",
            "00jcAFB7_pg_03d003.flac\n",
            "00jcAFB7_pg_03d004.flac\n",
            "00jcAFB7_pg_03d005.flac\n",
            "00jcAFB7_pg_03d006.flac\n",
            "00jcAFB7_pg_03d007.flac\n",
            "00jcAFB7_pg_03d008.flac\n",
            "00jcAFB7_pg_03d009.flac\n",
            "00jcAFB7_pg_03d010.flac\n"
          ]
        }
      ],
      "source": [
        "!ls -1 \"v2.0/\" | head"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!du -h v2.0/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nghLvbkAsQwd",
        "outputId": "93371902-28ad-40f1-c399-4b4d830c1406"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25G\tv2.0/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aqdm3SEqmVGQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccd2dd72-91ca-49be-f035-c4ceb1915c1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m708.0/708.0 kB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m118.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.7/272.7 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m129.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install audiolm-pytorch -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install laion-clap -q #RESTART after this(?)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36uDXDNesF7a",
        "outputId": "7c34c6e2-7e00-4dd5-aaec-ea9f3c722052"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.7/201.7 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n337KoD2om3L",
        "outputId": "6ccb53da-e2ae-432f-f58c-4231900d0a59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon May  1 04:24:19 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -q"
      ],
      "metadata": {
        "id": "AbNksjKecRjh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.exit(1) #RESTART after this!!!!!!!!!!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "JQFjzWqzb4I_",
        "outputId": "bb016fdf-a579-499d-88d3-66eed35ba3e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Yet more pre-processing (NO-EXECUTE)"
      ],
      "metadata": {
        "id": "D6zkgFFzkqEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!find v1.0/data/ -size +10M -delete"
      ],
      "metadata": {
        "id": "qaR_kXG-ko8M"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install sox"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdSyOEL0meOJ",
        "outputId": "04607577-89ff-45d6-ed49-e4bfdece9ebe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa libsox-fmt-base\n",
            "  libsox3\n",
            "Suggested packages:\n",
            "  libsox-fmt-all\n",
            "The following NEW packages will be installed:\n",
            "  libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa libsox-fmt-base\n",
            "  libsox3 sox\n",
            "0 upgraded, 6 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 513 kB of archives.\n",
            "After this operation, 1,564 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 libopencore-amrnb0 amd64 0.1.5-1 [94.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libopencore-amrwb0 amd64 0.1.5-1 [49.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libsox3 amd64 14.4.2+git20190427-2+deb11u2build0.20.04.1 [225 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2+git20190427-2+deb11u2build0.20.04.1 [10.5 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libsox-fmt-base amd64 14.4.2+git20190427-2+deb11u2build0.20.04.1 [31.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 sox amd64 14.4.2+git20190427-2+deb11u2build0.20.04.1 [102 kB]\n",
            "Fetched 513 kB in 2s (335 kB/s)\n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "(Reading database ... 122518 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libopencore-amrnb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../1-libopencore-amrwb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../2-libsox3_14.4.2+git20190427-2+deb11u2build0.20.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2+git20190427-2+deb11u2build0.20.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../3-libsox-fmt-alsa_14.4.2+git20190427-2+deb11u2build0.20.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2build0.20.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../4-libsox-fmt-base_14.4.2+git20190427-2+deb11u2build0.20.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2build0.20.04.1) ...\n",
            "Selecting previously unselected package sox.\n",
            "Preparing to unpack .../5-sox_14.4.2+git20190427-2+deb11u2build0.20.04.1_amd64.deb ...\n",
            "Unpacking sox (14.4.2+git20190427-2+deb11u2build0.20.04.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2+git20190427-2+deb11u2build0.20.04.1) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2build0.20.04.1) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2build0.20.04.1) ...\n",
            "Setting up sox (14.4.2+git20190427-2+deb11u2build0.20.04.1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for mime-support (3.64ubuntu1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install bc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUcvQX45syZR",
        "outputId": "3dd0882d-6423-4074-f976-a9209e888d9e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  bc\n",
            "0 upgraded, 1 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 86.3 kB of archives.\n",
            "After this operation, 231 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 bc amd64 1.07.1-2build1 [86.3 kB]\n",
            "Fetched 86.3 kB in 1s (80.6 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package bc.\n",
            "(Reading database ... 122586 files and directories currently installed.)\n",
            "Preparing to unpack .../bc_1.07.1-2build1_amd64.deb ...\n",
            "Unpacking bc (1.07.1-2build1) ...\n",
            "Setting up bc (1.07.1-2build1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p test/test"
      ],
      "metadata": {
        "id": "fddT73ZEuE5N"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/v1.0/data/test/1eu9y3ZPahI.wav test/test"
      ],
      "metadata": {
        "id": "acwHVMb-uDJC"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# Set the input WAV file path\n",
        "export INPUT_WAV_FOLDER=\"/content/v1.0/data\"\n",
        "\n",
        "# Set the output directory for FLAC files\n",
        "export OUTPUT_FLAC_DIR=\"/content/v2.0\"\n",
        "mkdir -p \"$OUTPUT_FLAC_DIR\"\n",
        "\n",
        "# Set the maximum length of each split file in seconds\n",
        "MAX_LENGTH=30\n",
        "\n",
        "# Loop through all WAV files in the input folder\n",
        "for file in \"$INPUT_WAV_FOLDER\"/*/*.wav; do\n",
        "  # Get the file name without extension\n",
        "  filename=$(basename -- \"$file\")\n",
        "  filename=\"${filename%.*}\"\n",
        "\n",
        "  # Convert the WAV file to FLAC format\n",
        "  ffmpeg -i \"$file\" -compression_level 12 \"$OUTPUT_FLAC_DIR/output.flac\" > /dev/null\n",
        "  rm \"$file\"\n",
        "  # Split the FLAC file into multiple files of up to 30 seconds each\n",
        "  sox \"$OUTPUT_FLAC_DIR/output.flac\" \"$OUTPUT_FLAC_DIR/${filename}_%03d.flac\" trim 0 $MAX_LENGTH : newfile : restart\n",
        "  rm \"$OUTPUT_FLAC_DIR/output.flac\"\n",
        "  echo \"Conversion and splitting of $file complete.\"\n",
        "done\n",
        "\n",
        "echo \"Processing complete for all files in $INPUT_WAV_FOLDER.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqGF-ATBl5a_",
        "outputId": "c10fc5cd-a63d-40a7-db71-c8837a32f01a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process is terminated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash \n",
        "OUTPUT_FLAC_DIR=\"/content/v2.0\"\n",
        "MAX_LENGTH=30\n",
        "# Loop through each split file and check its duration\n",
        "for f in \"$OUTPUT_FLAC_DIR/\"*; do\n",
        "  # Get the duration of the current file in seconds\n",
        "  duration=$(soxi -D \"$f\")\n",
        "\n",
        "  # If the duration is less or more than the maximum length, delete the file\n",
        "  if (( $(bc <<< \"$duration < $MAX_LENGTH\") )) || (( $(bc <<< \"$duration > $MAX_LENGTH\") )); then\n",
        "    rm \"$f\"\n",
        "  fi\n",
        "done"
      ],
      "metadata": {
        "id": "wO6JruQIrNBK"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFbUOV1PmEhI"
      },
      "outputs": [],
      "source": [
        "!zip v2_1.zip \"v2.0/*\" -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FR0nJQp7FQ6"
      },
      "outputs": [],
      "source": [
        "!mkdir -p \"/content/gdrive/MyDrive/IDL_Project/data/releases/v2.1\"\n",
        "!cp -R \"/content/v2_1.zip\" \"/content/gdrive/MyDrive/IDL_Project/data/releases\" \n",
        "!cp -R \"/content/v2.0/\" \"/content/gdrive/MyDrive/IDL_Project/data/releases/v2.1\" "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configs"
      ],
      "metadata": {
        "id": "CjjRTPyZcnZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_semantic = dict(\n",
        "        model=\"semantic\",\n",
        "        batch_size=8,\n",
        "        data_max_length_seconds = 30, #30\n",
        "        lr=5e-4, #1e-3\n",
        "        wd=0.,\n",
        "        attn_dropout=0.,\n",
        "        ff_dropout=0.,\n",
        "        grad_accum_every=1,\n",
        "        max_grad_norm=0.5,\n",
        "        scheduler=\"reducelr\",\n",
        "    )\n",
        "\n",
        "config_coarse = dict(\n",
        "        model=\"coarse\",\n",
        "        embedding_dim = 1024, #1024\n",
        "        depth = 12, #6\n",
        "        heads = 16, #8\n",
        "        batch_size=1,\n",
        "        data_max_length_seconds = 7,\n",
        "        lr=1e-2,\n",
        "        wd=0.,\n",
        "        attn_dropout=0.0,\n",
        "        ff_dropout=0.0,\n",
        "        grad_accum_every=1,\n",
        "        max_grad_norm=2.0, #0.5\n",
        "        scheduler=\"reducelr\"\n",
        "    )\n",
        "\n",
        "config_fine = dict(\n",
        "        model=\"fine\",\n",
        "        batch_size=4,\n",
        "        data_max_length_seconds = 3,\n",
        "        lr=1e-3, #1e-3\n",
        "        wd=0.,\n",
        "        attn_dropout=0.0,\n",
        "        ff_dropout=0.0,\n",
        "        grad_accum_every=1,\n",
        "        max_grad_norm=0.5,\n",
        "        scheduler=\"reducelr\",\n",
        "    )\n",
        "\n",
        "config = config_coarse #SELECT ME!!!\n",
        "VAL_EVERY_STEPS = 20\n",
        "STEPS = 20000 # 300 fro testing"
      ],
      "metadata": {
        "id": "jh-j5yPMcnsw"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_ckpt = False\n",
        "train = True\n",
        "DATA_PATH=\"/content/v2.0\"\n",
        "RESULTS_ROOT_PATH=\"/content/gdrive/MyDrive/IDL_Project/models\"\n",
        "semantic_load_path = RESULTS_ROOT_PATH+'/results_semantic/semantic.transformer.50.pt' \n",
        "coarse_load_path = RESULTS_ROOT_PATH+'/results_coarse/coarse.transformer.300.pt'\n",
        "fine_load_path = RESULTS_ROOT_PATH+'/results_fine/fine.transformer.300.pt'"
      ],
      "metadata": {
        "id": "MhmVMu-Idzoc"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wandb"
      ],
      "metadata": {
        "id": "QBaqCz5jb_l_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "now = datetime.datetime.now()\n",
        "minutes_today = (now.hour * 60) + now.minute\n",
        "days = now.day  \n",
        "hours = minutes_today // 60\n",
        "minutes = minutes_today % 60\n",
        "\n",
        "# Format the output string as \"day-hour-minute\"\n",
        "suffix = \"{:02d}{:02d}{:02d}\".format(days, hours, minutes)\n",
        "suffix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jQpcleFTK0NJ",
        "outputId": "57118d94-363d-4000-f041-8a1da053a7ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'010849'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb as wandb_org\n",
        "using_wandb= True\n",
        "if using_wandb:\n",
        "  wandb = wandb_org\n",
        "  wandb.login(key=\"d599fc284dc6e3f8363808c9da20e06180ec7462\")\n",
        "  # run = wandb.init(\n",
        "  #             name=f\"{config['model']}_{suffix}\",\n",
        "  #             resume=False,\n",
        "  #             project=\"project\",\n",
        "  #             entity=\"cmu-idl\",\n",
        "  #             config=config,\n",
        "  #         )\n",
        "  # RUN_ID=run.id\n",
        "  # print(RUN_ID)\n",
        "else:\n",
        "  wandb = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u1VuDAUcABX",
        "outputId": "77307af0-00ac-4a2f-d67c-cf81e5d97bc7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mols\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SglfcvOvmS_Z"
      },
      "source": [
        "#CLAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEFSss2wqCtL"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yU8Jawod3kN3"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BNVJt9bj08XT"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "import joblib\n",
        "\n",
        "REPO_ID = \"lukewys/laion_clap\"\n",
        "FILENAME = \"music_audioset_epoch_15_esc_90.14.pt\"\n",
        "\n",
        "clap_ckp_path=hf_hub_download(repo_id=REPO_ID, filename=FILENAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cv0KTESo4Fn",
        "outputId": "1869a741-305f-4673-f246-47341b9d90b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load the specified checkpoint /root/.cache/huggingface/hub/models--lukewys--laion_clap/snapshots/b3708341862f581175dba5c356a4ebf74a9b6651/music_audioset_epoch_15_esc_90.14.pt from users.\n",
            "Load Checkpoint...\n",
            "logit_scale_a \t Loaded\n",
            "logit_scale_t \t Loaded\n",
            "audio_branch.spectrogram_extractor.stft.conv_real.weight \t Loaded\n",
            "audio_branch.spectrogram_extractor.stft.conv_imag.weight \t Loaded\n",
            "audio_branch.logmel_extractor.melW \t Loaded\n",
            "audio_branch.bn0.weight \t Loaded\n",
            "audio_branch.bn0.bias \t Loaded\n",
            "audio_branch.patch_embed.proj.weight \t Loaded\n",
            "audio_branch.patch_embed.proj.bias \t Loaded\n",
            "audio_branch.patch_embed.norm.weight \t Loaded\n",
            "audio_branch.patch_embed.norm.bias \t Loaded\n",
            "audio_branch.layers.0.blocks.0.norm1.weight \t Loaded\n",
            "audio_branch.layers.0.blocks.0.norm1.bias \t Loaded\n",
            "audio_branch.layers.0.blocks.0.attn.relative_position_bias_table \t Loaded\n",
            "audio_branch.layers.0.blocks.0.attn.qkv.weight \t Loaded\n",
            "audio_branch.layers.0.blocks.0.attn.qkv.bias \t Loaded\n",
            "audio_branch.layers.0.blocks.0.attn.proj.weight \t Loaded\n",
            "audio_branch.layers.0.blocks.0.attn.proj.bias \t Loaded\n",
            "audio_branch.layers.0.blocks.0.norm2.weight \t Loaded\n",
            "audio_branch.layers.0.blocks.0.norm2.bias \t Loaded\n",
            "audio_branch.layers.0.blocks.0.mlp.fc1.weight \t Loaded\n",
            "audio_branch.layers.0.blocks.0.mlp.fc1.bias \t Loaded\n",
            "audio_branch.layers.0.blocks.0.mlp.fc2.weight \t Loaded\n",
            "audio_branch.layers.0.blocks.0.mlp.fc2.bias \t Loaded\n",
            "audio_branch.layers.0.blocks.1.norm1.weight \t Loaded\n",
            "audio_branch.layers.0.blocks.1.norm1.bias \t Loaded\n",
            "audio_branch.layers.0.blocks.1.attn.relative_position_bias_table \t Loaded\n",
            "audio_branch.layers.0.blocks.1.attn.qkv.weight \t Loaded\n",
            "audio_branch.layers.0.blocks.1.attn.qkv.bias \t Loaded\n",
            "audio_branch.layers.0.blocks.1.attn.proj.weight \t Loaded\n",
            "audio_branch.layers.0.blocks.1.attn.proj.bias \t Loaded\n",
            "audio_branch.layers.0.blocks.1.norm2.weight \t Loaded\n",
            "audio_branch.layers.0.blocks.1.norm2.bias \t Loaded\n",
            "audio_branch.layers.0.blocks.1.mlp.fc1.weight \t Loaded\n",
            "audio_branch.layers.0.blocks.1.mlp.fc1.bias \t Loaded\n",
            "audio_branch.layers.0.blocks.1.mlp.fc2.weight \t Loaded\n",
            "audio_branch.layers.0.blocks.1.mlp.fc2.bias \t Loaded\n",
            "audio_branch.layers.0.downsample.reduction.weight \t Loaded\n",
            "audio_branch.layers.0.downsample.norm.weight \t Loaded\n",
            "audio_branch.layers.0.downsample.norm.bias \t Loaded\n",
            "audio_branch.layers.1.blocks.0.norm1.weight \t Loaded\n",
            "audio_branch.layers.1.blocks.0.norm1.bias \t Loaded\n",
            "audio_branch.layers.1.blocks.0.attn.relative_position_bias_table \t Loaded\n",
            "audio_branch.layers.1.blocks.0.attn.qkv.weight \t Loaded\n",
            "audio_branch.layers.1.blocks.0.attn.qkv.bias \t Loaded\n",
            "audio_branch.layers.1.blocks.0.attn.proj.weight \t Loaded\n",
            "audio_branch.layers.1.blocks.0.attn.proj.bias \t Loaded\n",
            "audio_branch.layers.1.blocks.0.norm2.weight \t Loaded\n",
            "audio_branch.layers.1.blocks.0.norm2.bias \t Loaded\n",
            "audio_branch.layers.1.blocks.0.mlp.fc1.weight \t Loaded\n",
            "audio_branch.layers.1.blocks.0.mlp.fc1.bias \t Loaded\n",
            "audio_branch.layers.1.blocks.0.mlp.fc2.weight \t Loaded\n",
            "audio_branch.layers.1.blocks.0.mlp.fc2.bias \t Loaded\n",
            "audio_branch.layers.1.blocks.1.norm1.weight \t Loaded\n",
            "audio_branch.layers.1.blocks.1.norm1.bias \t Loaded\n",
            "audio_branch.layers.1.blocks.1.attn.relative_position_bias_table \t Loaded\n",
            "audio_branch.layers.1.blocks.1.attn.qkv.weight \t Loaded\n",
            "audio_branch.layers.1.blocks.1.attn.qkv.bias \t Loaded\n",
            "audio_branch.layers.1.blocks.1.attn.proj.weight \t Loaded\n",
            "audio_branch.layers.1.blocks.1.attn.proj.bias \t Loaded\n",
            "audio_branch.layers.1.blocks.1.norm2.weight \t Loaded\n",
            "audio_branch.layers.1.blocks.1.norm2.bias \t Loaded\n",
            "audio_branch.layers.1.blocks.1.mlp.fc1.weight \t Loaded\n",
            "audio_branch.layers.1.blocks.1.mlp.fc1.bias \t Loaded\n",
            "audio_branch.layers.1.blocks.1.mlp.fc2.weight \t Loaded\n",
            "audio_branch.layers.1.blocks.1.mlp.fc2.bias \t Loaded\n",
            "audio_branch.layers.1.downsample.reduction.weight \t Loaded\n",
            "audio_branch.layers.1.downsample.norm.weight \t Loaded\n",
            "audio_branch.layers.1.downsample.norm.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.0.norm1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.0.norm1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.0.attn.relative_position_bias_table \t Loaded\n",
            "audio_branch.layers.2.blocks.0.attn.qkv.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.0.attn.qkv.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.0.attn.proj.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.0.attn.proj.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.0.norm2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.0.norm2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.0.mlp.fc1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.0.mlp.fc1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.0.mlp.fc2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.0.mlp.fc2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.1.norm1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.1.norm1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.1.attn.relative_position_bias_table \t Loaded\n",
            "audio_branch.layers.2.blocks.1.attn.qkv.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.1.attn.qkv.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.1.attn.proj.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.1.attn.proj.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.1.norm2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.1.norm2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.1.mlp.fc1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.1.mlp.fc1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.1.mlp.fc2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.1.mlp.fc2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.2.norm1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.2.norm1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.2.attn.relative_position_bias_table \t Loaded\n",
            "audio_branch.layers.2.blocks.2.attn.qkv.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.2.attn.qkv.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.2.attn.proj.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.2.attn.proj.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.2.norm2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.2.norm2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.2.mlp.fc1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.2.mlp.fc1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.2.mlp.fc2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.2.mlp.fc2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.3.norm1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.3.norm1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.3.attn.relative_position_bias_table \t Loaded\n",
            "audio_branch.layers.2.blocks.3.attn.qkv.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.3.attn.qkv.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.3.attn.proj.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.3.attn.proj.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.3.norm2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.3.norm2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.3.mlp.fc1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.3.mlp.fc1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.3.mlp.fc2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.3.mlp.fc2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.4.norm1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.4.norm1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.4.attn.relative_position_bias_table \t Loaded\n",
            "audio_branch.layers.2.blocks.4.attn.qkv.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.4.attn.qkv.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.4.attn.proj.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.4.attn.proj.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.4.norm2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.4.norm2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.4.mlp.fc1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.4.mlp.fc1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.4.mlp.fc2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.4.mlp.fc2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.5.norm1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.5.norm1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.5.attn.relative_position_bias_table \t Loaded\n",
            "audio_branch.layers.2.blocks.5.attn.qkv.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.5.attn.qkv.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.5.attn.proj.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.5.attn.proj.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.5.norm2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.5.norm2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.5.mlp.fc1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.5.mlp.fc1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.5.mlp.fc2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.5.mlp.fc2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.6.norm1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.6.norm1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.6.attn.relative_position_bias_table \t Loaded\n",
            "audio_branch.layers.2.blocks.6.attn.qkv.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.6.attn.qkv.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.6.attn.proj.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.6.attn.proj.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.6.norm2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.6.norm2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.6.mlp.fc1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.6.mlp.fc1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.6.mlp.fc2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.6.mlp.fc2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.7.norm1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.7.norm1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.7.attn.relative_position_bias_table \t Loaded\n",
            "audio_branch.layers.2.blocks.7.attn.qkv.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.7.attn.qkv.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.7.attn.proj.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.7.attn.proj.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.7.norm2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.7.norm2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.7.mlp.fc1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.7.mlp.fc1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.7.mlp.fc2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.7.mlp.fc2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.8.norm1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.8.norm1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.8.attn.relative_position_bias_table \t Loaded\n",
            "audio_branch.layers.2.blocks.8.attn.qkv.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.8.attn.qkv.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.8.attn.proj.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.8.attn.proj.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.8.norm2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.8.norm2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.8.mlp.fc1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.8.mlp.fc1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.8.mlp.fc2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.8.mlp.fc2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.9.norm1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.9.norm1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.9.attn.relative_position_bias_table \t Loaded\n",
            "audio_branch.layers.2.blocks.9.attn.qkv.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.9.attn.qkv.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.9.attn.proj.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.9.attn.proj.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.9.norm2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.9.norm2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.9.mlp.fc1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.9.mlp.fc1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.9.mlp.fc2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.9.mlp.fc2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.10.norm1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.10.norm1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.10.attn.relative_position_bias_table \t Loaded\n",
            "audio_branch.layers.2.blocks.10.attn.qkv.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.10.attn.qkv.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.10.attn.proj.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.10.attn.proj.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.10.norm2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.10.norm2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.10.mlp.fc1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.10.mlp.fc1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.10.mlp.fc2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.10.mlp.fc2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.11.norm1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.11.norm1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.11.attn.relative_position_bias_table \t Loaded\n",
            "audio_branch.layers.2.blocks.11.attn.qkv.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.11.attn.qkv.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.11.attn.proj.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.11.attn.proj.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.11.norm2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.11.norm2.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.11.mlp.fc1.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.11.mlp.fc1.bias \t Loaded\n",
            "audio_branch.layers.2.blocks.11.mlp.fc2.weight \t Loaded\n",
            "audio_branch.layers.2.blocks.11.mlp.fc2.bias \t Loaded\n",
            "audio_branch.layers.2.downsample.reduction.weight \t Loaded\n",
            "audio_branch.layers.2.downsample.norm.weight \t Loaded\n",
            "audio_branch.layers.2.downsample.norm.bias \t Loaded\n",
            "audio_branch.layers.3.blocks.0.norm1.weight \t Loaded\n",
            "audio_branch.layers.3.blocks.0.norm1.bias \t Loaded\n",
            "audio_branch.layers.3.blocks.0.attn.relative_position_bias_table \t Loaded\n",
            "audio_branch.layers.3.blocks.0.attn.qkv.weight \t Loaded\n",
            "audio_branch.layers.3.blocks.0.attn.qkv.bias \t Loaded\n",
            "audio_branch.layers.3.blocks.0.attn.proj.weight \t Loaded\n",
            "audio_branch.layers.3.blocks.0.attn.proj.bias \t Loaded\n",
            "audio_branch.layers.3.blocks.0.norm2.weight \t Loaded\n",
            "audio_branch.layers.3.blocks.0.norm2.bias \t Loaded\n",
            "audio_branch.layers.3.blocks.0.mlp.fc1.weight \t Loaded\n",
            "audio_branch.layers.3.blocks.0.mlp.fc1.bias \t Loaded\n",
            "audio_branch.layers.3.blocks.0.mlp.fc2.weight \t Loaded\n",
            "audio_branch.layers.3.blocks.0.mlp.fc2.bias \t Loaded\n",
            "audio_branch.layers.3.blocks.1.norm1.weight \t Loaded\n",
            "audio_branch.layers.3.blocks.1.norm1.bias \t Loaded\n",
            "audio_branch.layers.3.blocks.1.attn.relative_position_bias_table \t Loaded\n",
            "audio_branch.layers.3.blocks.1.attn.qkv.weight \t Loaded\n",
            "audio_branch.layers.3.blocks.1.attn.qkv.bias \t Loaded\n",
            "audio_branch.layers.3.blocks.1.attn.proj.weight \t Loaded\n",
            "audio_branch.layers.3.blocks.1.attn.proj.bias \t Loaded\n",
            "audio_branch.layers.3.blocks.1.norm2.weight \t Loaded\n",
            "audio_branch.layers.3.blocks.1.norm2.bias \t Loaded\n",
            "audio_branch.layers.3.blocks.1.mlp.fc1.weight \t Loaded\n",
            "audio_branch.layers.3.blocks.1.mlp.fc1.bias \t Loaded\n",
            "audio_branch.layers.3.blocks.1.mlp.fc2.weight \t Loaded\n",
            "audio_branch.layers.3.blocks.1.mlp.fc2.bias \t Loaded\n",
            "audio_branch.norm.weight \t Loaded\n",
            "audio_branch.norm.bias \t Loaded\n",
            "audio_branch.tscam_conv.weight \t Loaded\n",
            "audio_branch.tscam_conv.bias \t Loaded\n",
            "audio_branch.head.weight \t Loaded\n",
            "audio_branch.head.bias \t Loaded\n",
            "text_branch.embeddings.word_embeddings.weight \t Loaded\n",
            "text_branch.embeddings.position_embeddings.weight \t Loaded\n",
            "text_branch.embeddings.token_type_embeddings.weight \t Loaded\n",
            "text_branch.embeddings.LayerNorm.weight \t Loaded\n",
            "text_branch.embeddings.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.0.attention.self.query.weight \t Loaded\n",
            "text_branch.encoder.layer.0.attention.self.query.bias \t Loaded\n",
            "text_branch.encoder.layer.0.attention.self.key.weight \t Loaded\n",
            "text_branch.encoder.layer.0.attention.self.key.bias \t Loaded\n",
            "text_branch.encoder.layer.0.attention.self.value.weight \t Loaded\n",
            "text_branch.encoder.layer.0.attention.self.value.bias \t Loaded\n",
            "text_branch.encoder.layer.0.attention.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.0.attention.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.0.attention.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.0.attention.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.0.intermediate.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.0.intermediate.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.0.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.0.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.0.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.0.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.1.attention.self.query.weight \t Loaded\n",
            "text_branch.encoder.layer.1.attention.self.query.bias \t Loaded\n",
            "text_branch.encoder.layer.1.attention.self.key.weight \t Loaded\n",
            "text_branch.encoder.layer.1.attention.self.key.bias \t Loaded\n",
            "text_branch.encoder.layer.1.attention.self.value.weight \t Loaded\n",
            "text_branch.encoder.layer.1.attention.self.value.bias \t Loaded\n",
            "text_branch.encoder.layer.1.attention.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.1.attention.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.1.attention.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.1.attention.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.1.intermediate.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.1.intermediate.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.1.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.1.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.1.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.1.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.2.attention.self.query.weight \t Loaded\n",
            "text_branch.encoder.layer.2.attention.self.query.bias \t Loaded\n",
            "text_branch.encoder.layer.2.attention.self.key.weight \t Loaded\n",
            "text_branch.encoder.layer.2.attention.self.key.bias \t Loaded\n",
            "text_branch.encoder.layer.2.attention.self.value.weight \t Loaded\n",
            "text_branch.encoder.layer.2.attention.self.value.bias \t Loaded\n",
            "text_branch.encoder.layer.2.attention.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.2.attention.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.2.attention.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.2.attention.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.2.intermediate.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.2.intermediate.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.2.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.2.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.2.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.2.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.3.attention.self.query.weight \t Loaded\n",
            "text_branch.encoder.layer.3.attention.self.query.bias \t Loaded\n",
            "text_branch.encoder.layer.3.attention.self.key.weight \t Loaded\n",
            "text_branch.encoder.layer.3.attention.self.key.bias \t Loaded\n",
            "text_branch.encoder.layer.3.attention.self.value.weight \t Loaded\n",
            "text_branch.encoder.layer.3.attention.self.value.bias \t Loaded\n",
            "text_branch.encoder.layer.3.attention.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.3.attention.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.3.attention.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.3.attention.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.3.intermediate.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.3.intermediate.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.3.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.3.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.3.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.3.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.4.attention.self.query.weight \t Loaded\n",
            "text_branch.encoder.layer.4.attention.self.query.bias \t Loaded\n",
            "text_branch.encoder.layer.4.attention.self.key.weight \t Loaded\n",
            "text_branch.encoder.layer.4.attention.self.key.bias \t Loaded\n",
            "text_branch.encoder.layer.4.attention.self.value.weight \t Loaded\n",
            "text_branch.encoder.layer.4.attention.self.value.bias \t Loaded\n",
            "text_branch.encoder.layer.4.attention.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.4.attention.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.4.attention.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.4.attention.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.4.intermediate.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.4.intermediate.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.4.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.4.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.4.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.4.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.5.attention.self.query.weight \t Loaded\n",
            "text_branch.encoder.layer.5.attention.self.query.bias \t Loaded\n",
            "text_branch.encoder.layer.5.attention.self.key.weight \t Loaded\n",
            "text_branch.encoder.layer.5.attention.self.key.bias \t Loaded\n",
            "text_branch.encoder.layer.5.attention.self.value.weight \t Loaded\n",
            "text_branch.encoder.layer.5.attention.self.value.bias \t Loaded\n",
            "text_branch.encoder.layer.5.attention.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.5.attention.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.5.attention.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.5.attention.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.5.intermediate.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.5.intermediate.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.5.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.5.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.5.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.5.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.6.attention.self.query.weight \t Loaded\n",
            "text_branch.encoder.layer.6.attention.self.query.bias \t Loaded\n",
            "text_branch.encoder.layer.6.attention.self.key.weight \t Loaded\n",
            "text_branch.encoder.layer.6.attention.self.key.bias \t Loaded\n",
            "text_branch.encoder.layer.6.attention.self.value.weight \t Loaded\n",
            "text_branch.encoder.layer.6.attention.self.value.bias \t Loaded\n",
            "text_branch.encoder.layer.6.attention.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.6.attention.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.6.attention.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.6.attention.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.6.intermediate.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.6.intermediate.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.6.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.6.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.6.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.6.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.7.attention.self.query.weight \t Loaded\n",
            "text_branch.encoder.layer.7.attention.self.query.bias \t Loaded\n",
            "text_branch.encoder.layer.7.attention.self.key.weight \t Loaded\n",
            "text_branch.encoder.layer.7.attention.self.key.bias \t Loaded\n",
            "text_branch.encoder.layer.7.attention.self.value.weight \t Loaded\n",
            "text_branch.encoder.layer.7.attention.self.value.bias \t Loaded\n",
            "text_branch.encoder.layer.7.attention.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.7.attention.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.7.attention.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.7.attention.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.7.intermediate.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.7.intermediate.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.7.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.7.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.7.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.7.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.8.attention.self.query.weight \t Loaded\n",
            "text_branch.encoder.layer.8.attention.self.query.bias \t Loaded\n",
            "text_branch.encoder.layer.8.attention.self.key.weight \t Loaded\n",
            "text_branch.encoder.layer.8.attention.self.key.bias \t Loaded\n",
            "text_branch.encoder.layer.8.attention.self.value.weight \t Loaded\n",
            "text_branch.encoder.layer.8.attention.self.value.bias \t Loaded\n",
            "text_branch.encoder.layer.8.attention.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.8.attention.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.8.attention.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.8.attention.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.8.intermediate.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.8.intermediate.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.8.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.8.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.8.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.8.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.9.attention.self.query.weight \t Loaded\n",
            "text_branch.encoder.layer.9.attention.self.query.bias \t Loaded\n",
            "text_branch.encoder.layer.9.attention.self.key.weight \t Loaded\n",
            "text_branch.encoder.layer.9.attention.self.key.bias \t Loaded\n",
            "text_branch.encoder.layer.9.attention.self.value.weight \t Loaded\n",
            "text_branch.encoder.layer.9.attention.self.value.bias \t Loaded\n",
            "text_branch.encoder.layer.9.attention.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.9.attention.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.9.attention.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.9.attention.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.9.intermediate.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.9.intermediate.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.9.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.9.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.9.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.9.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.10.attention.self.query.weight \t Loaded\n",
            "text_branch.encoder.layer.10.attention.self.query.bias \t Loaded\n",
            "text_branch.encoder.layer.10.attention.self.key.weight \t Loaded\n",
            "text_branch.encoder.layer.10.attention.self.key.bias \t Loaded\n",
            "text_branch.encoder.layer.10.attention.self.value.weight \t Loaded\n",
            "text_branch.encoder.layer.10.attention.self.value.bias \t Loaded\n",
            "text_branch.encoder.layer.10.attention.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.10.attention.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.10.attention.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.10.attention.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.10.intermediate.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.10.intermediate.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.10.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.10.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.10.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.10.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.11.attention.self.query.weight \t Loaded\n",
            "text_branch.encoder.layer.11.attention.self.query.bias \t Loaded\n",
            "text_branch.encoder.layer.11.attention.self.key.weight \t Loaded\n",
            "text_branch.encoder.layer.11.attention.self.key.bias \t Loaded\n",
            "text_branch.encoder.layer.11.attention.self.value.weight \t Loaded\n",
            "text_branch.encoder.layer.11.attention.self.value.bias \t Loaded\n",
            "text_branch.encoder.layer.11.attention.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.11.attention.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.11.attention.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.11.attention.output.LayerNorm.bias \t Loaded\n",
            "text_branch.encoder.layer.11.intermediate.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.11.intermediate.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.11.output.dense.weight \t Loaded\n",
            "text_branch.encoder.layer.11.output.dense.bias \t Loaded\n",
            "text_branch.encoder.layer.11.output.LayerNorm.weight \t Loaded\n",
            "text_branch.encoder.layer.11.output.LayerNorm.bias \t Loaded\n",
            "text_branch.pooler.dense.weight \t Loaded\n",
            "text_branch.pooler.dense.bias \t Loaded\n",
            "text_transform.sequential.0.weight \t Loaded\n",
            "text_transform.sequential.0.bias \t Loaded\n",
            "text_transform.sequential.3.weight \t Loaded\n",
            "text_transform.sequential.3.bias \t Loaded\n",
            "text_projection.0.weight \t Loaded\n",
            "text_projection.0.bias \t Loaded\n",
            "text_projection.2.weight \t Loaded\n",
            "text_projection.2.bias \t Loaded\n",
            "audio_transform.sequential.0.weight \t Loaded\n",
            "audio_transform.sequential.0.bias \t Loaded\n",
            "audio_transform.sequential.3.weight \t Loaded\n",
            "audio_transform.sequential.3.bias \t Loaded\n",
            "audio_projection.0.weight \t Loaded\n",
            "audio_projection.0.bias \t Loaded\n",
            "audio_projection.2.weight \t Loaded\n",
            "audio_projection.2.bias \t Loaded\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import torch\n",
        "import laion_clap\n",
        "\n",
        "# quantization\n",
        "def int16_to_float32(x):\n",
        "    return (x / 32767.0).astype(np.float32)\n",
        "\n",
        "\n",
        "def float32_to_int16(x):\n",
        "    x = np.clip(x, a_min=-1., a_max=1.)\n",
        "    return (x * 32767.).astype(np.int16)\n",
        "\n",
        "clap_model = laion_clap.CLAP_Module(enable_fusion=False, amodel= 'HTSAT-base')\n",
        "clap_model.load_ckpt(clap_ckp_path) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiEBo6goqFRE"
      },
      "source": [
        "### Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wJJrpfgUqNhE"
      },
      "outputs": [],
      "source": [
        "# Directly get audio embeddings from audio files\n",
        "run_this=False\n",
        "if run_this:\n",
        "  audio_file = [\n",
        "      DATA_PATH+'/train/-y3Abv2ovkU.wav',\n",
        "      DATA_PATH+'/train/BNyoM9gvGMs.wav'\n",
        "  ]\n",
        "  audio_embed = clap_model.get_audio_embedding_from_filelist(x = audio_file, use_tensor=False)\n",
        "  print(audio_embed[:,-20:])\n",
        "  print(audio_embed.shape)\n",
        "\n",
        "  # Get audio embeddings from audio data\n",
        "  audio_data, _ = librosa.load(DATA_PATH+'/train/-y3Abv2ovkU.wav', sr=48000) # sample rate should be 48000\n",
        "  audio_data = audio_data.reshape(1, -1) # Make it (1,T) or (N,T)\n",
        "  audio_embed = clap_model.get_audio_embedding_from_data(x = audio_data, use_tensor=False)\n",
        "  print(audio_embed[:,-20:])\n",
        "  print(audio_embed.shape)\n",
        "\n",
        "  # Directly get audio embeddings from audio files, but return torch tensor\n",
        "  audio_embed = clap_model.get_audio_embedding_from_filelist(x = audio_file, use_tensor=True)\n",
        "  print(audio_embed[:,-20:])\n",
        "  print(audio_embed.shape)\n",
        "\n",
        "  # Get audio embeddings from audio data\n",
        "  audio_data, _ = librosa.load(DATA_PATH+'/train/-y3Abv2ovkU.wav', sr=48000) # sample rate should be 48000\n",
        "  audio_data = audio_data.reshape(1, -1) # Make it (1,T) or (N,T)\n",
        "  audio_data = torch.from_numpy(int16_to_float32(float32_to_int16(audio_data))).float() # quantize before send it in to the model\n",
        "  audio_embed = clap_model.get_audio_embedding_from_data(x = audio_data, use_tensor=True)\n",
        "  print(audio_embed[:,-20:])\n",
        "  print(audio_embed.shape)\n",
        "\n",
        "  # Get text embedings from texts:\n",
        "  text_data = [\"I love the contrastive learning\", \"I love the pretrain model\"] \n",
        "  text_embed = clap_model.get_text_embedding(text_data)\n",
        "  print(text_embed)\n",
        "  print(text_embed.shape)\n",
        "\n",
        "  # Get text embedings from texts, but return torch tensor:\n",
        "  text_data = [\"I love the contrastive learning\", \"I love the pretrain model\"] \n",
        "  text_embed = clap_model.get_text_embedding(text_data, use_tensor=True)\n",
        "  print(text_embed)\n",
        "  print(text_embed.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZizSIRjnwDlI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6beb5a3-b5f3-48b0-8060-30fb9fecdbc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "wavs = torch.randn(2, 1024)\n",
        "texts = torch.randint(0, 20000, (2, 256))\n",
        "clap_model.get_audio_embedding_from_data(x = wavs, use_tensor=True).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhK_3FSVqF2t"
      },
      "source": [
        "### Quantizer for AudioML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ihv8jANAqN-J"
      },
      "outputs": [],
      "source": [
        "# Based on MuLaNEmbedQuantizer implementation on https://github.com/lucidrains/musiclm-pytorch\n",
        "from audiolm_pytorch.utils import AudioConditionerBase\n",
        "from beartype.typing import List, Optional, Tuple\n",
        "from beartype import beartype\n",
        "from einops import rearrange, repeat, reduce, pack, unpack\n",
        "from einops.layers.torch import Rearrange\n",
        "from vector_quantize_pytorch import ResidualVQ\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "def exists(val):\n",
        "    return val is not None\n",
        "\n",
        "def default(val, d):\n",
        "    return val if exists(val) else d\n",
        "\n",
        "class CLAPEmbedQuantizer(AudioConditionerBase):\n",
        "    @beartype\n",
        "    def __init__(\n",
        "        self,\n",
        "        clap: laion_clap.CLAP_Module,\n",
        "        conditioning_dims: Tuple[int, ...],\n",
        "        rq_num_quantizers = 8,\n",
        "        rq_ema_decay = 0.9,\n",
        "        codebook_size = 1024,\n",
        "        namespaces: Tuple[str, ...] = ('semantic', 'coarse', 'fine'),\n",
        "\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.clap = clap\n",
        "\n",
        "        assert len(namespaces) > 0\n",
        "        self.namespaces = namespaces\n",
        "        self.conditioning_dims = conditioning_dims\n",
        "\n",
        "        assert len(conditioning_dims) == len(namespaces), 'number of conditioning dimensions must be equal to number of namespaces'\n",
        "\n",
        "        dim = clap.model.audio_projection[-1].out_features\n",
        "\n",
        "        self.rq = ResidualVQ(\n",
        "            dim = dim,\n",
        "            num_quantizers = rq_num_quantizers,\n",
        "            codebook_size = codebook_size,\n",
        "            decay = rq_ema_decay,\n",
        "            commitment_weight = 0,    # only use EMA to update codebooks\n",
        "            kmeans_init = True,\n",
        "            threshold_ema_dead_code = 2,\n",
        "            quantize_dropout = False  # no quantize dropout\n",
        "        )\n",
        "\n",
        "        self.dim = dim\n",
        "        self.num_codebooks = rq_num_quantizers\n",
        "\n",
        "        self.cond_embeddings = nn.ParameterDict({})\n",
        "\n",
        "        for namespace, conditioning_dim in zip(namespaces, conditioning_dims):\n",
        "            cond_embeddings = nn.Parameter(torch.randn(rq_num_quantizers, codebook_size, conditioning_dim))\n",
        "            nn.init.normal_(cond_embeddings, std = 0.02)\n",
        "\n",
        "            self.cond_embeddings[namespace] = cond_embeddings\n",
        "\n",
        "        self.set_default_namespace(namespaces[0])\n",
        "\n",
        "    def parameters(self):\n",
        "        return self.cond_embeddings.parameters()\n",
        "\n",
        "    def set_default_namespace(self, namespace):\n",
        "        self._default_namespace = namespace\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        wavs = None,\n",
        "        texts = None,\n",
        "        namespace = None\n",
        "    ):\n",
        "        assert exists(wavs) ^ exists(texts)\n",
        "\n",
        "        namespace = default(namespace, self._default_namespace)\n",
        "        assert namespace in self.namespaces, f'namespace {namespace} not found'\n",
        "        cond_embeddings = self.cond_embeddings[namespace]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.clap.eval()\n",
        "\n",
        "            # sound and language live in joint embedding space because of contrastive learning\n",
        "\n",
        "            if exists(wavs):\n",
        "                latents = self.clap.get_audio_embedding_from_data(x = wavs, use_tensor=True) \n",
        "            elif exists(texts):\n",
        "                latents = self.clap.get_text_embedding(texts, use_tensor=True) \n",
        "\n",
        "        _, indices, _ = self.rq(latents)\n",
        "\n",
        "        batch, num_codebooks, dim = indices.shape[0], self.num_codebooks, cond_embeddings.shape[-1]\n",
        "\n",
        "        cond_embeddings = repeat(cond_embeddings, 'q c d -> b q c d', b = batch)\n",
        "        indices = repeat(indices, 'b q -> b q 1 d', q = num_codebooks, d = dim)\n",
        "\n",
        "        cond_embeddings = cond_embeddings.gather(2, indices)\n",
        "        return rearrange(cond_embeddings, 'b q 1 d -> b q d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ExxNRIaavxk4"
      },
      "outputs": [],
      "source": [
        "# setup the quantizer with the namespaced conditioning embeddings, \n",
        "# unique per quantizer as well as namespace (per transformer)\n",
        "quantizer = CLAPEmbedQuantizer(\n",
        "    clap = clap_model,                         \n",
        "    conditioning_dims = (1024, 1024, 1024), # say all three transformers have model dimensions of 1024\n",
        "    namespaces = ('semantic', 'coarse', 'fine')\n",
        ").cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2HUYIETzxSib"
      },
      "outputs": [],
      "source": [
        "# now say you want the conditioning embeddings for semantic transformer\n",
        "# wavs = torch.randn(2, 1024).cuda()\n",
        "# conds = quantizer(wavs = wavs, namespace = 'coarse')\n",
        "# print(conds.shape)\n",
        "# conds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Q1fIZMgIFGNJ"
      },
      "outputs": [],
      "source": [
        "# text_embbeddings = quantizer(texts=[\"I love the contrastive learning\", \"\"])[0:1]\n",
        "# text_embbeddings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYEwiQq93j11"
      },
      "source": [
        "#AudioLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBxNK5cKW--_"
      },
      "source": [
        "### Imports & paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OrNeKngVVM0L"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import math\n",
        "import wave\n",
        "import struct\n",
        "import os\n",
        "import urllib.request\n",
        "import tarfile\n",
        "from audiolm_pytorch import SoundStream, SoundStreamTrainer, HubertWithKmeans, SemanticTransformer, SemanticTransformerTrainer, HubertWithKmeans, CoarseTransformer, CoarseTransformerWrapper, CoarseTransformerTrainer, FineTransformer, FineTransformerWrapper, FineTransformerTrainer, AudioLM\n",
        "from torch import nn\n",
        "import torch\n",
        "import torchaudio\n",
        "import gc\n",
        "\n",
        "# define all dataset paths, checkpoints, etc\n",
        "dataset_folder = DATA_PATH\n",
        "soundstream_ckpt = RESULTS_ROOT_PATH+\"/results_soundstream/soundstream.8.pt\" # this can change depending on number of steps\n",
        "hubert_ckpt = 'hubert/hubert_base_ls960.pt'\n",
        "hubert_quantizer = f'hubert/hubert_base_ls960_L9_km500.bin' # listed in row \"HuBERT Base (~95M params)\", column Quantizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def noop(*args, **kwargs):\n",
        "    pass"
      ],
      "metadata": {
        "id": "N3q3VXndzJll"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYcI0aXEwuxR"
      },
      "source": [
        "## Training\n",
        "\n",
        "Now that we have a dataset, we can train AudioLM.\n",
        "\n",
        "**Note**: do NOT type \"y\" to overwrite previous experiments/ checkpoints when running through the cells here unless you're ready to the entire results folder! Otherwise you will end up erasing things (e.g. you train SoundStream first, and if you choose \"overwrite\" then you lose the SoundStream checkpoint when you then train SemanticTransformer)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7GiyBcBWiZV"
      },
      "source": [
        "### SoundStream / encodec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Oz4Mll6lVPbt"
      },
      "outputs": [],
      "source": [
        "using_encodec=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wSVRf1Z7V8dT"
      },
      "outputs": [],
      "source": [
        "# from audiolm_pytorch import AudioLMSoundStream, MusicLMSoundStream\n",
        "# MusicLMSoundStream()\n",
        "from audiolm_pytorch import EncodecWrapper\n",
        "soundstream = EncodecWrapper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nGU0OZiOwPEO"
      },
      "outputs": [],
      "source": [
        "if not using_encodec:\n",
        "  soundstream = SoundStream(\n",
        "      codebook_size = 1024,\n",
        "      rq_num_quantizers = 8,\n",
        "  )\n",
        "\n",
        "  trainer = SoundStreamTrainer( \n",
        "      soundstream,\n",
        "      folder = dataset_folder,\n",
        "      batch_size = 4,\n",
        "      grad_accum_every = 8,         # effective batch size of 32\n",
        "      data_max_length = 320 * 32,\n",
        "      save_results_every = 2,\n",
        "      save_model_every = 4,\n",
        "      num_train_steps = 9,\n",
        "      results_folder = RESULTS_ROOT_PATH+'/results_soundstream',\n",
        "      force_clear_prev_results = True,\n",
        "  ).cuda()\n",
        "  # NOTE: I changed num_train_steps to 9 (aka 8 + 1) from 10000 to make things go faster for demo purposes\n",
        "  # adjusting save_*_every variables for the same reason\n",
        "\n",
        "  trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### wav2Vec"
      ],
      "metadata": {
        "id": "aKAFNMrqpMBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hubert checkpoints can be downloaded at\n",
        "# https://github.com/facebookresearch/fairseq/tree/main/examples/hubert\n",
        "if not os.path.isdir(\"hubert\"):\n",
        "  os.makedirs(\"hubert\")\n",
        "if not os.path.isfile(hubert_ckpt):\n",
        "  hubert_ckpt_download = f\"https://dl.fbaipublicfiles.com/{hubert_ckpt}\"\n",
        "  urllib.request.urlretrieve(hubert_ckpt_download, f\"./{hubert_ckpt}\")\n",
        "if not os.path.isfile(hubert_quantizer):\n",
        "  hubert_quantizer_download = f\"https://dl.fbaipublicfiles.com/{hubert_quantizer}\"\n",
        "  urllib.request.urlretrieve(hubert_quantizer_download, f\"./{hubert_quantizer}\")\n",
        "\n",
        "wav2vec = HubertWithKmeans(\n",
        "    checkpoint_path = f'./{hubert_ckpt}',\n",
        "    kmeans_path = f'./{hubert_quantizer}'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Bu8Ve0-pO9J",
        "outputId": "a5e57d09-feb9-4772-e204-7d291bf9f03b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MiniBatchKMeans from version 0.24.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wav2vec.target_sample_hz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOCVHaqWtC3D",
        "outputId": "4f2d5801-1933-4a55-bed2-47d61427863c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16000"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Common functions"
      ],
      "metadata": {
        "id": "uhKGvSDSC-Mr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import traceback\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "_S6pCA-F5KsZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger = wandb.log if wandb is not None else noop"
      ],
      "metadata": {
        "id": "giauL5TlTD2f"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def free_gpu_memory(model):\n",
        "  for p in model.parameters():\n",
        "      if p.grad is not None:\n",
        "          del p.grad  # free some memory\n",
        "  torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "KS--wGvPEJfj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_train(trainer, config, scheduler=None, from_step=None):\n",
        "  logger= noop\n",
        "  if wandb is not None:\n",
        "    logger = wandb.log \n",
        "    wandb.config.update(config)\n",
        "\n",
        "  if from_step is not None:\n",
        "    trainer.steps = from_step\n",
        "  \n",
        "  num_raise_oom=0\n",
        "\n",
        "  while trainer.steps < trainer.num_train_steps:\n",
        "      torch.cuda.empty_cache()\n",
        "      try:\n",
        "          logs = trainer.train_step()\n",
        "\n",
        "          if scheduler is not None:\n",
        "            if isinstance(scheduler, ReduceLROnPlateau):\n",
        "              scheduler.step(logs[\"loss\"])\n",
        "              logs[\"lr\"] = trainer.optim.param_groups[0][\"lr\"]\n",
        "          logger(logs)\n",
        "          num_raise_oom = 0\n",
        "      except RuntimeError as e:\n",
        "\n",
        "          if 'out of memory' in str(e) and num_raise_oom<7:\n",
        "              print('| WARNING: ran out of memory, retrying batch')\n",
        "              free_gpu_memory(trainer.transformer)\n",
        "              num_raise_oom+=1\n",
        "          elif num_raise_oom>= 7:\n",
        "            print(traceback.format_exc())\n",
        "            print(e)\n",
        "            break\n",
        "          else:\n",
        "              print(traceback.format_exc())\n",
        "              print(e)\n",
        "              \n",
        "\n",
        "  model_path = str(trainer.results_folder / f\"transformer.last.pt\")\n",
        "  trainer.save(model_path)\n",
        "  trainer.print(\"training complete\")"
      ],
      "metadata": {
        "id": "l3MB2Jzn5HfM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_scheduler(optim, config):\n",
        "  if config[\"scheduler\"] == None:\n",
        "    return None\n",
        "  if config[\"scheduler\"] == \"reducelr\":\n",
        "    if config[\"model\"] == \"semantic\":\n",
        "      return ReduceLROnPlateau(optim, \n",
        "                              factor=0.7, patience=15, \n",
        "                              threshold=0.0001, threshold_mode='rel', \n",
        "                              cooldown=0, min_lr=1e-5, eps=1e-08, \n",
        "                              verbose=True)\n",
        "    elif config[\"model\"] == \"coarse\":\n",
        "      return ReduceLROnPlateau(optim, \n",
        "                              factor=0.7, patience=200, \n",
        "                              threshold=0.0001, threshold_mode='rel', \n",
        "                              cooldown=100, min_lr=1e-5, eps=1e-08, \n",
        "                              verbose=True)\n",
        "    elif config[\"model\"] == \"fine\":\n",
        "      return ReduceLROnPlateau(optim, \n",
        "                              factor=0.7, patience=40, \n",
        "                              threshold=0.0001, threshold_mode='rel', \n",
        "                              cooldown=5, min_lr=1e-5, eps=1e-08, \n",
        "                              verbose=True)"
      ],
      "metadata": {
        "id": "Ds3-LSnKAP2U"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accelerate_kwargs(config):\n",
        "  return dict(log_with=\"wandb\") if wandb is not None else None"
      ],
      "metadata": {
        "id": "4PemCzvVB_1w"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqjN28L4Wc5Q"
      },
      "source": [
        "### SemanticTransformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_max_length = data_max_length_seconds * wav2vec.target_sample_hz\n",
        "\n",
        "# custom_ds = SoundDataset(\n",
        "#     dataset_folder,\n",
        "#     max_length = data_max_length,\n",
        "#     target_sample_hz = wav2vec.target_sample_hz,\n",
        "#     seq_len_multiple_of = wav2vec.seq_len_multiple_of\n",
        "# )"
      ],
      "metadata": {
        "id": "F3nnCLqZyM0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f1960d391f8a4ab3bd375daf781e7cd3",
            "d887cd8b7b3f4e4f91afe9fdec5b74d2",
            "217ae3c37be743128194700a2eed146f",
            "bd0624db5611477683b193fa9fa4da7b",
            "b51ae5afdce3498db172fbf31b787377",
            "62b7f7b6421045a3ba7cbed71b496107",
            "54ac48515c63477592ca6af47bed4cae",
            "78a3cb842060468683370d9da6fdcad8"
          ]
        },
        "id": "qgd962eSvDzS",
        "outputId": "0a6c87d2-0cfb-439a-fb5b-9e120b95699c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training with dataset of 207 samples and validating with randomly splitted 11 samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:pthopscw) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1960d391f8a4ab3bd375daf781e7cd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">vibrant-pyramid-2</strong> at: <a href='https://wandb.ai/ols/semantic/runs/pthopscw' target=\"_blank\">https://wandb.ai/ols/semantic/runs/pthopscw</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230501_084124-pthopscw/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:pthopscw). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230501_084222-41cg1nl6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ols/semantic/runs/41cg1nl6' target=\"_blank\">dandy-dawn-3</a></strong> to <a href='https://wandb.ai/ols/semantic' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ols/semantic' target=\"_blank\">https://wandb.ai/ols/semantic</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ols/semantic/runs/41cg1nl6' target=\"_blank\">https://wandb.ai/ols/semantic/runs/41cg1nl6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: loss: 6.412100791931152\n",
            "0: valid loss 5.621673583984375\n",
            "0: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_semantic\n",
            "1: loss: 5.715096473693848\n",
            "2: loss: 5.409526824951172\n",
            "3: loss: 5.440529823303223\n",
            "4: loss: 5.176313877105713\n",
            "5: loss: 5.018872261047363\n",
            "6: loss: 4.985597610473633\n",
            "7: loss: 4.564576148986816\n",
            "8: loss: 4.783191680908203\n",
            "9: loss: 4.523497104644775\n",
            "10: loss: 4.521331310272217\n",
            "11: loss: 4.495727062225342\n",
            "12: loss: 4.5598273277282715\n",
            "13: loss: 4.492865562438965\n",
            "14: loss: 4.435531139373779\n",
            "15: loss: 4.084705829620361\n",
            "16: loss: 4.100088119506836\n",
            "17: loss: 4.249460697174072\n",
            "18: loss: 4.073540687561035\n",
            "19: loss: 4.238702774047852\n",
            "20: loss: 3.945391893386841\n",
            "20: valid loss 4.0078630447387695\n",
            "21: loss: 4.041194915771484\n",
            "22: loss: 3.896615505218506\n",
            "23: loss: 3.7288925647735596\n",
            "24: loss: 3.5784125328063965\n",
            "25: loss: 4.0225300788879395\n",
            "26: loss: 3.4903275966644287\n",
            "27: loss: 3.284003496170044\n",
            "28: loss: 3.303596019744873\n",
            "29: loss: 3.3120968341827393\n",
            "30: loss: 3.5409088134765625\n",
            "31: loss: 3.282320499420166\n",
            "32: loss: 3.271390676498413\n",
            "33: loss: 3.2687182426452637\n",
            "34: loss: 3.3631434440612793\n",
            "35: loss: 3.1935720443725586\n",
            "36: loss: 3.072545051574707\n",
            "37: loss: 2.9031293392181396\n",
            "38: loss: 2.9505650997161865\n",
            "39: loss: 3.3290114402770996\n",
            "40: loss: 3.1004130840301514\n",
            "40: valid loss 3.7765328884124756\n",
            "41: loss: 3.3815834522247314\n",
            "42: loss: 3.2082712650299072\n",
            "43: loss: 3.0332963466644287\n",
            "44: loss: 3.0911598205566406\n",
            "45: loss: 3.088696002960205\n",
            "46: loss: 3.0971951484680176\n",
            "47: loss: 3.1360697746276855\n",
            "48: loss: 3.1779088973999023\n",
            "49: loss: 3.162658452987671\n",
            "50: loss: 2.8609721660614014\n",
            "50: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_semantic\n",
            "51: loss: 2.847060441970825\n",
            "52: loss: 1.7626854181289673\n",
            "53: loss: 2.235626459121704\n",
            "54: loss: 2.1014702320098877\n",
            "55: loss: 1.98898184299469\n",
            "56: loss: 1.8549792766571045\n",
            "57: loss: 2.025986671447754\n",
            "58: loss: 1.8402334451675415\n",
            "59: loss: 1.997538447380066\n",
            "60: loss: 1.9228875637054443\n",
            "60: valid loss 3.96842885017395\n",
            "61: loss: 1.6648913621902466\n",
            "62: loss: 1.5406683683395386\n",
            "63: loss: 2.175852060317993\n",
            "64: loss: 1.7825369834899902\n",
            "65: loss: 1.6503580808639526\n",
            "66: loss: 1.6043251752853394\n",
            "67: loss: 1.545078158378601\n",
            "68: loss: 1.8291471004486084\n",
            "69: loss: 2.0719892978668213\n",
            "70: loss: 1.9848990440368652\n",
            "71: loss: 1.8375965356826782\n",
            "72: loss: 1.6307246685028076\n",
            "73: loss: 1.5891765356063843\n",
            "74: loss: 1.6907248497009277\n",
            "75: loss: 1.9600534439086914\n",
            "76: loss: 1.9151517152786255\n",
            "77: loss: 2.1508007049560547\n",
            "78: loss: 0.7804369330406189\n",
            "79: loss: 0.4783356785774231\n",
            "80: loss: 0.5524523854255676\n",
            "80: valid loss 4.278469562530518\n",
            "81: loss: 0.684889018535614\n",
            "82: loss: 0.6984291076660156\n",
            "83: loss: 1.1568245887756348\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 37>\u001b[0m:\u001b[94m38\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92mcustom_train\u001b[0m:\u001b[94m15\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/audiolm_pytorch/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m715\u001b[0m in \u001b[92mtrain_step\u001b[0m             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 712 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# update vae (generator)\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 713 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 714 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m _ \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(\u001b[96mself\u001b[0m.grad_accum_every):                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 715 \u001b[2m│   │   │   \u001b[0mdata_kwargs = \u001b[96mself\u001b[0m.data_tuple_to_kwargs(\u001b[96mnext\u001b[0m(\u001b[96mself\u001b[0m.dl_iter))                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 716 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 717 \u001b[0m\u001b[2m│   │   │   \u001b[0mloss = \u001b[96mself\u001b[0m.train_wrapper(**data_kwargs, return_loss = \u001b[94mTrue\u001b[0m)                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 718 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/audiolm_pytorch/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m76\u001b[0m in \u001b[92mcycle\u001b[0m                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m  73 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m  74 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcycle\u001b[0m(dl):                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m  75 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mwhile\u001b[0m \u001b[94mTrue\u001b[0m:                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m  76 \u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m data \u001b[95min\u001b[0m dl:                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m  77 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94myield\u001b[0m data                                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m  78 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m  79 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcast_tuple\u001b[0m(t):                                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/accelerate/\u001b[0m\u001b[1;33mdata_loader.py\u001b[0m:\u001b[94m388\u001b[0m in \u001b[92m__iter__\u001b[0m                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m385 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# But we still move it to the device so it is done before `StopIteration\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m386 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.device \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m387 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mcurrent_batch = send_to_device(current_batch, \u001b[96mself\u001b[0m.device)             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m388 \u001b[2m│   │   │   │   \u001b[0mnext_batch = \u001b[96mnext\u001b[0m(dataloader_iter)                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m389 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m batch_index >= \u001b[96mself\u001b[0m.skip_batches:                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m390 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94myield\u001b[0m current_batch                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m391 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mbatch_index += \u001b[94m1\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.py\u001b[0m:\u001b[94m634\u001b[0m in \u001b[92m__next__\u001b[0m           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 631 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._sampler_iter \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 632 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 633 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._reset()  \u001b[2m# type: ignore[call-arg]\u001b[0m                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 634 \u001b[2m│   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m._next_data()                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 635 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._num_yielded += \u001b[94m1\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 636 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._dataset_kind == _DatasetKind.Iterable \u001b[95mand\u001b[0m \\                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 637 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._IterableDataset_len_called \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m \\                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.py\u001b[0m:\u001b[94m678\u001b[0m in \u001b[92m_next_data\u001b[0m         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 675 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 676 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_next_data\u001b[0m(\u001b[96mself\u001b[0m):                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 677 \u001b[0m\u001b[2m│   │   \u001b[0mindex = \u001b[96mself\u001b[0m._next_index()  \u001b[2m# may raise StopIteration\u001b[0m                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 678 \u001b[2m│   │   \u001b[0mdata = \u001b[96mself\u001b[0m._dataset_fetcher.fetch(index)  \u001b[2m# may raise StopIteration\u001b[0m              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 679 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._pin_memory:                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 680 \u001b[0m\u001b[2m│   │   │   \u001b[0mdata = _utils.pin_memory.pin_memory(data, \u001b[96mself\u001b[0m._pin_memory_device)            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 681 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m data                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/\u001b[0m\u001b[1;33mfetch.py\u001b[0m:\u001b[94m51\u001b[0m in \u001b[92mfetch\u001b[0m             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mhasattr\u001b[0m(\u001b[96mself\u001b[0m.dataset, \u001b[33m\"\u001b[0m\u001b[33m__getitems__\u001b[0m\u001b[33m\"\u001b[0m) \u001b[95mand\u001b[0m \u001b[96mself\u001b[0m.dataset.__getitems__:         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m49 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m.dataset.__getitems__(possibly_batched_index)                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m50 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m51 \u001b[2m│   │   │   │   \u001b[0mdata = [\u001b[96mself\u001b[0m.dataset[idx] \u001b[94mfor\u001b[0m idx \u001b[95min\u001b[0m possibly_batched_index]                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m52 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m53 \u001b[0m\u001b[2m│   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m.dataset[possibly_batched_index]                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m54 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.collate_fn(data)                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/\u001b[0m\u001b[1;33mfetch.py\u001b[0m:\u001b[94m51\u001b[0m in \u001b[92m<listcomp>\u001b[0m        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mhasattr\u001b[0m(\u001b[96mself\u001b[0m.dataset, \u001b[33m\"\u001b[0m\u001b[33m__getitems__\u001b[0m\u001b[33m\"\u001b[0m) \u001b[95mand\u001b[0m \u001b[96mself\u001b[0m.dataset.__getitems__:         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m49 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m.dataset.__getitems__(possibly_batched_index)                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m50 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m51 \u001b[2m│   │   │   │   \u001b[0mdata = [\u001b[96mself\u001b[0m.dataset[idx] \u001b[94mfor\u001b[0m idx \u001b[95min\u001b[0m possibly_batched_index]                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m52 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m53 \u001b[0m\u001b[2m│   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m.dataset[possibly_batched_index]                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m54 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.collate_fn(data)                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataset.py\u001b[0m:\u001b[94m298\u001b[0m in \u001b[92m__getitem__\u001b[0m           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m295 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__getitem__\u001b[0m(\u001b[96mself\u001b[0m, idx):                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m296 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(idx, \u001b[96mlist\u001b[0m):                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m297 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.dataset[[\u001b[96mself\u001b[0m.indices[i] \u001b[94mfor\u001b[0m i \u001b[95min\u001b[0m idx]]                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m298 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.dataset[\u001b[96mself\u001b[0m.indices[idx]]                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m299 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m300 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__len__\u001b[0m(\u001b[96mself\u001b[0m):                                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m301 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mlen\u001b[0m(\u001b[96mself\u001b[0m.indices)                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/audiolm_pytorch/\u001b[0m\u001b[1;33mdata.py\u001b[0m:\u001b[94m67\u001b[0m in \u001b[92m__getitem__\u001b[0m                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 64 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__getitem__\u001b[0m(\u001b[96mself\u001b[0m, idx):                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 65 \u001b[0m\u001b[2m│   │   \u001b[0mfile = \u001b[96mself\u001b[0m.files[idx]                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 66 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 67 \u001b[2m│   │   \u001b[0mdata, sample_hz = torchaudio.load(file)                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 68 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 69 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m data.numel() > \u001b[94m0\u001b[0m, \u001b[33mf\u001b[0m\u001b[33m'\u001b[0m\u001b[33mone of your audio file (\u001b[0m\u001b[33m{\u001b[0mfile\u001b[33m}\u001b[0m\u001b[33m) is empty. please remo\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 70 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torchaudio/backend/\u001b[0m\u001b[1;33msox_io_backend.py\u001b[0m:\u001b[94m251\u001b[0m in \u001b[92mload\u001b[0m         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m248 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mbuffer_size,                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m249 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m250 \u001b[0m\u001b[2m│   │   \u001b[0mfilepath = os.fspath(filepath)                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m251 \u001b[2m│   \u001b[0mret = torch.ops.torchaudio.sox_io_load_audio_file(                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m252 \u001b[0m\u001b[2m│   │   \u001b[0mfilepath, frame_offset, num_frames, normalize, channels_first, \u001b[96mformat\u001b[0m              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m253 \u001b[0m\u001b[2m│   \u001b[0m)                                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m254 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m ret \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/\u001b[0m\u001b[1;33m_ops.py\u001b[0m:\u001b[94m502\u001b[0m in \u001b[92m__call__\u001b[0m                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m499 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# is still callable from JIT\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m500 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# We save the function ptr as the `op` attribute on\u001b[0m                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m501 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# OpOverloadPacket to access it here.\u001b[0m                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m502 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._op(*args, **kwargs \u001b[95mor\u001b[0m {})                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m503 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m504 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# TODO: use this to make a __dir__\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m505 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92moverloads\u001b[0m(\u001b[96mself\u001b[0m):                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 37&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">38</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">custom_train</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">15</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/audiolm_pytorch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">715</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_step</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 712 │   │   # update vae (generator)</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 713 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 714 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> _ <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.grad_accum_every):                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 715 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data_kwargs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.data_tuple_to_kwargs(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">next</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dl_iter))                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 716 │   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 717 │   │   │   </span>loss = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.train_wrapper(**data_kwargs, return_loss = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 718 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/audiolm_pytorch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">76</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cycle</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  73 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  74 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cycle</span>(dl):                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  75 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">while</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>:                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>  76 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> data <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> dl:                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  77 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">yield</span> data                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  78 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  79 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cast_tuple</span>(t):                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">data_loader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">388</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">385 │   │   │   │   # But we still move it to the device so it is done before `StopIteration</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">386 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.device <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">387 │   │   │   │   │   </span>current_batch = send_to_device(current_batch, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.device)             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>388 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>next_batch = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">next</span>(dataloader_iter)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">389 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> batch_index &gt;= <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.skip_batches:                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">390 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">yield</span> current_batch                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">391 │   │   │   │   </span>batch_index += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">634</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__next__</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 631 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._sampler_iter <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 632 │   │   │   │   # TODO(https://github.com/pytorch/pytorch/issues/76750)</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 633 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._reset()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[call-arg]</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 634 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._next_data()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 635 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._num_yielded += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 636 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_kind == _DatasetKind.Iterable <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 637 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._IterableDataset_len_called <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">678</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_next_data</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 675 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 676 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_next_data</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 677 │   │   </span>index = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._next_index()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># may raise StopIteration</span>                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 678 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_fetcher.fetch(index)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># may raise StopIteration</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 679 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._pin_memory:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 680 │   │   │   </span>data = _utils.pin_memory.pin_memory(data, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._pin_memory_device)            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 681 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> data                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">fetch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">51</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fetch</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">48 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">hasattr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset, <span style=\"color: #808000; text-decoration-color: #808000\">\"__getitems__\"</span>) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset.__getitems__:         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">49 │   │   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset.__getitems__(possibly_batched_index)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">50 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>51 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>data = [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[idx] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> idx <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> possibly_batched_index]                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">52 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53 │   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[possibly_batched_index]                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">54 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.collate_fn(data)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">fetch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">51</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;listcomp&gt;</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">48 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">hasattr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset, <span style=\"color: #808000; text-decoration-color: #808000\">\"__getitems__\"</span>) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset.__getitems__:         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">49 │   │   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset.__getitems__(possibly_batched_index)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">50 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>51 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>data = [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[idx] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> idx <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> possibly_batched_index]                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">52 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53 │   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[possibly_batched_index]                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">54 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.collate_fn(data)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataset.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">298</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getitem__</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">295 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getitem__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, idx):                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">296 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(idx, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>):                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">297 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.indices[i] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> idx]]                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>298 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.indices[idx]]                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">299 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">300 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__len__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">301 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.indices)                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/audiolm_pytorch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">data.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">67</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getitem__</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 64 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getitem__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, idx):                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 65 │   │   </span>file = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.files[idx]                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 66 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 67 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>data, sample_hz = torchaudio.load(file)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 68 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 69 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> data.numel() &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">f'one of your audio file ({</span>file<span style=\"color: #808000; text-decoration-color: #808000\">}) is empty. please remo</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 70 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torchaudio/backend/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">sox_io_backend.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">251</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">248 │   │   │   │   </span>buffer_size,                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">249 │   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">250 │   │   </span>filepath = os.fspath(filepath)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>251 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>ret = torch.ops.torchaudio.sox_io_load_audio_file(                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">252 │   │   </span>filepath, frame_offset, num_frames, normalize, channels_first, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">format</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">253 │   </span>)                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">254 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> ret <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_ops.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">502</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">499 │   │   # is still callable from JIT</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">500 │   │   # We save the function ptr as the `op` attribute on</span>                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">501 │   │   # OpOverloadPacket to access it here.</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>502 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._op(*args, **kwargs <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> {})                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">503 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">504 │   # TODO: use this to make a __dir__</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">505 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">overloads</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "semantic_transformer = SemanticTransformer(\n",
        "    num_semantic_tokens = wav2vec.codebook_size,\n",
        "    dim = 1024,\n",
        "    depth = 6,\n",
        "    audio_text_condition = True,\n",
        "    attn_dropout = config[\"attn_dropout\"],\n",
        "    ff_dropout = config[\"ff_dropout\"],\n",
        ").cuda()\n",
        "\n",
        "\n",
        "semantic_trainer = SemanticTransformerTrainer(\n",
        "    transformer = semantic_transformer,\n",
        "    wav2vec = wav2vec,\n",
        "    audio_conditioner = quantizer,\n",
        "    folder = dataset_folder,\n",
        "    lr=config[\"lr\"],\n",
        "    batch_size = config[\"batch_size\"],\n",
        "    data_max_length_seconds = config.get(\"data_max_length_seconds\"),\n",
        "    data_max_length = config.get(\"data_max_length\"),\n",
        "    save_results_every = VAL_EVERY_STEPS,\n",
        "    wd = config[\"wd\"],\n",
        "    grad_accum_every = config[\"grad_accum_every\"],\n",
        "    max_grad_norm = config[\"max_grad_norm\"],\n",
        "    save_model_every = 50,\n",
        "    num_train_steps = STEPS,\n",
        "    results_folder = RESULTS_ROOT_PATH+'/results_semantic',\n",
        "    force_clear_prev_results = False,\n",
        "    accelerate_kwargs = get_accelerate_kwargs(config)\n",
        ")\n",
        "\n",
        "scheduler = get_scheduler(semantic_trainer.optim, config)\n",
        "\n",
        "if load_ckpt:\n",
        "  semantic_trainer.load(semantic_load_path)\n",
        "\n",
        "if train:\n",
        "  custom_train(semantic_trainer,\n",
        "               config,\n",
        "               scheduler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eEvIzhEWwRz"
      },
      "source": [
        "### CoarseTransformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  if train:\n",
        "    free_gpu_memory(coarse_transformer)\n",
        "    free_gpu_memory(semantic_transformer)\n",
        "    del semantic_transformer, semantic_trainer\n",
        "except:\n",
        "  pass\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "bx3OGKzFECEa"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "03c5c35192a14cef8af9371388f83602",
            "b19a5a45243249938cba2d23d09ee494",
            "a3378fc8820642598d34dfe081e04cb9",
            "0a55105b36594142b78f6fde2db55e38",
            "58b69b72e9dd407389bc7b3ad43ac356",
            "c84d870a56544315a9b9cefac5ba829a",
            "22f48152a5cf4656a2b03ae69bc958ca",
            "9d74fa8b95484c7886575a93a366b9b6"
          ]
        },
        "id": "1LeWmaNHzzY9",
        "outputId": "20f64c09-834f-4891-f347-f9628bca05e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training with dataset of 3950 samples and validating with randomly splitted 208 samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:0ayng3f5) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03c5c35192a14cef8af9371388f83602"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▆▆▇▅▆▆▄▇▇▂▅▅▄▄▂▄▅▆▂▁▇▅▃▇▂▅▃▅▆▅▅▅▄▅▃▄█▄▆</td></tr><tr><td>lr</td><td>██████████▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▆▇▅▆▆▄▇▇▂▅▅▄▄▂▄▅▆▂▁▇▅▃▇▂▅▃▅▆▅▅▅▄▅▃▄█▄▆</td></tr><tr><td>valid_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>6.73926</td></tr><tr><td>lr</td><td>0.00107</td></tr><tr><td>train_loss</td><td>6.73926</td></tr><tr><td>valid_loss</td><td>6.82518</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">efficient-field-19</strong> at: <a href='https://wandb.ai/ols/coarse/runs/0ayng3f5' target=\"_blank\">https://wandb.ai/ols/coarse/runs/0ayng3f5</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230501_161625-0ayng3f5/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:0ayng3f5). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230501_164327-0s5jzzl6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ols/coarse/runs/0s5jzzl6' target=\"_blank\">laced-smoke-20</a></strong> to <a href='https://wandb.ai/ols/coarse' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ols/coarse' target=\"_blank\">https://wandb.ai/ols/coarse</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ols/coarse/runs/0s5jzzl6' target=\"_blank\">https://wandb.ai/ols/coarse/runs/0s5jzzl6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: loss: 88.29727172851562\n",
            "0: valid loss 116.65431213378906\n",
            "0: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1: loss: 118.74707794189453\n",
            "2: loss: 271.0717468261719\n",
            "3: loss: 92.91575622558594\n",
            "4: loss: 6.856545925140381\n",
            "5: loss: 6.819956302642822\n",
            "6: loss: 6.8548431396484375\n",
            "7: loss: 6.849978446960449\n",
            "8: loss: 6.858493328094482\n",
            "9: loss: 6.854159355163574\n",
            "10: loss: 6.839321136474609\n",
            "11: loss: 6.857316017150879\n",
            "12: loss: 6.852304935455322\n",
            "13: loss: 6.845803260803223\n",
            "14: loss: 6.828117847442627\n",
            "15: loss: 6.833473205566406\n",
            "16: loss: 6.837560653686523\n",
            "17: loss: 6.847071170806885\n",
            "18: loss: 6.842496871948242\n",
            "19: loss: 6.814000129699707\n",
            "20: loss: 6.829832553863525\n",
            "20: valid loss 6.842960834503174\n",
            "21: loss: 6.826789855957031\n",
            "22: loss: 6.8206915855407715\n",
            "23: loss: 6.839731693267822\n",
            "24: loss: 6.811281681060791\n",
            "25: loss: 6.822240829467773\n",
            "26: loss: 6.830132007598877\n",
            "27: loss: 6.83229398727417\n",
            "28: loss: 6.8827900886535645\n",
            "29: loss: 6.830297946929932\n",
            "30: loss: 6.859164237976074\n",
            "31: loss: 6.837863922119141\n",
            "32: loss: 6.82882833480835\n",
            "33: loss: 6.818244934082031\n",
            "34: loss: 6.8286027908325195\n",
            "35: loss: 6.817090034484863\n",
            "36: loss: 6.825463771820068\n",
            "37: loss: 6.815895080566406\n",
            "38: loss: 6.809627056121826\n",
            "39: loss: 6.832245349884033\n",
            "40: loss: 6.836520671844482\n",
            "40: valid loss 6.81951904296875\n",
            "41: loss: 6.815087795257568\n",
            "42: loss: 6.811925411224365\n",
            "43: loss: 6.800739765167236\n",
            "44: loss: 6.848878860473633\n",
            "45: loss: 6.813527584075928\n",
            "46: loss: 6.826347351074219\n",
            "47: loss: 6.8417744636535645\n",
            "48: loss: 6.84041690826416\n",
            "49: loss: 6.830750465393066\n",
            "50: loss: 6.810060977935791\n",
            "50: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "51: loss: 6.8279876708984375\n",
            "52: loss: 6.804778575897217\n",
            "53: loss: 6.801074028015137\n",
            "54: loss: 6.773504257202148\n",
            "55: loss: 6.802597999572754\n",
            "56: loss: 6.826570987701416\n",
            "57: loss: 6.8191351890563965\n",
            "58: loss: 6.791110515594482\n",
            "59: loss: 6.760689735412598\n",
            "60: loss: 6.84807825088501\n",
            "60: valid loss 6.81745719909668\n",
            "61: loss: 6.835179328918457\n",
            "62: loss: 6.817635536193848\n",
            "63: loss: 6.81902551651001\n",
            "64: loss: 6.845557689666748\n",
            "65: loss: 6.799557209014893\n",
            "66: loss: 6.861442565917969\n",
            "67: loss: 6.810070991516113\n",
            "68: loss: 6.789845943450928\n",
            "69: loss: 6.813299655914307\n",
            "70: loss: 6.789157867431641\n",
            "71: loss: 6.818886756896973\n",
            "72: loss: 6.817170143127441\n",
            "73: loss: 6.802889823913574\n",
            "74: loss: 6.8370280265808105\n",
            "75: loss: 6.795406341552734\n",
            "76: loss: 6.816583156585693\n",
            "77: loss: 6.849337100982666\n",
            "78: loss: 6.802199840545654\n",
            "79: loss: 6.796790599822998\n",
            "80: loss: 6.8342390060424805\n",
            "80: valid loss 6.820069313049316\n",
            "81: loss: 6.785871982574463\n",
            "82: loss: 6.809582710266113\n",
            "83: loss: 6.805929183959961\n",
            "84: loss: 6.838873386383057\n",
            "85: loss: 6.813855171203613\n",
            "86: loss: 6.808289527893066\n",
            "87: loss: 6.816825866699219\n",
            "88: loss: 6.812125205993652\n",
            "89: loss: 6.809858322143555\n",
            "90: loss: 6.804815769195557\n",
            "91: loss: 6.82033109664917\n",
            "92: loss: 6.785014629364014\n",
            "93: loss: 6.785623550415039\n",
            "94: loss: 6.81282377243042\n",
            "95: loss: 6.795381546020508\n",
            "96: loss: 6.81242036819458\n",
            "97: loss: 6.788638591766357\n",
            "98: loss: 6.789644241333008\n",
            "99: loss: 6.839064598083496\n",
            "100: loss: 6.76167106628418\n",
            "100: valid loss 6.791256427764893\n",
            "100: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "101: loss: 6.806239604949951\n",
            "102: loss: 6.821881294250488\n",
            "103: loss: 6.833168983459473\n",
            "104: loss: 6.802407264709473\n",
            "105: loss: 6.7961273193359375\n",
            "106: loss: 6.774631023406982\n",
            "107: loss: 6.805267333984375\n",
            "108: loss: 6.7980475425720215\n",
            "109: loss: 6.805793285369873\n",
            "110: loss: 6.7671217918396\n",
            "111: loss: 6.809332847595215\n",
            "112: loss: 6.777076244354248\n",
            "113: loss: 6.801304340362549\n",
            "114: loss: 6.798208236694336\n",
            "115: loss: 6.797979354858398\n",
            "116: loss: 6.811665058135986\n",
            "117: loss: 6.763192653656006\n",
            "118: loss: 6.794338703155518\n",
            "119: loss: 6.79519510269165\n",
            "120: loss: 6.776662826538086\n",
            "120: valid loss 6.80990743637085\n",
            "121: loss: 6.771738052368164\n",
            "122: loss: 6.743401527404785\n",
            "123: loss: 6.79019021987915\n",
            "124: loss: 6.788711071014404\n",
            "125: loss: 6.7965569496154785\n",
            "126: loss: 6.812652111053467\n",
            "127: loss: 6.780749320983887\n",
            "128: loss: 6.770939826965332\n",
            "129: loss: 6.777033805847168\n",
            "130: loss: 6.756420135498047\n",
            "131: loss: 6.759669303894043\n",
            "132: loss: 6.773590087890625\n",
            "133: loss: 6.767100811004639\n",
            "134: loss: 6.799289226531982\n",
            "135: loss: 6.798187732696533\n",
            "136: loss: 6.788610935211182\n",
            "137: loss: 6.763296127319336\n",
            "138: loss: 6.800512790679932\n",
            "139: loss: 6.781703472137451\n",
            "140: loss: 6.801842212677002\n",
            "140: valid loss 6.929569721221924\n",
            "141: loss: 6.782727241516113\n",
            "142: loss: 6.770963668823242\n",
            "143: loss: 6.788084983825684\n",
            "144: loss: 6.795923709869385\n",
            "145: loss: 6.8002471923828125\n",
            "146: loss: 6.761727333068848\n",
            "147: loss: 6.769223213195801\n",
            "148: loss: 6.7788591384887695\n",
            "149: loss: 6.806345462799072\n",
            "150: loss: 6.745248317718506\n",
            "150: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "151: loss: 6.783302307128906\n",
            "152: loss: 6.804826736450195\n",
            "153: loss: 6.826751708984375\n",
            "154: loss: 6.775453090667725\n",
            "155: loss: 6.745872974395752\n",
            "156: loss: 6.78648042678833\n",
            "157: loss: 6.772310733795166\n",
            "158: loss: 6.812263488769531\n",
            "159: loss: 6.7505059242248535\n",
            "160: loss: 6.738794326782227\n",
            "160: valid loss 6.775827884674072\n",
            "161: loss: 6.743444442749023\n",
            "162: loss: 6.801050186157227\n",
            "163: loss: 6.7811431884765625\n",
            "164: loss: 6.769955158233643\n",
            "165: loss: 6.7785420417785645\n",
            "166: loss: 6.7592620849609375\n",
            "167: loss: 6.7361226081848145\n",
            "168: loss: 6.790496826171875\n",
            "169: loss: 6.802787780761719\n",
            "170: loss: 6.787369251251221\n",
            "171: loss: 6.750219345092773\n",
            "172: loss: 6.765782833099365\n",
            "173: loss: 6.732387065887451\n",
            "174: loss: 6.786106586456299\n",
            "175: loss: 6.775310039520264\n",
            "176: loss: 6.713184356689453\n",
            "177: loss: 6.785132884979248\n",
            "178: loss: 6.76369047164917\n",
            "179: loss: 6.694504737854004\n",
            "180: loss: 6.797220706939697\n",
            "180: valid loss 6.764491081237793\n",
            "181: loss: 6.824944496154785\n",
            "182: loss: 6.736057281494141\n",
            "183: loss: 6.8274335861206055\n",
            "184: loss: 6.702991008758545\n",
            "185: loss: 6.749605178833008\n",
            "186: loss: 6.777602672576904\n",
            "187: loss: 6.827300071716309\n",
            "188: loss: 6.742807865142822\n",
            "189: loss: 6.774622440338135\n",
            "190: loss: 6.721215724945068\n",
            "191: loss: 6.789184093475342\n",
            "192: loss: 6.806616306304932\n",
            "193: loss: 6.747365474700928\n",
            "194: loss: 6.781886100769043\n",
            "195: loss: 6.7788848876953125\n",
            "196: loss: 6.828820705413818\n",
            "197: loss: 6.798612594604492\n",
            "198: loss: 6.784326076507568\n",
            "199: loss: 6.79872465133667\n",
            "200: loss: 6.83673095703125\n",
            "200: valid loss 6.793106555938721\n",
            "200: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "201: loss: 6.749596118927002\n",
            "202: loss: 6.818573474884033\n",
            "203: loss: 6.809326171875\n",
            "204: loss: 6.781970977783203\n",
            "205: loss: 6.743079662322998\n",
            "206: loss: 6.810512542724609\n",
            "207: loss: 6.725022792816162\n",
            "208: loss: 6.762515068054199\n",
            "209: loss: 6.790812015533447\n",
            "210: loss: 6.771382808685303\n",
            "211: loss: 6.771734714508057\n",
            "212: loss: 6.690719127655029\n",
            "213: loss: 6.831091403961182\n",
            "214: loss: 6.801049709320068\n",
            "215: loss: 6.794186115264893\n",
            "216: loss: 6.789855480194092\n",
            "217: loss: 6.855295658111572\n",
            "218: loss: 6.765490531921387\n",
            "219: loss: 6.781253337860107\n",
            "220: loss: 6.8143510818481445\n",
            "220: valid loss 6.732400417327881\n",
            "221: loss: 6.7759928703308105\n",
            "222: loss: 6.779653072357178\n",
            "223: loss: 6.819217681884766\n",
            "224: loss: 6.8071746826171875\n",
            "225: loss: 6.696572780609131\n",
            "226: loss: 6.775417327880859\n",
            "227: loss: 6.716021537780762\n",
            "228: loss: 6.7369914054870605\n",
            "229: loss: 6.796271324157715\n",
            "230: loss: 6.813068866729736\n",
            "231: loss: 6.770055294036865\n",
            "232: loss: 6.7806077003479\n",
            "233: loss: 6.7839674949646\n",
            "234: loss: 6.7350358963012695\n",
            "235: loss: 6.7810211181640625\n",
            "236: loss: 6.777445316314697\n",
            "237: loss: 6.8117594718933105\n",
            "238: loss: 6.763973236083984\n",
            "239: loss: 6.720654487609863\n",
            "240: loss: 6.789335250854492\n",
            "240: valid loss 6.812410354614258\n",
            "241: loss: 6.717592239379883\n",
            "242: loss: 6.7483601570129395\n",
            "243: loss: 6.798776149749756\n",
            "244: loss: 6.740312099456787\n",
            "245: loss: 6.744822978973389\n",
            "246: loss: 6.757564544677734\n",
            "247: loss: 6.725574016571045\n",
            "248: loss: 6.7543439865112305\n",
            "249: loss: 6.849812984466553\n",
            "250: loss: 6.80043888092041\n",
            "250: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "251: loss: 6.754392623901367\n",
            "252: loss: 6.766759395599365\n",
            "253: loss: 6.725289344787598\n",
            "254: loss: 6.724212169647217\n",
            "255: loss: 6.698456287384033\n",
            "256: loss: 6.756843090057373\n",
            "257: loss: 6.772809982299805\n",
            "258: loss: 6.785247325897217\n",
            "259: loss: 6.782505512237549\n",
            "260: loss: 6.724512100219727\n",
            "260: valid loss 6.78182315826416\n",
            "261: loss: 6.7495832443237305\n",
            "262: loss: 6.825896739959717\n",
            "263: loss: 6.787978649139404\n",
            "264: loss: 6.758572101593018\n",
            "265: loss: 6.803989887237549\n",
            "266: loss: 6.732205390930176\n",
            "267: loss: 6.842368125915527\n",
            "268: loss: 6.803577899932861\n",
            "269: loss: 6.749850749969482\n",
            "270: loss: 6.793907642364502\n",
            "271: loss: 6.8151044845581055\n",
            "272: loss: 6.744320869445801\n",
            "273: loss: 6.674895763397217\n",
            "274: loss: 6.7393412590026855\n",
            "275: loss: 6.823103904724121\n",
            "276: loss: 6.768436431884766\n",
            "277: loss: 6.848084926605225\n",
            "278: loss: 6.7823920249938965\n",
            "279: loss: 6.76724910736084\n",
            "280: loss: 6.763000011444092\n",
            "280: valid loss 6.80200719833374\n",
            "281: loss: 6.7145304679870605\n",
            "282: loss: 6.720822811126709\n",
            "283: loss: 6.784796237945557\n",
            "284: loss: 6.768304824829102\n",
            "285: loss: 6.753011226654053\n",
            "286: loss: 6.807835102081299\n",
            "287: loss: 6.786750316619873\n",
            "288: loss: 6.840327262878418\n",
            "289: loss: 6.762325286865234\n",
            "290: loss: 6.782412528991699\n",
            "291: loss: 6.770893573760986\n",
            "292: loss: 6.727853775024414\n",
            "293: loss: 6.7671589851379395\n",
            "294: loss: 6.7282562255859375\n",
            "295: loss: 6.829292297363281\n",
            "296: loss: 6.772167682647705\n",
            "297: loss: 6.828423023223877\n",
            "298: loss: 6.78178596496582\n",
            "299: loss: 6.813603401184082\n",
            "300: loss: 6.739989757537842\n",
            "300: valid loss 6.8420491218566895\n",
            "300: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "301: loss: 6.758420944213867\n",
            "302: loss: 6.8088059425354\n",
            "303: loss: 6.7604827880859375\n",
            "304: loss: 6.813559532165527\n",
            "305: loss: 6.816117286682129\n",
            "306: loss: 6.804871559143066\n",
            "307: loss: 6.716991424560547\n",
            "308: loss: 6.772159099578857\n",
            "309: loss: 6.789303779602051\n",
            "310: loss: 6.794450759887695\n",
            "311: loss: 6.719179153442383\n",
            "312: loss: 6.744594573974609\n",
            "313: loss: 6.758759021759033\n",
            "314: loss: 6.763937950134277\n",
            "315: loss: 6.810609817504883\n",
            "316: loss: 6.752732753753662\n",
            "317: loss: 6.761280536651611\n",
            "318: loss: 6.716043949127197\n",
            "319: loss: 6.7836689949035645\n",
            "320: loss: 6.75488805770874\n",
            "320: valid loss 6.713982582092285\n",
            "321: loss: 6.763852119445801\n",
            "322: loss: 6.738973140716553\n",
            "323: loss: 6.797045707702637\n",
            "324: loss: 6.775839805603027\n",
            "325: loss: 6.713361740112305\n",
            "326: loss: 6.777322292327881\n",
            "327: loss: 6.931665420532227\n",
            "328: loss: 6.753065586090088\n",
            "329: loss: 6.767846584320068\n",
            "330: loss: 6.848677635192871\n",
            "331: loss: 6.761813640594482\n",
            "332: loss: 6.827437877655029\n",
            "333: loss: 6.762781143188477\n",
            "334: loss: 6.721285820007324\n",
            "335: loss: 6.8241682052612305\n",
            "336: loss: 6.7792463302612305\n",
            "337: loss: 6.789059638977051\n",
            "338: loss: 6.759449005126953\n",
            "339: loss: 6.749300003051758\n",
            "340: loss: 6.690496921539307\n",
            "340: valid loss 6.788305282592773\n",
            "341: loss: 6.808948516845703\n",
            "342: loss: 6.764169692993164\n",
            "343: loss: 6.807080268859863\n",
            "344: loss: 6.774670600891113\n",
            "345: loss: 6.771732330322266\n",
            "346: loss: 6.807450771331787\n",
            "347: loss: 6.720546245574951\n",
            "348: loss: 6.808484077453613\n",
            "349: loss: 6.741484642028809\n",
            "350: loss: 6.749868392944336\n",
            "350: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "351: loss: 6.762578964233398\n",
            "352: loss: 6.695567607879639\n",
            "353: loss: 6.681497097015381\n",
            "354: loss: 6.8540568351745605\n",
            "355: loss: 6.790743827819824\n",
            "356: loss: 6.777047157287598\n",
            "357: loss: 6.726401329040527\n",
            "358: loss: 6.785311222076416\n",
            "359: loss: 6.761767387390137\n",
            "360: loss: 6.796842098236084\n",
            "360: valid loss 6.809607028961182\n",
            "361: loss: 6.676669120788574\n",
            "362: loss: 6.779559135437012\n",
            "363: loss: 6.721002101898193\n",
            "364: loss: 6.720982074737549\n",
            "365: loss: 6.789243698120117\n",
            "366: loss: 6.782870769500732\n",
            "367: loss: 6.648472309112549\n",
            "368: loss: 6.735873699188232\n",
            "369: loss: 6.788509845733643\n",
            "370: loss: 6.755460739135742\n",
            "371: loss: 6.805400848388672\n",
            "372: loss: 6.7086663246154785\n",
            "373: loss: 6.809475421905518\n",
            "374: loss: 6.713079929351807\n",
            "375: loss: 6.784736633300781\n",
            "376: loss: 6.779221057891846\n",
            "377: loss: 6.768215179443359\n",
            "378: loss: 6.7271928787231445\n",
            "379: loss: 6.783304214477539\n",
            "380: loss: 6.712287425994873\n",
            "380: valid loss 6.810882091522217\n",
            "381: loss: 6.7335896492004395\n",
            "382: loss: 6.754987716674805\n",
            "383: loss: 6.8042707443237305\n",
            "384: loss: 6.7689337730407715\n",
            "385: loss: 6.710399150848389\n",
            "386: loss: 6.772120952606201\n",
            "387: loss: 6.677418231964111\n",
            "388: loss: 6.707026481628418\n",
            "389: loss: 6.717606544494629\n",
            "390: loss: 6.756597518920898\n",
            "391: loss: 6.756742000579834\n",
            "392: loss: 6.731245517730713\n",
            "393: loss: 6.765163898468018\n",
            "394: loss: 6.706802845001221\n",
            "395: loss: 6.693880558013916\n",
            "396: loss: 6.7227091789245605\n",
            "397: loss: 6.710061073303223\n",
            "398: loss: 6.780799388885498\n",
            "399: loss: 6.770240783691406\n",
            "400: loss: 6.786201477050781\n",
            "400: valid loss 6.797870635986328\n",
            "400: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "401: loss: 6.695732593536377\n",
            "402: loss: 6.781823635101318\n",
            "403: loss: 6.704738616943359\n",
            "404: loss: 6.734980583190918\n",
            "405: loss: 6.700751304626465\n",
            "406: loss: 6.7093987464904785\n",
            "407: loss: 6.655907154083252\n",
            "408: loss: 6.657166481018066\n",
            "409: loss: 6.765240669250488\n",
            "410: loss: 6.7477545738220215\n",
            "411: loss: 6.725192070007324\n",
            "412: loss: 6.792418956756592\n",
            "413: loss: 6.7482500076293945\n",
            "414: loss: 6.745854377746582\n",
            "415: loss: 6.743305683135986\n",
            "416: loss: 6.753470420837402\n",
            "417: loss: 6.777985572814941\n",
            "418: loss: 6.676577568054199\n",
            "419: loss: 6.78415060043335\n",
            "420: loss: 6.725657939910889\n",
            "420: valid loss 6.786337852478027\n",
            "421: loss: 6.723884105682373\n",
            "422: loss: 6.812567234039307\n",
            "423: loss: 6.706751823425293\n",
            "424: loss: 6.768002510070801\n",
            "425: loss: 6.707275390625\n",
            "426: loss: 6.703648090362549\n",
            "427: loss: 6.810803413391113\n",
            "428: loss: 6.773615837097168\n",
            "429: loss: 6.760558605194092\n",
            "430: loss: 6.726794719696045\n",
            "431: loss: 6.725212097167969\n",
            "432: loss: 6.7450480461120605\n",
            "433: loss: 6.757864475250244\n",
            "434: loss: 6.700267791748047\n",
            "435: loss: 6.776732444763184\n",
            "436: loss: 6.810166358947754\n",
            "437: loss: 6.765594005584717\n",
            "438: loss: 6.804533004760742\n",
            "439: loss: 6.763436794281006\n",
            "440: loss: 6.765708923339844\n",
            "440: valid loss 6.774936676025391\n",
            "441: loss: 6.729166507720947\n",
            "442: loss: 6.778799057006836\n",
            "443: loss: 6.751236915588379\n",
            "444: loss: 6.810740947723389\n",
            "445: loss: 6.8048930168151855\n",
            "446: loss: 6.737475395202637\n",
            "447: loss: 6.760022163391113\n",
            "448: loss: 6.778627872467041\n",
            "449: loss: 6.788982391357422\n",
            "450: loss: 6.792430877685547\n",
            "450: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "451: loss: 6.794824600219727\n",
            "452: loss: 6.819341659545898\n",
            "453: loss: 6.825599670410156\n",
            "454: loss: 6.739633560180664\n",
            "455: loss: 6.777573585510254\n",
            "456: loss: 6.825915813446045\n",
            "457: loss: 6.795774936676025\n",
            "458: loss: 6.711318492889404\n",
            "459: loss: 6.775332927703857\n",
            "460: loss: 6.783027648925781\n",
            "460: valid loss 6.807511329650879\n",
            "461: loss: 6.6521477699279785\n",
            "462: loss: 6.644449710845947\n",
            "463: loss: 6.746616363525391\n",
            "464: loss: 6.82075309753418\n",
            "465: loss: 6.667962551116943\n",
            "466: loss: 6.747921466827393\n",
            "467: loss: 6.762197017669678\n",
            "468: loss: 6.772597312927246\n",
            "469: loss: 6.609882354736328\n",
            "470: loss: 6.723860263824463\n",
            "471: loss: 6.726245880126953\n",
            "472: loss: 6.749763011932373\n",
            "473: loss: 6.753340721130371\n",
            "474: loss: 6.779784202575684\n",
            "475: loss: 6.7999348640441895\n",
            "476: loss: 6.773933410644531\n",
            "477: loss: 6.731919765472412\n",
            "478: loss: 6.749684810638428\n",
            "479: loss: 6.794270992279053\n",
            "480: loss: 6.723055362701416\n",
            "480: valid loss 6.698063850402832\n",
            "481: loss: 6.794604778289795\n",
            "482: loss: 6.791795253753662\n",
            "483: loss: 6.762211322784424\n",
            "484: loss: 6.668181419372559\n",
            "485: loss: 6.791936874389648\n",
            "486: loss: 6.79953670501709\n",
            "487: loss: 6.788728713989258\n",
            "488: loss: 6.745544910430908\n",
            "489: loss: 6.725973129272461\n",
            "490: loss: 6.7886128425598145\n",
            "491: loss: 6.7449049949646\n",
            "492: loss: 6.80482816696167\n",
            "493: loss: 6.732826232910156\n",
            "494: loss: 6.7892069816589355\n",
            "495: loss: 6.770127296447754\n",
            "496: loss: 6.755352973937988\n",
            "497: loss: 6.830605506896973\n",
            "498: loss: 6.763533115386963\n",
            "499: loss: 6.763956546783447\n",
            "500: loss: 6.748825550079346\n",
            "500: valid loss 6.779434680938721\n",
            "500: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "501: loss: 6.847079753875732\n",
            "502: loss: 6.765018939971924\n",
            "503: loss: 6.718844413757324\n",
            "504: loss: 6.769978046417236\n",
            "505: loss: 6.6793694496154785\n",
            "506: loss: 6.762506008148193\n",
            "507: loss: 6.696234226226807\n",
            "508: loss: 6.836606025695801\n",
            "509: loss: 6.740667343139648\n",
            "510: loss: 6.772963523864746\n",
            "511: loss: 6.7496747970581055\n",
            "512: loss: 6.789639949798584\n",
            "513: loss: 6.741486549377441\n",
            "514: loss: 6.678506851196289\n",
            "515: loss: 6.717601299285889\n",
            "516: loss: 6.7483673095703125\n",
            "517: loss: 6.646748065948486\n",
            "518: loss: 6.753096580505371\n",
            "519: loss: 6.697054386138916\n",
            "520: loss: 6.7232465744018555\n",
            "520: valid loss 6.7996320724487305\n",
            "521: loss: 6.824004173278809\n",
            "522: loss: 6.7655510902404785\n",
            "523: loss: 6.786593914031982\n",
            "524: loss: 6.698461532592773\n",
            "525: loss: 6.708424091339111\n",
            "526: loss: 6.851940155029297\n",
            "527: loss: 6.699239253997803\n",
            "528: loss: 6.695590019226074\n",
            "529: loss: 6.739976406097412\n",
            "530: loss: 6.726737976074219\n",
            "531: loss: 6.742488384246826\n",
            "532: loss: 6.7975921630859375\n",
            "533: loss: 6.75520133972168\n",
            "534: loss: 6.709586143493652\n",
            "535: loss: 6.744262218475342\n",
            "536: loss: 6.768312931060791\n",
            "537: loss: 6.711824417114258\n",
            "538: loss: 6.827467918395996\n",
            "539: loss: 6.752451419830322\n",
            "540: loss: 6.725874423980713\n",
            "540: valid loss 6.73157262802124\n",
            "541: loss: 6.744637489318848\n",
            "542: loss: 6.6455888748168945\n",
            "543: loss: 6.745091438293457\n",
            "544: loss: 6.797924041748047\n",
            "545: loss: 6.747335910797119\n",
            "546: loss: 6.694918155670166\n",
            "547: loss: 6.682186126708984\n",
            "548: loss: 6.734852313995361\n",
            "549: loss: 6.794840335845947\n",
            "550: loss: 6.675914764404297\n",
            "550: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "551: loss: 6.690790176391602\n",
            "552: loss: 6.750767707824707\n",
            "553: loss: 6.683732986450195\n",
            "554: loss: 6.772324085235596\n",
            "555: loss: 6.681185722351074\n",
            "556: loss: 6.727213382720947\n",
            "557: loss: 6.709476470947266\n",
            "558: loss: 6.713644027709961\n",
            "559: loss: 6.733151435852051\n",
            "560: loss: 6.69091272354126\n",
            "560: valid loss 6.737038612365723\n",
            "561: loss: 6.726652145385742\n",
            "562: loss: 6.717695713043213\n",
            "563: loss: 6.730463981628418\n",
            "564: loss: 6.7146077156066895\n",
            "565: loss: 6.7989091873168945\n",
            "566: loss: 6.785762786865234\n",
            "567: loss: 6.742339134216309\n",
            "568: loss: 6.769259929656982\n",
            "569: loss: 6.762990951538086\n",
            "570: loss: 6.704315185546875\n",
            "571: loss: 6.748715877532959\n",
            "572: loss: 6.8402605056762695\n",
            "573: loss: 6.761134147644043\n",
            "574: loss: 6.76915168762207\n",
            "575: loss: 6.769866466522217\n",
            "576: loss: 6.809491157531738\n",
            "577: loss: 6.649728298187256\n",
            "578: loss: 6.798495292663574\n",
            "579: loss: 6.7719550132751465\n",
            "580: loss: 6.742664337158203\n",
            "580: valid loss 6.7620463371276855\n",
            "581: loss: 6.8332600593566895\n",
            "582: loss: 6.738460540771484\n",
            "583: loss: 6.785689353942871\n",
            "584: loss: 6.685965538024902\n",
            "585: loss: 6.766320705413818\n",
            "586: loss: 6.686833381652832\n",
            "587: loss: 6.819222450256348\n",
            "588: loss: 6.725733757019043\n",
            "589: loss: 6.723837375640869\n",
            "590: loss: 6.7696967124938965\n",
            "591: loss: 6.771471977233887\n",
            "592: loss: 6.763223171234131\n",
            "593: loss: 6.691032409667969\n",
            "594: loss: 6.780454158782959\n",
            "595: loss: 6.797013759613037\n",
            "596: loss: 6.831168174743652\n",
            "597: loss: 6.724985122680664\n",
            "598: loss: 6.748245716094971\n",
            "599: loss: 6.655819416046143\n",
            "600: loss: 6.759505748748779\n",
            "600: valid loss 6.7647857666015625\n",
            "600: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "601: loss: 6.8130998611450195\n",
            "602: loss: 6.700948238372803\n",
            "603: loss: 6.690460205078125\n",
            "604: loss: 6.69809103012085\n",
            "605: loss: 6.775122165679932\n",
            "606: loss: 6.7664289474487305\n",
            "607: loss: 6.778260707855225\n",
            "608: loss: 6.6914825439453125\n",
            "609: loss: 6.793913841247559\n",
            "610: loss: 6.803714752197266\n",
            "611: loss: 6.696686267852783\n",
            "612: loss: 6.725287914276123\n",
            "613: loss: 6.7151875495910645\n",
            "614: loss: 6.772270202636719\n",
            "615: loss: 6.801531791687012\n",
            "616: loss: 6.7232584953308105\n",
            "617: loss: 6.775373458862305\n",
            "618: loss: 6.7491888999938965\n",
            "619: loss: 6.7429890632629395\n",
            "620: loss: 6.692352771759033\n",
            "620: valid loss 6.783698558807373\n",
            "621: loss: 6.7626214027404785\n",
            "622: loss: 6.777993202209473\n",
            "623: loss: 6.73521614074707\n",
            "624: loss: 6.748374938964844\n",
            "625: loss: 6.805446147918701\n",
            "626: loss: 6.669406890869141\n",
            "627: loss: 6.7577128410339355\n",
            "628: loss: 6.723771095275879\n",
            "629: loss: 6.704080104827881\n",
            "630: loss: 6.783195495605469\n",
            "631: loss: 6.785589218139648\n",
            "632: loss: 6.706381320953369\n",
            "633: loss: 6.780766487121582\n",
            "634: loss: 6.79780912399292\n",
            "635: loss: 6.721309185028076\n",
            "636: loss: 6.767046928405762\n",
            "637: loss: 6.761051177978516\n",
            "638: loss: 6.761288642883301\n",
            "639: loss: 6.702376842498779\n",
            "640: loss: 6.676636695861816\n",
            "640: valid loss 6.773701190948486\n",
            "641: loss: 6.795123100280762\n",
            "642: loss: 6.712368488311768\n",
            "643: loss: 6.777041912078857\n",
            "644: loss: 6.847799301147461\n",
            "645: loss: 6.762662887573242\n",
            "646: loss: 6.676769256591797\n",
            "647: loss: 6.690166473388672\n",
            "648: loss: 6.788295745849609\n",
            "649: loss: 6.646568775177002\n",
            "650: loss: 6.806788444519043\n",
            "650: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "651: loss: 6.763540744781494\n",
            "652: loss: 6.698888778686523\n",
            "653: loss: 6.772465229034424\n",
            "654: loss: 6.807303428649902\n",
            "655: loss: 6.786069869995117\n",
            "656: loss: 6.78835916519165\n",
            "657: loss: 6.753758907318115\n",
            "658: loss: 6.774470806121826\n",
            "659: loss: 6.7137274742126465\n",
            "660: loss: 6.733973979949951\n",
            "660: valid loss 6.695991039276123\n",
            "661: loss: 6.760831356048584\n",
            "662: loss: 6.77824592590332\n",
            "663: loss: 6.73125696182251\n",
            "664: loss: 6.735202789306641\n",
            "665: loss: 6.922365188598633\n",
            "666: loss: 6.828458309173584\n",
            "667: loss: 6.789285182952881\n",
            "668: loss: 6.77972936630249\n",
            "669: loss: 6.730851173400879\n",
            "670: loss: 6.660123348236084\n",
            "Epoch 00671: reducing learning rate of group 0 to 7.0000e-03.\n",
            "671: loss: 6.706423759460449\n",
            "672: loss: 6.748148441314697\n",
            "673: loss: 6.714620113372803\n",
            "674: loss: 6.732426166534424\n",
            "675: loss: 6.746281147003174\n",
            "676: loss: 6.7518486976623535\n",
            "677: loss: 6.792110443115234\n",
            "678: loss: 6.758233070373535\n",
            "679: loss: 6.789463043212891\n",
            "680: loss: 6.793198108673096\n",
            "680: valid loss 6.726896286010742\n",
            "681: loss: 6.832466125488281\n",
            "682: loss: 6.7461771965026855\n",
            "683: loss: 6.815138339996338\n",
            "684: loss: 6.759355545043945\n",
            "685: loss: 6.761211395263672\n",
            "686: loss: 6.806458950042725\n",
            "687: loss: 6.818881034851074\n",
            "688: loss: 6.7689290046691895\n",
            "689: loss: 6.7480854988098145\n",
            "690: loss: 6.735191822052002\n",
            "691: loss: 6.824390888214111\n",
            "692: loss: 6.790555477142334\n",
            "693: loss: 6.77817440032959\n",
            "694: loss: 6.635876178741455\n",
            "695: loss: 6.777092933654785\n",
            "696: loss: 6.782617092132568\n",
            "697: loss: 6.808891296386719\n",
            "698: loss: 6.759400367736816\n",
            "699: loss: 6.695666313171387\n",
            "700: loss: 6.726858139038086\n",
            "700: valid loss 6.812732696533203\n",
            "700: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "701: loss: 6.834500312805176\n",
            "702: loss: 6.707785129547119\n",
            "703: loss: 6.732422828674316\n",
            "704: loss: 6.839801788330078\n",
            "705: loss: 6.773833751678467\n",
            "706: loss: 6.8012895584106445\n",
            "707: loss: 6.792805194854736\n",
            "708: loss: 6.746333599090576\n",
            "709: loss: 6.845208644866943\n",
            "710: loss: 6.801151752471924\n",
            "711: loss: 6.720100402832031\n",
            "712: loss: 6.752551555633545\n",
            "713: loss: 6.757791996002197\n",
            "714: loss: 6.635913848876953\n",
            "715: loss: 6.760213375091553\n",
            "716: loss: 6.750933647155762\n",
            "717: loss: 6.787428855895996\n",
            "718: loss: 6.711490631103516\n",
            "719: loss: 6.719435691833496\n",
            "720: loss: 6.795200347900391\n",
            "720: valid loss 6.768198013305664\n",
            "721: loss: 6.731713771820068\n",
            "722: loss: 6.728757381439209\n",
            "723: loss: 6.730382442474365\n",
            "724: loss: 6.718544006347656\n",
            "725: loss: 6.788274765014648\n",
            "726: loss: 6.8491034507751465\n",
            "727: loss: 6.735238552093506\n",
            "728: loss: 6.736462593078613\n",
            "729: loss: 6.834936618804932\n",
            "730: loss: 6.7762451171875\n",
            "731: loss: 6.805643558502197\n",
            "732: loss: 6.736662864685059\n",
            "733: loss: 6.740930557250977\n",
            "734: loss: 6.719873905181885\n",
            "735: loss: 6.775713920593262\n",
            "736: loss: 6.789311408996582\n",
            "737: loss: 6.710677623748779\n",
            "738: loss: 6.752995491027832\n",
            "739: loss: 6.833474159240723\n",
            "740: loss: 6.706062316894531\n",
            "740: valid loss 6.787935256958008\n",
            "741: loss: 6.809410095214844\n",
            "742: loss: 6.7569169998168945\n",
            "743: loss: 6.766249656677246\n",
            "744: loss: 6.770495414733887\n",
            "745: loss: 6.778247356414795\n",
            "746: loss: 6.776659965515137\n",
            "747: loss: 6.723236560821533\n",
            "748: loss: 6.6943840980529785\n",
            "749: loss: 6.796408176422119\n",
            "750: loss: 6.743934154510498\n",
            "750: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "751: loss: 6.807819366455078\n",
            "752: loss: 6.728390693664551\n",
            "753: loss: 6.747084140777588\n",
            "754: loss: 6.6567535400390625\n",
            "755: loss: 6.787789344787598\n",
            "756: loss: 6.782112121582031\n",
            "757: loss: 6.709450721740723\n",
            "758: loss: 6.789576530456543\n",
            "759: loss: 6.756228446960449\n",
            "760: loss: 6.72507905960083\n",
            "760: valid loss 6.664336204528809\n",
            "761: loss: 6.715109348297119\n",
            "762: loss: 6.710386276245117\n",
            "763: loss: 6.7900261878967285\n",
            "764: loss: 6.719881057739258\n",
            "765: loss: 6.780226230621338\n",
            "766: loss: 6.730251312255859\n",
            "767: loss: 6.731163024902344\n",
            "768: loss: 6.670287132263184\n",
            "769: loss: 6.816470146179199\n",
            "770: loss: 6.6788859367370605\n",
            "771: loss: 6.70121431350708\n",
            "772: loss: 6.856893539428711\n",
            "773: loss: 6.766562461853027\n",
            "774: loss: 6.77402925491333\n",
            "775: loss: 6.7807135581970215\n",
            "776: loss: 6.711775302886963\n",
            "777: loss: 6.731043815612793\n",
            "778: loss: 6.730391979217529\n",
            "779: loss: 6.734311103820801\n",
            "780: loss: 6.737445831298828\n",
            "780: valid loss 6.776072978973389\n",
            "781: loss: 6.791612148284912\n",
            "782: loss: 6.789984226226807\n",
            "783: loss: 6.743091583251953\n",
            "784: loss: 6.7841057777404785\n",
            "785: loss: 6.645244121551514\n",
            "786: loss: 6.756453037261963\n",
            "787: loss: 6.7457709312438965\n",
            "788: loss: 6.751848220825195\n",
            "789: loss: 6.6403374671936035\n",
            "790: loss: 6.751613616943359\n",
            "791: loss: 6.7909064292907715\n",
            "792: loss: 6.675464153289795\n",
            "793: loss: 6.804883003234863\n",
            "794: loss: 6.7735209465026855\n",
            "795: loss: 6.7958269119262695\n",
            "796: loss: 6.732902526855469\n",
            "797: loss: 6.831246852874756\n",
            "798: loss: 6.823044300079346\n",
            "799: loss: 6.78412389755249\n",
            "800: loss: 6.747384548187256\n",
            "800: valid loss 6.739930629730225\n",
            "800: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "801: loss: 6.741406440734863\n",
            "802: loss: 6.7806806564331055\n",
            "803: loss: 6.815164089202881\n",
            "804: loss: 6.66055154800415\n",
            "805: loss: 6.753225803375244\n",
            "806: loss: 6.772233009338379\n",
            "807: loss: 6.733057975769043\n",
            "808: loss: 6.746997356414795\n",
            "809: loss: 6.8544697761535645\n",
            "810: loss: 6.6891913414001465\n",
            "811: loss: 6.779922008514404\n",
            "812: loss: 6.804609775543213\n",
            "813: loss: 6.831893444061279\n",
            "814: loss: 6.714326858520508\n",
            "815: loss: 6.789797306060791\n",
            "816: loss: 6.739387035369873\n",
            "817: loss: 6.756370544433594\n",
            "818: loss: 6.787722587585449\n",
            "819: loss: 6.725208282470703\n",
            "820: loss: 6.803904056549072\n",
            "820: valid loss 6.705883502960205\n",
            "821: loss: 6.860604286193848\n",
            "822: loss: 6.777237415313721\n",
            "823: loss: 6.673009395599365\n",
            "824: loss: 6.736564636230469\n",
            "825: loss: 6.827220439910889\n",
            "826: loss: 6.785589694976807\n",
            "827: loss: 6.839205265045166\n",
            "828: loss: 6.7723917961120605\n",
            "829: loss: 6.686139106750488\n",
            "830: loss: 6.778338432312012\n",
            "831: loss: 6.761525630950928\n",
            "832: loss: 6.795018196105957\n",
            "833: loss: 6.675317287445068\n",
            "834: loss: 6.7763261795043945\n",
            "835: loss: 6.6976189613342285\n",
            "836: loss: 6.815594673156738\n",
            "837: loss: 6.716919898986816\n",
            "838: loss: 6.7610015869140625\n",
            "839: loss: 6.6847052574157715\n",
            "840: loss: 6.669117450714111\n",
            "840: valid loss 6.818547248840332\n",
            "841: loss: 6.772810459136963\n",
            "842: loss: 6.830644130706787\n",
            "843: loss: 6.75657844543457\n",
            "844: loss: 6.802744388580322\n",
            "845: loss: 6.721983432769775\n",
            "846: loss: 6.762254238128662\n",
            "847: loss: 6.83350133895874\n",
            "848: loss: 6.804024696350098\n",
            "849: loss: 6.732702732086182\n",
            "850: loss: 6.756375312805176\n",
            "850: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "851: loss: 6.777411937713623\n",
            "852: loss: 6.782081604003906\n",
            "853: loss: 6.7683539390563965\n",
            "854: loss: 6.8278703689575195\n",
            "855: loss: 6.775382995605469\n",
            "856: loss: 6.820216178894043\n",
            "857: loss: 6.762988567352295\n",
            "858: loss: 6.766592979431152\n",
            "859: loss: 6.780786037445068\n",
            "860: loss: 6.68233585357666\n",
            "860: valid loss 6.830629348754883\n",
            "861: loss: 6.845713138580322\n",
            "862: loss: 6.7289347648620605\n",
            "863: loss: 6.789165496826172\n",
            "864: loss: 6.746714115142822\n",
            "865: loss: 6.803709506988525\n",
            "866: loss: 6.806723117828369\n",
            "867: loss: 6.750243663787842\n",
            "868: loss: 6.770619869232178\n",
            "869: loss: 6.745879173278809\n",
            "870: loss: 6.736300945281982\n",
            "871: loss: 6.740121364593506\n",
            "872: loss: 6.777214527130127\n",
            "873: loss: 6.770316123962402\n",
            "874: loss: 6.74473237991333\n",
            "875: loss: 6.793116092681885\n",
            "876: loss: 6.786635875701904\n",
            "877: loss: 6.831765651702881\n",
            "878: loss: 6.731176376342773\n",
            "879: loss: 6.812244892120361\n",
            "880: loss: 6.708584785461426\n",
            "880: valid loss 6.789375305175781\n",
            "881: loss: 6.734199047088623\n",
            "882: loss: 6.768640518188477\n",
            "883: loss: 6.7946929931640625\n",
            "884: loss: 6.636744499206543\n",
            "885: loss: 6.757411003112793\n",
            "886: loss: 6.799351215362549\n",
            "887: loss: 6.683277130126953\n",
            "888: loss: 6.722132682800293\n",
            "889: loss: 6.751220226287842\n",
            "890: loss: 6.743170738220215\n",
            "891: loss: 6.82163667678833\n",
            "892: loss: 6.7650532722473145\n",
            "893: loss: 6.734259605407715\n",
            "894: loss: 6.77289342880249\n",
            "895: loss: 6.792395114898682\n",
            "896: loss: 6.7198381423950195\n",
            "897: loss: 6.7295989990234375\n",
            "898: loss: 6.73433780670166\n",
            "899: loss: 6.690924167633057\n",
            "900: loss: 6.777942657470703\n",
            "900: valid loss 6.810580253601074\n",
            "900: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "901: loss: 6.755299091339111\n",
            "902: loss: 6.821861743927002\n",
            "903: loss: 6.702683448791504\n",
            "904: loss: 6.694835186004639\n",
            "905: loss: 6.739131450653076\n",
            "906: loss: 6.7242512702941895\n",
            "907: loss: 6.7917561531066895\n",
            "908: loss: 6.753584384918213\n",
            "909: loss: 6.773030757904053\n",
            "910: loss: 6.693232536315918\n",
            "911: loss: 6.7793755531311035\n",
            "912: loss: 6.728365898132324\n",
            "913: loss: 6.719588756561279\n",
            "914: loss: 6.718306541442871\n",
            "915: loss: 6.777107238769531\n",
            "916: loss: 6.670846462249756\n",
            "917: loss: 6.719995021820068\n",
            "918: loss: 6.781968116760254\n",
            "919: loss: 6.638770580291748\n",
            "920: loss: 6.800851345062256\n",
            "920: valid loss 6.765537261962891\n",
            "921: loss: 6.6261138916015625\n",
            "922: loss: 6.833062648773193\n",
            "923: loss: 6.778179168701172\n",
            "924: loss: 6.707925796508789\n",
            "925: loss: 6.688167095184326\n",
            "926: loss: 6.722896575927734\n",
            "927: loss: 6.766612529754639\n",
            "928: loss: 6.746193885803223\n",
            "929: loss: 6.759479999542236\n",
            "930: loss: 6.7319655418396\n",
            "931: loss: 6.74432897567749\n",
            "932: loss: 6.866057872772217\n",
            "933: loss: 6.748828887939453\n",
            "934: loss: 6.759232521057129\n",
            "935: loss: 6.806427001953125\n",
            "936: loss: 6.696838855743408\n",
            "937: loss: 6.6249895095825195\n",
            "938: loss: 6.755687713623047\n",
            "939: loss: 6.835274696350098\n",
            "940: loss: 6.73649787902832\n",
            "940: valid loss 6.60548210144043\n",
            "941: loss: 6.644155502319336\n",
            "942: loss: 6.697357177734375\n",
            "943: loss: 6.764527797698975\n",
            "944: loss: 6.766808032989502\n",
            "945: loss: 6.721814155578613\n",
            "946: loss: 6.749183177947998\n",
            "947: loss: 6.765336036682129\n",
            "948: loss: 6.768197059631348\n",
            "949: loss: 6.767922401428223\n",
            "950: loss: 6.735193252563477\n",
            "950: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "951: loss: 6.791011333465576\n",
            "952: loss: 6.794064521789551\n",
            "953: loss: 6.7976837158203125\n",
            "954: loss: 6.781499862670898\n",
            "955: loss: 6.704588890075684\n",
            "956: loss: 6.750530242919922\n",
            "957: loss: 6.813586711883545\n",
            "958: loss: 6.7154998779296875\n",
            "959: loss: 6.748532772064209\n",
            "960: loss: 6.726130962371826\n",
            "960: valid loss 6.679385662078857\n",
            "961: loss: 6.865072727203369\n",
            "962: loss: 6.701603412628174\n",
            "963: loss: 6.765097141265869\n",
            "964: loss: 6.744034290313721\n",
            "965: loss: 6.729858875274658\n",
            "966: loss: 6.7307939529418945\n",
            "967: loss: 6.777270793914795\n",
            "968: loss: 6.698739528656006\n",
            "969: loss: 6.76133394241333\n",
            "970: loss: 6.841278553009033\n",
            "971: loss: 6.825638294219971\n",
            "Epoch 00972: reducing learning rate of group 0 to 4.9000e-03.\n",
            "972: loss: 6.741533279418945\n",
            "973: loss: 6.788600444793701\n",
            "974: loss: 6.768190860748291\n",
            "975: loss: 6.795071125030518\n",
            "976: loss: 6.698024749755859\n",
            "977: loss: 6.757626056671143\n",
            "978: loss: 6.806173324584961\n",
            "979: loss: 6.7812066078186035\n",
            "980: loss: 6.833190441131592\n",
            "980: valid loss 6.710286617279053\n",
            "981: loss: 6.747249126434326\n",
            "982: loss: 6.69140100479126\n",
            "983: loss: 6.738447189331055\n",
            "984: loss: 6.772093296051025\n",
            "985: loss: 6.7602949142456055\n",
            "986: loss: 6.730887413024902\n",
            "987: loss: 6.7521162033081055\n",
            "988: loss: 6.749929904937744\n",
            "989: loss: 6.763267517089844\n",
            "990: loss: 6.750866889953613\n",
            "991: loss: 6.739174842834473\n",
            "992: loss: 6.726200103759766\n",
            "993: loss: 6.787207126617432\n",
            "994: loss: 6.718452453613281\n",
            "995: loss: 6.770161151885986\n",
            "996: loss: 6.80203914642334\n",
            "997: loss: 6.797364234924316\n",
            "998: loss: 6.760064125061035\n",
            "999: loss: 6.807601451873779\n",
            "1000: loss: 6.691522598266602\n",
            "1000: valid loss 6.879809856414795\n",
            "1000: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1001: loss: 6.791728973388672\n",
            "1002: loss: 6.789884090423584\n",
            "1003: loss: 6.841154098510742\n",
            "1004: loss: 6.750121116638184\n",
            "1005: loss: 6.784440517425537\n",
            "1006: loss: 6.769372940063477\n",
            "1007: loss: 6.846390247344971\n",
            "1008: loss: 6.769034385681152\n",
            "1009: loss: 6.8222784996032715\n",
            "1010: loss: 6.787032604217529\n",
            "1011: loss: 6.7561564445495605\n",
            "1012: loss: 6.755943775177002\n",
            "1013: loss: 6.733702659606934\n",
            "1014: loss: 6.676248073577881\n",
            "1015: loss: 6.733368396759033\n",
            "1016: loss: 6.776748180389404\n",
            "1017: loss: 6.790137767791748\n",
            "1018: loss: 6.7650604248046875\n",
            "1019: loss: 6.718697547912598\n",
            "1020: loss: 6.760921478271484\n",
            "1020: valid loss 6.802986145019531\n",
            "1021: loss: 6.736777305603027\n",
            "1022: loss: 6.738284111022949\n",
            "1023: loss: 6.740792751312256\n",
            "1024: loss: 6.694194316864014\n",
            "1025: loss: 6.711839199066162\n",
            "1026: loss: 6.7931227684021\n",
            "1027: loss: 6.739645004272461\n",
            "1028: loss: 6.871208667755127\n",
            "1029: loss: 6.724725723266602\n",
            "1030: loss: 6.702456474304199\n",
            "1031: loss: 6.714320182800293\n",
            "1032: loss: 6.870755672454834\n",
            "1033: loss: 6.784440517425537\n",
            "1034: loss: 6.759127616882324\n",
            "1035: loss: 6.736385822296143\n",
            "1036: loss: 6.788854598999023\n",
            "1037: loss: 6.869978427886963\n",
            "1038: loss: 6.696126937866211\n",
            "1039: loss: 6.728605270385742\n",
            "1040: loss: 6.713771343231201\n",
            "1040: valid loss 6.811105251312256\n",
            "1041: loss: 6.787630081176758\n",
            "1042: loss: 6.740814685821533\n",
            "1043: loss: 6.815611839294434\n",
            "1044: loss: 6.766577243804932\n",
            "1045: loss: 6.81679105758667\n",
            "1046: loss: 6.861230850219727\n",
            "1047: loss: 6.762983322143555\n",
            "1048: loss: 6.7285637855529785\n",
            "1049: loss: 6.783815860748291\n",
            "1050: loss: 6.7713494300842285\n",
            "1050: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1051: loss: 6.777059555053711\n",
            "1052: loss: 6.760526180267334\n",
            "1053: loss: 6.66816520690918\n",
            "1054: loss: 6.853041648864746\n",
            "1055: loss: 6.709958553314209\n",
            "1056: loss: 6.752011775970459\n",
            "1057: loss: 6.727540493011475\n",
            "1058: loss: 6.741111755371094\n",
            "1059: loss: 6.811963081359863\n",
            "1060: loss: 6.7666192054748535\n",
            "1060: valid loss 6.779148578643799\n",
            "1061: loss: 6.6993184089660645\n",
            "1062: loss: 6.746520042419434\n",
            "1063: loss: 6.793198108673096\n",
            "1064: loss: 6.684751987457275\n",
            "1065: loss: 6.753753185272217\n",
            "1066: loss: 6.752415657043457\n",
            "1067: loss: 6.841392517089844\n",
            "1068: loss: 6.738473892211914\n",
            "1069: loss: 6.806072235107422\n",
            "1070: loss: 6.741368293762207\n",
            "1071: loss: 6.8186845779418945\n",
            "1072: loss: 6.628546237945557\n",
            "1073: loss: 6.740103721618652\n",
            "1074: loss: 6.701112270355225\n",
            "1075: loss: 6.785626411437988\n",
            "1076: loss: 6.726871967315674\n",
            "1077: loss: 6.770583629608154\n",
            "1078: loss: 6.780147552490234\n",
            "1079: loss: 6.741703033447266\n",
            "1080: loss: 6.717706680297852\n",
            "1080: valid loss 6.801004409790039\n",
            "1081: loss: 6.780869483947754\n",
            "1082: loss: 6.740713596343994\n",
            "1083: loss: 6.780723571777344\n",
            "1084: loss: 6.837925910949707\n",
            "1085: loss: 6.771652698516846\n",
            "1086: loss: 6.788496494293213\n",
            "1087: loss: 6.690730571746826\n",
            "1088: loss: 6.674924373626709\n",
            "1089: loss: 6.732555866241455\n",
            "1090: loss: 6.755192756652832\n",
            "1091: loss: 6.7891998291015625\n",
            "1092: loss: 6.744497776031494\n",
            "1093: loss: 6.697900772094727\n",
            "1094: loss: 6.851118087768555\n",
            "1095: loss: 6.725124835968018\n",
            "1096: loss: 6.7849321365356445\n",
            "1097: loss: 6.779013156890869\n",
            "1098: loss: 6.792443752288818\n",
            "1099: loss: 6.694781303405762\n",
            "1100: loss: 6.752845764160156\n",
            "1100: valid loss 6.790834903717041\n",
            "1100: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1101: loss: 6.7649993896484375\n",
            "1102: loss: 6.793792247772217\n",
            "1103: loss: 6.8055243492126465\n",
            "1104: loss: 6.683178901672363\n",
            "1105: loss: 6.674772262573242\n",
            "1106: loss: 6.7965779304504395\n",
            "1107: loss: 6.748780250549316\n",
            "1108: loss: 6.687631607055664\n",
            "1109: loss: 6.676751613616943\n",
            "1110: loss: 6.802985668182373\n",
            "1111: loss: 6.843967437744141\n",
            "1112: loss: 6.792105674743652\n",
            "1113: loss: 6.772879600524902\n",
            "1114: loss: 6.796955108642578\n",
            "1115: loss: 6.6764140129089355\n",
            "1116: loss: 6.769868850708008\n",
            "1117: loss: 6.732722282409668\n",
            "1118: loss: 6.744427680969238\n",
            "1119: loss: 6.802979469299316\n",
            "1120: loss: 6.7898383140563965\n",
            "1120: valid loss 6.775689125061035\n",
            "1121: loss: 6.701533794403076\n",
            "1122: loss: 6.792933940887451\n",
            "1123: loss: 6.740358352661133\n",
            "1124: loss: 6.778219699859619\n",
            "1125: loss: 6.806732177734375\n",
            "1126: loss: 6.652832984924316\n",
            "1127: loss: 6.709141731262207\n",
            "1128: loss: 6.846102237701416\n",
            "1129: loss: 6.784632682800293\n",
            "1130: loss: 6.752495765686035\n",
            "1131: loss: 6.734255790710449\n",
            "1132: loss: 6.82641077041626\n",
            "1133: loss: 6.712762832641602\n",
            "1134: loss: 6.75488805770874\n",
            "1135: loss: 6.774945259094238\n",
            "1136: loss: 6.747114658355713\n",
            "1137: loss: 6.736637592315674\n",
            "1138: loss: 6.736836910247803\n",
            "1139: loss: 6.815885066986084\n",
            "1140: loss: 6.701875686645508\n",
            "1140: valid loss 6.749493598937988\n",
            "1141: loss: 6.772818565368652\n",
            "1142: loss: 6.8175506591796875\n",
            "1143: loss: 6.795595645904541\n",
            "1144: loss: 6.838776111602783\n",
            "1145: loss: 6.851747035980225\n",
            "1146: loss: 6.7967753410339355\n",
            "1147: loss: 6.781553268432617\n",
            "1148: loss: 6.770724296569824\n",
            "1149: loss: 6.711893558502197\n",
            "1150: loss: 6.793838024139404\n",
            "1150: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1151: loss: 6.850017547607422\n",
            "1152: loss: 6.725077152252197\n",
            "1153: loss: 6.674585819244385\n",
            "1154: loss: 6.7963948249816895\n",
            "1155: loss: 6.822147369384766\n",
            "1156: loss: 6.6446123123168945\n",
            "1157: loss: 6.707756519317627\n",
            "1158: loss: 6.70787239074707\n",
            "1159: loss: 6.743890285491943\n",
            "1160: loss: 6.682374954223633\n",
            "1160: valid loss 6.763370037078857\n",
            "1161: loss: 6.747706413269043\n",
            "1162: loss: 6.795509338378906\n",
            "1163: loss: 6.825512886047363\n",
            "1164: loss: 6.7467241287231445\n",
            "1165: loss: 6.796253204345703\n",
            "1166: loss: 6.74837589263916\n",
            "1167: loss: 6.817415237426758\n",
            "1168: loss: 6.713353157043457\n",
            "1169: loss: 6.8298821449279785\n",
            "1170: loss: 6.777982234954834\n",
            "1171: loss: 6.71021842956543\n",
            "1172: loss: 6.82856559753418\n",
            "1173: loss: 6.861891269683838\n",
            "1174: loss: 6.80006217956543\n",
            "1175: loss: 6.775511741638184\n",
            "1176: loss: 6.730823516845703\n",
            "1177: loss: 6.794410705566406\n",
            "1178: loss: 6.6653571128845215\n",
            "1179: loss: 6.676684379577637\n",
            "1180: loss: 6.750280380249023\n",
            "1180: valid loss 6.690455436706543\n",
            "1181: loss: 6.754571437835693\n",
            "1182: loss: 6.713369369506836\n",
            "1183: loss: 6.720588207244873\n",
            "1184: loss: 6.705945014953613\n",
            "1185: loss: 6.767054080963135\n",
            "1186: loss: 6.744786739349365\n",
            "1187: loss: 6.661186695098877\n",
            "1188: loss: 6.684869766235352\n",
            "1189: loss: 6.70474100112915\n",
            "1190: loss: 6.735573768615723\n",
            "1191: loss: 6.803498268127441\n",
            "1192: loss: 6.826214790344238\n",
            "1193: loss: 6.752880096435547\n",
            "1194: loss: 6.744008541107178\n",
            "1195: loss: 6.700910568237305\n",
            "1196: loss: 6.779396057128906\n",
            "1197: loss: 6.709993362426758\n",
            "1198: loss: 6.798133373260498\n",
            "1199: loss: 6.651280403137207\n",
            "1200: loss: 6.794182777404785\n",
            "1200: valid loss 6.721790790557861\n",
            "1200: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1201: loss: 6.725673675537109\n",
            "1202: loss: 6.808842658996582\n",
            "1203: loss: 6.804192066192627\n",
            "1204: loss: 6.782937049865723\n",
            "1205: loss: 6.794891834259033\n",
            "1206: loss: 6.657344341278076\n",
            "1207: loss: 6.805987358093262\n",
            "1208: loss: 6.734436988830566\n",
            "1209: loss: 6.806941986083984\n",
            "1210: loss: 6.766703128814697\n",
            "1211: loss: 6.7110595703125\n",
            "1212: loss: 6.768560886383057\n",
            "1213: loss: 6.698803424835205\n",
            "1214: loss: 6.755917549133301\n",
            "1215: loss: 6.679728031158447\n",
            "1216: loss: 6.808535575866699\n",
            "1217: loss: 6.705047130584717\n",
            "1218: loss: 6.796689033508301\n",
            "1219: loss: 6.763513088226318\n",
            "1220: loss: 6.77439546585083\n",
            "1220: valid loss 6.698390007019043\n",
            "1221: loss: 6.690918922424316\n",
            "1222: loss: 6.795431137084961\n",
            "1223: loss: 6.732915878295898\n",
            "1224: loss: 6.842509746551514\n",
            "1225: loss: 6.734791278839111\n",
            "1226: loss: 6.694586753845215\n",
            "1227: loss: 6.789927959442139\n",
            "1228: loss: 6.74075984954834\n",
            "1229: loss: 6.802597999572754\n",
            "1230: loss: 6.804452896118164\n",
            "1231: loss: 6.760544776916504\n",
            "1232: loss: 6.707870960235596\n",
            "1233: loss: 6.739126205444336\n",
            "1234: loss: 6.749789237976074\n",
            "1235: loss: 6.801844596862793\n",
            "1236: loss: 6.844500541687012\n",
            "1237: loss: 6.751850128173828\n",
            "1238: loss: 6.785438537597656\n",
            "1239: loss: 6.823501110076904\n",
            "1240: loss: 6.7692036628723145\n",
            "1240: valid loss 6.743912696838379\n",
            "1241: loss: 6.698562145233154\n",
            "1242: loss: 6.769900321960449\n",
            "1243: loss: 6.716357707977295\n",
            "1244: loss: 6.773329257965088\n",
            "1245: loss: 6.677628040313721\n",
            "1246: loss: 6.773402690887451\n",
            "1247: loss: 6.837535858154297\n",
            "1248: loss: 6.6883955001831055\n",
            "1249: loss: 6.738705635070801\n",
            "1250: loss: 6.7901458740234375\n",
            "1250: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1251: loss: 6.77160120010376\n",
            "1252: loss: 6.702207088470459\n",
            "1253: loss: 6.767909049987793\n",
            "1254: loss: 6.646251201629639\n",
            "1255: loss: 6.802599906921387\n",
            "1256: loss: 6.788246154785156\n",
            "1257: loss: 6.784799098968506\n",
            "1258: loss: 6.729711055755615\n",
            "1259: loss: 6.757911205291748\n",
            "1260: loss: 6.77296257019043\n",
            "1260: valid loss 6.749706268310547\n",
            "1261: loss: 6.808371543884277\n",
            "1262: loss: 6.739745616912842\n",
            "1263: loss: 6.845794677734375\n",
            "1264: loss: 6.758366107940674\n",
            "1265: loss: 6.770216941833496\n",
            "1266: loss: 6.724968433380127\n",
            "1267: loss: 6.748393535614014\n",
            "1268: loss: 6.814492225646973\n",
            "1269: loss: 6.658118724822998\n",
            "1270: loss: 6.865326881408691\n",
            "1271: loss: 6.8061981201171875\n",
            "1272: loss: 6.783304214477539\n",
            "Epoch 01273: reducing learning rate of group 0 to 3.4300e-03.\n",
            "1273: loss: 6.715178489685059\n",
            "1274: loss: 6.718195915222168\n",
            "1275: loss: 6.7961249351501465\n",
            "1276: loss: 6.7485480308532715\n",
            "1277: loss: 6.782198429107666\n",
            "1278: loss: 6.6623430252075195\n",
            "1279: loss: 6.763510704040527\n",
            "1280: loss: 6.603189945220947\n",
            "1280: valid loss 6.758799076080322\n",
            "1281: loss: 6.718945503234863\n",
            "1282: loss: 6.775033950805664\n",
            "1283: loss: 6.765902042388916\n",
            "1284: loss: 6.7883830070495605\n",
            "1285: loss: 6.728108882904053\n",
            "1286: loss: 6.691478252410889\n",
            "1287: loss: 6.762580394744873\n",
            "1288: loss: 6.797779083251953\n",
            "1289: loss: 6.74981689453125\n",
            "1290: loss: 6.78634786605835\n",
            "1291: loss: 6.79889440536499\n",
            "1292: loss: 6.787737846374512\n",
            "1293: loss: 6.672787666320801\n",
            "1294: loss: 6.828531742095947\n",
            "1295: loss: 6.771755218505859\n",
            "1296: loss: 6.774437427520752\n",
            "1297: loss: 6.784389019012451\n",
            "1298: loss: 6.707217216491699\n",
            "1299: loss: 6.789719104766846\n",
            "1300: loss: 6.736721992492676\n",
            "1300: valid loss 6.739933967590332\n",
            "1300: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1301: loss: 6.800900459289551\n",
            "1302: loss: 6.812421798706055\n",
            "1303: loss: 6.744869709014893\n",
            "1304: loss: 6.704444885253906\n",
            "1305: loss: 6.7119460105896\n",
            "1306: loss: 6.699185848236084\n",
            "1307: loss: 6.759851455688477\n",
            "1308: loss: 6.750777244567871\n",
            "1309: loss: 6.723234176635742\n",
            "1310: loss: 6.754030227661133\n",
            "1311: loss: 6.8092570304870605\n",
            "1312: loss: 6.7587504386901855\n",
            "1313: loss: 6.713623523712158\n",
            "1314: loss: 6.790195941925049\n",
            "1315: loss: 6.755238056182861\n",
            "1316: loss: 6.761675834655762\n",
            "1317: loss: 6.736747741699219\n",
            "1318: loss: 6.720128059387207\n",
            "1319: loss: 6.718142509460449\n",
            "1320: loss: 6.781875133514404\n",
            "1320: valid loss 6.686699867248535\n",
            "1321: loss: 6.804193019866943\n",
            "1322: loss: 6.745301723480225\n",
            "1323: loss: 6.743845462799072\n",
            "1324: loss: 6.750155448913574\n",
            "1325: loss: 6.884655475616455\n",
            "1326: loss: 6.802611827850342\n",
            "1327: loss: 6.711531639099121\n",
            "1328: loss: 6.729499816894531\n",
            "1329: loss: 6.768075466156006\n",
            "1330: loss: 6.685981750488281\n",
            "1331: loss: 6.7647600173950195\n",
            "1332: loss: 6.767551422119141\n",
            "1333: loss: 6.719430923461914\n",
            "1334: loss: 6.7971954345703125\n",
            "1335: loss: 6.772116661071777\n",
            "1336: loss: 6.727781295776367\n",
            "1337: loss: 6.748824596405029\n",
            "1338: loss: 6.750367164611816\n",
            "1339: loss: 6.667417049407959\n",
            "1340: loss: 6.8162946701049805\n",
            "1340: valid loss 6.802765846252441\n",
            "1341: loss: 6.768650054931641\n",
            "1342: loss: 6.787872791290283\n",
            "1343: loss: 6.689568996429443\n",
            "1344: loss: 6.7768659591674805\n",
            "1345: loss: 6.813696384429932\n",
            "1346: loss: 6.771081924438477\n",
            "1347: loss: 6.724603176116943\n",
            "1348: loss: 6.818804740905762\n",
            "1349: loss: 6.833384037017822\n",
            "1350: loss: 6.750661373138428\n",
            "1350: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1351: loss: 6.7753095626831055\n",
            "1352: loss: 6.7586798667907715\n",
            "1353: loss: 6.796390056610107\n",
            "1354: loss: 6.795834064483643\n",
            "1355: loss: 6.701289176940918\n",
            "1356: loss: 6.735735893249512\n",
            "1357: loss: 6.795756816864014\n",
            "1358: loss: 6.712597846984863\n",
            "1359: loss: 6.800878047943115\n",
            "1360: loss: 6.695550918579102\n",
            "1360: valid loss 6.684083938598633\n",
            "1361: loss: 6.7369704246521\n",
            "1362: loss: 6.8278913497924805\n",
            "1363: loss: 6.750875949859619\n",
            "1364: loss: 6.768677711486816\n",
            "1365: loss: 6.789915084838867\n",
            "1366: loss: 6.777513027191162\n",
            "1367: loss: 6.770442962646484\n",
            "1368: loss: 6.714096546173096\n",
            "1369: loss: 6.689443111419678\n",
            "1370: loss: 6.7320756912231445\n",
            "1371: loss: 6.88266134262085\n",
            "1372: loss: 6.6952362060546875\n",
            "1373: loss: 6.751471996307373\n",
            "1374: loss: 6.634067535400391\n",
            "1375: loss: 6.771090984344482\n",
            "1376: loss: 6.780478477478027\n",
            "1377: loss: 6.759746074676514\n",
            "1378: loss: 6.747805595397949\n",
            "1379: loss: 6.8193359375\n",
            "1380: loss: 6.77360200881958\n",
            "1380: valid loss 6.754019260406494\n",
            "1381: loss: 6.835562229156494\n",
            "1382: loss: 6.7758941650390625\n",
            "1383: loss: 6.730943202972412\n",
            "1384: loss: 6.795186519622803\n",
            "1385: loss: 6.674737930297852\n",
            "1386: loss: 6.770740032196045\n",
            "1387: loss: 6.750730991363525\n",
            "1388: loss: 6.830368995666504\n",
            "1389: loss: 6.719203472137451\n",
            "1390: loss: 6.675168991088867\n",
            "1391: loss: 6.758634567260742\n",
            "1392: loss: 6.679573059082031\n",
            "1393: loss: 6.751669883728027\n",
            "1394: loss: 6.733285427093506\n",
            "1395: loss: 6.782449722290039\n",
            "1396: loss: 6.753999710083008\n",
            "1397: loss: 6.740147590637207\n",
            "1398: loss: 6.710031509399414\n",
            "1399: loss: 6.749969959259033\n",
            "1400: loss: 6.761960506439209\n",
            "1400: valid loss 6.7723541259765625\n",
            "1400: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1401: loss: 6.817330837249756\n",
            "1402: loss: 6.719808101654053\n",
            "1403: loss: 6.711733818054199\n",
            "1404: loss: 6.674569129943848\n",
            "1405: loss: 6.744027137756348\n",
            "1406: loss: 6.695320129394531\n",
            "1407: loss: 6.812124729156494\n",
            "1408: loss: 6.842426300048828\n",
            "1409: loss: 6.783773422241211\n",
            "1410: loss: 6.686455249786377\n",
            "1411: loss: 6.804373264312744\n",
            "1412: loss: 6.723226547241211\n",
            "1413: loss: 6.758945941925049\n",
            "1414: loss: 6.754882335662842\n",
            "1415: loss: 6.629693984985352\n",
            "1416: loss: 6.693896770477295\n",
            "1417: loss: 6.758450508117676\n",
            "1418: loss: 6.7895612716674805\n",
            "1419: loss: 6.73712682723999\n",
            "1420: loss: 6.845144271850586\n",
            "1420: valid loss 6.756209373474121\n",
            "1421: loss: 6.807724952697754\n",
            "1422: loss: 6.808382034301758\n",
            "1423: loss: 6.777495384216309\n",
            "1424: loss: 6.779670238494873\n",
            "1425: loss: 6.710190296173096\n",
            "1426: loss: 6.812916278839111\n",
            "1427: loss: 6.746736526489258\n",
            "1428: loss: 6.783207893371582\n",
            "1429: loss: 6.800811290740967\n",
            "1430: loss: 6.696956157684326\n",
            "1431: loss: 6.709028720855713\n",
            "1432: loss: 6.7903828620910645\n",
            "1433: loss: 6.8027119636535645\n",
            "1434: loss: 6.774137020111084\n",
            "1435: loss: 6.802398204803467\n",
            "1436: loss: 6.737133979797363\n",
            "1437: loss: 6.710392951965332\n",
            "1438: loss: 6.762151718139648\n",
            "1439: loss: 6.750636577606201\n",
            "1440: loss: 6.77601957321167\n",
            "1440: valid loss 6.78725528717041\n",
            "1441: loss: 6.825039863586426\n",
            "1442: loss: 6.776027202606201\n",
            "1443: loss: 6.748320579528809\n",
            "1444: loss: 6.784360408782959\n",
            "1445: loss: 6.805065631866455\n",
            "1446: loss: 6.7398200035095215\n",
            "1447: loss: 6.709401607513428\n",
            "1448: loss: 6.722398281097412\n",
            "1449: loss: 6.749789237976074\n",
            "1450: loss: 6.712804317474365\n",
            "1450: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1451: loss: 6.6524882316589355\n",
            "1452: loss: 6.811160087585449\n",
            "1453: loss: 6.7672438621521\n",
            "1454: loss: 6.736473083496094\n",
            "1455: loss: 6.775888919830322\n",
            "1456: loss: 6.707610130310059\n",
            "1457: loss: 6.724656105041504\n",
            "1458: loss: 6.80002498626709\n",
            "1459: loss: 6.7508087158203125\n",
            "1460: loss: 6.792513370513916\n",
            "1460: valid loss 6.724735736846924\n",
            "1461: loss: 6.7602620124816895\n",
            "1462: loss: 6.721164703369141\n",
            "1463: loss: 6.707507610321045\n",
            "1464: loss: 6.723147869110107\n",
            "1465: loss: 6.802641868591309\n",
            "1466: loss: 6.679432392120361\n",
            "1467: loss: 6.795165538787842\n",
            "1468: loss: 6.702866077423096\n",
            "1469: loss: 6.779058933258057\n",
            "1470: loss: 6.8199944496154785\n",
            "1471: loss: 6.770796775817871\n",
            "1472: loss: 6.753757476806641\n",
            "1473: loss: 6.813104629516602\n",
            "1474: loss: 6.700112819671631\n",
            "1475: loss: 6.685547351837158\n",
            "1476: loss: 6.821295261383057\n",
            "1477: loss: 6.775306701660156\n",
            "1478: loss: 6.816640377044678\n",
            "1479: loss: 6.774603843688965\n",
            "1480: loss: 6.752354145050049\n",
            "1480: valid loss 6.78742790222168\n",
            "1481: loss: 6.8280110359191895\n",
            "1482: loss: 6.710095405578613\n",
            "1483: loss: 6.806468486785889\n",
            "1484: loss: 6.769461631774902\n",
            "1485: loss: 6.68958854675293\n",
            "1486: loss: 6.7967610359191895\n",
            "1487: loss: 6.665687084197998\n",
            "1488: loss: 6.804343223571777\n",
            "1489: loss: 6.790432453155518\n",
            "1490: loss: 6.7600178718566895\n",
            "1491: loss: 6.754161834716797\n",
            "1492: loss: 6.806317329406738\n",
            "1493: loss: 6.7886552810668945\n",
            "1494: loss: 6.7625627517700195\n",
            "1495: loss: 6.842739582061768\n",
            "1496: loss: 6.800378799438477\n",
            "1497: loss: 6.742661952972412\n",
            "1498: loss: 6.760107040405273\n",
            "1499: loss: 6.793734073638916\n",
            "1500: loss: 6.8052873611450195\n",
            "1500: valid loss 6.782322883605957\n",
            "1500: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1501: loss: 6.7190141677856445\n",
            "1502: loss: 6.726181507110596\n",
            "1503: loss: 6.633598327636719\n",
            "1504: loss: 6.7361555099487305\n",
            "1505: loss: 6.694938659667969\n",
            "1506: loss: 6.6720380783081055\n",
            "1507: loss: 6.8196821212768555\n",
            "1508: loss: 6.833320617675781\n",
            "1509: loss: 6.7449421882629395\n",
            "1510: loss: 6.6483259201049805\n",
            "1511: loss: 6.668818950653076\n",
            "1512: loss: 6.695621967315674\n",
            "1513: loss: 6.717504978179932\n",
            "1514: loss: 6.806909084320068\n",
            "1515: loss: 6.818176746368408\n",
            "1516: loss: 6.7600016593933105\n",
            "1517: loss: 6.793569564819336\n",
            "1518: loss: 6.772140979766846\n",
            "1519: loss: 6.766578197479248\n",
            "1520: loss: 6.782829284667969\n",
            "1520: valid loss 6.755486011505127\n",
            "1521: loss: 6.820373058319092\n",
            "1522: loss: 6.666634559631348\n",
            "1523: loss: 6.759236812591553\n",
            "1524: loss: 6.817051410675049\n",
            "1525: loss: 6.718845367431641\n",
            "1526: loss: 6.744314670562744\n",
            "1527: loss: 6.814001083374023\n",
            "1528: loss: 6.824219226837158\n",
            "1529: loss: 6.765936374664307\n",
            "1530: loss: 6.788650035858154\n",
            "1531: loss: 6.7740983963012695\n",
            "1532: loss: 6.8192138671875\n",
            "1533: loss: 6.761568069458008\n",
            "1534: loss: 6.841060638427734\n",
            "1535: loss: 6.764284610748291\n",
            "1536: loss: 6.825039863586426\n",
            "1537: loss: 6.739802360534668\n",
            "1538: loss: 6.817216873168945\n",
            "1539: loss: 6.796037197113037\n",
            "1540: loss: 6.760519027709961\n",
            "1540: valid loss 6.7151689529418945\n",
            "1541: loss: 6.797789096832275\n",
            "1542: loss: 6.78368616104126\n",
            "1543: loss: 6.703231334686279\n",
            "1544: loss: 6.737811088562012\n",
            "1545: loss: 6.740332126617432\n",
            "1546: loss: 6.77043342590332\n",
            "1547: loss: 6.771387577056885\n",
            "1548: loss: 6.783461570739746\n",
            "1549: loss: 6.794131278991699\n",
            "1550: loss: 6.772714138031006\n",
            "1550: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1551: loss: 6.807243824005127\n",
            "1552: loss: 6.752911567687988\n",
            "1553: loss: 6.82232666015625\n",
            "1554: loss: 6.770694255828857\n",
            "1555: loss: 6.687280654907227\n",
            "1556: loss: 6.810502529144287\n",
            "1557: loss: 6.743595123291016\n",
            "1558: loss: 6.72845458984375\n",
            "1559: loss: 6.770343780517578\n",
            "1560: loss: 6.750588893890381\n",
            "1560: valid loss 6.713052272796631\n",
            "1561: loss: 6.775666236877441\n",
            "1562: loss: 6.759039402008057\n",
            "1563: loss: 6.750457763671875\n",
            "1564: loss: 6.808745384216309\n",
            "1565: loss: 6.774130821228027\n",
            "1566: loss: 6.685115337371826\n",
            "1567: loss: 6.795266151428223\n",
            "1568: loss: 6.809745788574219\n",
            "1569: loss: 6.793369293212891\n",
            "1570: loss: 6.76336669921875\n",
            "1571: loss: 6.838840961456299\n",
            "1572: loss: 6.766453742980957\n",
            "1573: loss: 6.750248432159424\n",
            "Epoch 01574: reducing learning rate of group 0 to 2.4010e-03.\n",
            "1574: loss: 6.847952842712402\n",
            "1575: loss: 6.766083717346191\n",
            "1576: loss: 6.769395351409912\n",
            "1577: loss: 6.679037570953369\n",
            "1578: loss: 6.819746971130371\n",
            "1579: loss: 6.726696968078613\n",
            "1580: loss: 6.752376556396484\n",
            "1580: valid loss 6.786264419555664\n",
            "1581: loss: 6.803801536560059\n",
            "1582: loss: 6.7627129554748535\n",
            "1583: loss: 6.717353820800781\n",
            "1584: loss: 6.811021327972412\n",
            "1585: loss: 6.708127975463867\n",
            "1586: loss: 6.770957946777344\n",
            "1587: loss: 6.750822067260742\n",
            "1588: loss: 6.8274664878845215\n",
            "1589: loss: 6.765250205993652\n",
            "1590: loss: 6.787749290466309\n",
            "1591: loss: 6.813139915466309\n",
            "1592: loss: 6.668336868286133\n",
            "1593: loss: 6.801502704620361\n",
            "1594: loss: 6.797767162322998\n",
            "1595: loss: 6.714211940765381\n",
            "1596: loss: 6.642422199249268\n",
            "1597: loss: 6.786372661590576\n",
            "1598: loss: 6.7968034744262695\n",
            "1599: loss: 6.797949314117432\n",
            "1600: loss: 6.756065368652344\n",
            "1600: valid loss 6.701817512512207\n",
            "1600: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1601: loss: 6.794371604919434\n",
            "1602: loss: 6.767651557922363\n",
            "1603: loss: 6.777730464935303\n",
            "1604: loss: 6.833940029144287\n",
            "1605: loss: 6.717782497406006\n",
            "1606: loss: 6.705113410949707\n",
            "1607: loss: 6.719916343688965\n",
            "1608: loss: 6.718268394470215\n",
            "1609: loss: 6.69586181640625\n",
            "1610: loss: 6.690844535827637\n",
            "1611: loss: 6.821901321411133\n",
            "1612: loss: 6.786777496337891\n",
            "1613: loss: 6.80800199508667\n",
            "1614: loss: 6.834531784057617\n",
            "1615: loss: 6.739473342895508\n",
            "1616: loss: 6.809597969055176\n",
            "1617: loss: 6.773689270019531\n",
            "1618: loss: 6.746246337890625\n",
            "1619: loss: 6.77153205871582\n",
            "1620: loss: 6.75209379196167\n",
            "1620: valid loss 6.6659440994262695\n",
            "1621: loss: 6.729982852935791\n",
            "1622: loss: 6.7899603843688965\n",
            "1623: loss: 6.815339088439941\n",
            "1624: loss: 6.721024990081787\n",
            "1625: loss: 6.764461994171143\n",
            "1626: loss: 6.753196716308594\n",
            "1627: loss: 6.690337181091309\n",
            "1628: loss: 6.797607898712158\n",
            "1629: loss: 6.759296894073486\n",
            "1630: loss: 6.793144226074219\n",
            "1631: loss: 6.778994083404541\n",
            "1632: loss: 6.791811943054199\n",
            "1633: loss: 6.764948844909668\n",
            "1634: loss: 6.765498638153076\n",
            "1635: loss: 6.815054893493652\n",
            "1636: loss: 6.758327007293701\n",
            "1637: loss: 6.804549694061279\n",
            "1638: loss: 6.768974304199219\n",
            "1639: loss: 6.784502983093262\n",
            "1640: loss: 6.75357723236084\n",
            "1640: valid loss 6.717566967010498\n",
            "1641: loss: 6.792043685913086\n",
            "1642: loss: 6.719038486480713\n",
            "1643: loss: 6.818408489227295\n",
            "1644: loss: 6.804090976715088\n",
            "1645: loss: 6.775609970092773\n",
            "1646: loss: 6.736591339111328\n",
            "1647: loss: 6.73826265335083\n",
            "1648: loss: 6.7088727951049805\n",
            "1649: loss: 6.823554515838623\n",
            "1650: loss: 6.765603542327881\n",
            "1650: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1651: loss: 6.756506443023682\n",
            "1652: loss: 6.70214319229126\n",
            "1653: loss: 6.765895843505859\n",
            "1654: loss: 6.88125467300415\n",
            "1655: loss: 6.783477306365967\n",
            "1656: loss: 6.787304878234863\n",
            "1657: loss: 6.674219608306885\n",
            "1658: loss: 6.796568870544434\n",
            "1659: loss: 6.784842491149902\n",
            "1660: loss: 6.803829193115234\n",
            "1660: valid loss 6.697239875793457\n",
            "1661: loss: 6.777127742767334\n",
            "1662: loss: 6.79440450668335\n",
            "1663: loss: 6.744997501373291\n",
            "1664: loss: 6.745080471038818\n",
            "1665: loss: 6.8557891845703125\n",
            "1666: loss: 6.650512218475342\n",
            "1667: loss: 6.75962495803833\n",
            "1668: loss: 6.794844150543213\n",
            "1669: loss: 6.713367462158203\n",
            "1670: loss: 6.742576599121094\n",
            "1671: loss: 6.790586948394775\n",
            "1672: loss: 6.745765686035156\n",
            "1673: loss: 6.793360710144043\n",
            "1674: loss: 6.797888278961182\n",
            "1675: loss: 6.7560648918151855\n",
            "1676: loss: 6.766637802124023\n",
            "1677: loss: 6.757810115814209\n",
            "1678: loss: 6.908787250518799\n",
            "1679: loss: 6.756574630737305\n",
            "1680: loss: 6.785358428955078\n",
            "1680: valid loss 6.644122123718262\n",
            "1681: loss: 6.720850467681885\n",
            "1682: loss: 6.781140327453613\n",
            "1683: loss: 6.762145042419434\n",
            "1684: loss: 6.672308921813965\n",
            "1685: loss: 6.759140968322754\n",
            "1686: loss: 6.787410736083984\n",
            "1687: loss: 6.708745956420898\n",
            "1688: loss: 6.754408836364746\n",
            "1689: loss: 6.77324914932251\n",
            "1690: loss: 6.617934226989746\n",
            "1691: loss: 6.725156784057617\n",
            "1692: loss: 6.813830852508545\n",
            "1693: loss: 6.770604610443115\n",
            "1694: loss: 6.794567108154297\n",
            "1695: loss: 6.65298318862915\n",
            "1696: loss: 6.739774227142334\n",
            "1697: loss: 6.7806901931762695\n",
            "1698: loss: 6.780514717102051\n",
            "1699: loss: 6.686460971832275\n",
            "1700: loss: 6.796030044555664\n",
            "1700: valid loss 6.718381881713867\n",
            "1700: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1701: loss: 6.726269245147705\n",
            "1702: loss: 6.758279800415039\n",
            "1703: loss: 6.741504192352295\n",
            "1704: loss: 6.747259616851807\n",
            "1705: loss: 6.758607864379883\n",
            "1706: loss: 6.706390380859375\n",
            "1707: loss: 6.762039661407471\n",
            "1708: loss: 6.768095016479492\n",
            "1709: loss: 6.776935577392578\n",
            "1710: loss: 6.721064567565918\n",
            "1711: loss: 6.7372870445251465\n",
            "1712: loss: 6.777315139770508\n",
            "1713: loss: 6.827615261077881\n",
            "1714: loss: 6.774450302124023\n",
            "1715: loss: 6.785703182220459\n",
            "1716: loss: 6.79799747467041\n",
            "1717: loss: 6.803819179534912\n",
            "1718: loss: 6.788864612579346\n",
            "1719: loss: 6.749471187591553\n",
            "1720: loss: 6.69774866104126\n",
            "1720: valid loss 6.780259132385254\n",
            "1721: loss: 6.762823104858398\n",
            "1722: loss: 6.773623943328857\n",
            "1723: loss: 6.782721042633057\n",
            "1724: loss: 6.712382793426514\n",
            "1725: loss: 6.812558174133301\n",
            "1726: loss: 6.797678470611572\n",
            "1727: loss: 6.729674339294434\n",
            "1728: loss: 6.795045375823975\n",
            "1729: loss: 6.777966499328613\n",
            "1730: loss: 6.8267998695373535\n",
            "1731: loss: 6.7896246910095215\n",
            "1732: loss: 6.773930072784424\n",
            "1733: loss: 6.778944969177246\n",
            "1734: loss: 6.82436990737915\n",
            "1735: loss: 6.737202167510986\n",
            "1736: loss: 6.725904941558838\n",
            "1737: loss: 6.7855963706970215\n",
            "1738: loss: 6.788767337799072\n",
            "1739: loss: 6.771377086639404\n",
            "1740: loss: 6.8067522048950195\n",
            "1740: valid loss 6.867393970489502\n",
            "1741: loss: 6.783230304718018\n",
            "1742: loss: 6.78061580657959\n",
            "1743: loss: 6.681183338165283\n",
            "1744: loss: 6.751861095428467\n",
            "1745: loss: 6.755887031555176\n",
            "1746: loss: 6.7363433837890625\n",
            "1747: loss: 6.689652442932129\n",
            "1748: loss: 6.7486138343811035\n",
            "1749: loss: 6.770876407623291\n",
            "1750: loss: 6.793534278869629\n",
            "1750: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1751: loss: 6.753993034362793\n",
            "1752: loss: 6.757328987121582\n",
            "1753: loss: 6.728365898132324\n",
            "1754: loss: 6.732480525970459\n",
            "1755: loss: 6.716727256774902\n",
            "1756: loss: 6.758293151855469\n",
            "1757: loss: 6.834259986877441\n",
            "1758: loss: 6.702278137207031\n",
            "1759: loss: 6.799752712249756\n",
            "1760: loss: 6.725503444671631\n",
            "1760: valid loss 6.766168594360352\n",
            "1761: loss: 6.77559757232666\n",
            "1762: loss: 6.806980133056641\n",
            "1763: loss: 6.695791244506836\n",
            "1764: loss: 6.746544361114502\n",
            "1765: loss: 6.736515522003174\n",
            "1766: loss: 6.777945518493652\n",
            "1767: loss: 6.652503967285156\n",
            "1768: loss: 6.756139755249023\n",
            "1769: loss: 6.75949764251709\n",
            "1770: loss: 6.741797924041748\n",
            "1771: loss: 6.7629194259643555\n",
            "1772: loss: 6.74807596206665\n",
            "1773: loss: 6.626409530639648\n",
            "1774: loss: 6.70430326461792\n",
            "1775: loss: 6.6434326171875\n",
            "1776: loss: 6.73502779006958\n",
            "1777: loss: 6.755882740020752\n",
            "1778: loss: 6.821651935577393\n",
            "1779: loss: 6.842566967010498\n",
            "1780: loss: 6.751454830169678\n",
            "1780: valid loss 6.6753058433532715\n",
            "1781: loss: 6.839558124542236\n",
            "1782: loss: 6.716424465179443\n",
            "1783: loss: 6.766323089599609\n",
            "1784: loss: 6.765985488891602\n",
            "1785: loss: 6.737716197967529\n",
            "1786: loss: 6.72983455657959\n",
            "1787: loss: 6.8003764152526855\n",
            "1788: loss: 6.848150730133057\n",
            "1789: loss: 6.821579456329346\n",
            "1790: loss: 6.826156139373779\n",
            "1791: loss: 6.744748115539551\n",
            "1792: loss: 6.71096134185791\n",
            "1793: loss: 6.747498989105225\n",
            "1794: loss: 6.683618068695068\n",
            "1795: loss: 6.755945682525635\n",
            "1796: loss: 6.7008137702941895\n",
            "1797: loss: 6.760798931121826\n",
            "1798: loss: 6.769557476043701\n",
            "1799: loss: 6.713186264038086\n",
            "1800: loss: 6.800765037536621\n",
            "1800: valid loss 6.70290470123291\n",
            "1800: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1801: loss: 6.766757011413574\n",
            "1802: loss: 6.8197550773620605\n",
            "1803: loss: 6.772091865539551\n",
            "1804: loss: 6.752903938293457\n",
            "1805: loss: 6.829085350036621\n",
            "1806: loss: 6.723536014556885\n",
            "1807: loss: 6.840781211853027\n",
            "1808: loss: 6.775264739990234\n",
            "1809: loss: 6.766561031341553\n",
            "1810: loss: 6.792848110198975\n",
            "1811: loss: 6.740488529205322\n",
            "1812: loss: 6.737685680389404\n",
            "1813: loss: 6.716825485229492\n",
            "1814: loss: 6.814830780029297\n",
            "1815: loss: 6.7744221687316895\n",
            "1816: loss: 6.664543628692627\n",
            "1817: loss: 6.748592376708984\n",
            "1818: loss: 6.703322410583496\n",
            "1819: loss: 6.732384204864502\n",
            "1820: loss: 6.754815578460693\n",
            "1820: valid loss 6.7603912353515625\n",
            "1821: loss: 6.7412109375\n",
            "1822: loss: 6.6840057373046875\n",
            "1823: loss: 6.727040767669678\n",
            "1824: loss: 6.751517295837402\n",
            "1825: loss: 6.730974197387695\n",
            "1826: loss: 6.790737152099609\n",
            "1827: loss: 6.749227523803711\n",
            "1828: loss: 6.853844165802002\n",
            "1829: loss: 6.826770305633545\n",
            "1830: loss: 6.717371940612793\n",
            "1831: loss: 6.735243797302246\n",
            "1832: loss: 6.7472968101501465\n",
            "1833: loss: 6.808075428009033\n",
            "1834: loss: 6.730785846710205\n",
            "1835: loss: 6.706088066101074\n",
            "1836: loss: 6.66735315322876\n",
            "1837: loss: 6.73389196395874\n",
            "1838: loss: 6.829151153564453\n",
            "1839: loss: 6.61588716506958\n",
            "1840: loss: 6.697547435760498\n",
            "1840: valid loss 6.744792938232422\n",
            "1841: loss: 6.822153091430664\n",
            "1842: loss: 6.692543029785156\n",
            "1843: loss: 6.812921524047852\n",
            "1844: loss: 6.779447555541992\n",
            "1845: loss: 6.671664714813232\n",
            "1846: loss: 6.806723594665527\n",
            "1847: loss: 6.743383884429932\n",
            "1848: loss: 6.751008987426758\n",
            "1849: loss: 6.853538513183594\n",
            "1850: loss: 6.772492408752441\n",
            "1850: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1851: loss: 6.781723499298096\n",
            "1852: loss: 6.753168106079102\n",
            "1853: loss: 6.806817054748535\n",
            "1854: loss: 6.720210552215576\n",
            "1855: loss: 6.659030914306641\n",
            "1856: loss: 6.637735843658447\n",
            "1857: loss: 6.7720947265625\n",
            "1858: loss: 6.797494411468506\n",
            "1859: loss: 6.7729926109313965\n",
            "1860: loss: 6.798677921295166\n",
            "1860: valid loss 6.771660327911377\n",
            "1861: loss: 6.748007774353027\n",
            "1862: loss: 6.807865619659424\n",
            "1863: loss: 6.602970600128174\n",
            "1864: loss: 6.804965496063232\n",
            "1865: loss: 6.791443824768066\n",
            "1866: loss: 6.700397968292236\n",
            "1867: loss: 6.727292537689209\n",
            "1868: loss: 6.713582515716553\n",
            "1869: loss: 6.760734558105469\n",
            "1870: loss: 6.789644241333008\n",
            "1871: loss: 6.786441326141357\n",
            "1872: loss: 6.705957412719727\n",
            "1873: loss: 6.794424533843994\n",
            "1874: loss: 6.831273555755615\n",
            "Epoch 01875: reducing learning rate of group 0 to 1.6807e-03.\n",
            "1875: loss: 6.797911167144775\n",
            "1876: loss: 6.779487609863281\n",
            "1877: loss: 6.777010440826416\n",
            "1878: loss: 6.766210079193115\n",
            "1879: loss: 6.714437484741211\n",
            "1880: loss: 6.711792945861816\n",
            "1880: valid loss 6.755191326141357\n",
            "1881: loss: 6.727394104003906\n",
            "1882: loss: 6.818416118621826\n",
            "1883: loss: 6.658849239349365\n",
            "1884: loss: 6.720780372619629\n",
            "1885: loss: 6.733114242553711\n",
            "1886: loss: 6.743778228759766\n",
            "1887: loss: 6.741852283477783\n",
            "1888: loss: 6.711948871612549\n",
            "1889: loss: 6.719403266906738\n",
            "1890: loss: 6.791227340698242\n",
            "1891: loss: 6.797878265380859\n",
            "1892: loss: 6.7333664894104\n",
            "1893: loss: 6.728565216064453\n",
            "1894: loss: 6.79304313659668\n",
            "1895: loss: 6.80631685256958\n",
            "1896: loss: 6.810846328735352\n",
            "1897: loss: 6.751095771789551\n",
            "1898: loss: 6.842784404754639\n",
            "1899: loss: 6.7952880859375\n",
            "1900: loss: 6.717981338500977\n",
            "1900: valid loss 6.763429164886475\n",
            "1900: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1901: loss: 6.763343334197998\n",
            "1902: loss: 6.734243869781494\n",
            "1903: loss: 6.732658863067627\n",
            "1904: loss: 6.753835201263428\n",
            "1905: loss: 6.795548915863037\n",
            "1906: loss: 6.781917095184326\n",
            "1907: loss: 6.797026634216309\n",
            "1908: loss: 6.696264743804932\n",
            "1909: loss: 6.727034568786621\n",
            "1910: loss: 6.732285499572754\n",
            "1911: loss: 6.828186988830566\n",
            "1912: loss: 6.784060955047607\n",
            "1913: loss: 6.735733509063721\n",
            "1914: loss: 6.774874210357666\n",
            "1915: loss: 6.804481029510498\n",
            "1916: loss: 6.774785041809082\n",
            "1917: loss: 6.765654563903809\n",
            "1918: loss: 6.697541236877441\n",
            "1919: loss: 6.691784858703613\n",
            "1920: loss: 6.794826030731201\n",
            "1920: valid loss 6.826358795166016\n",
            "1921: loss: 6.763457298278809\n",
            "1922: loss: 6.702712535858154\n",
            "1923: loss: 6.740808963775635\n",
            "1924: loss: 6.788150310516357\n",
            "1925: loss: 6.757268905639648\n",
            "1926: loss: 6.750618934631348\n",
            "1927: loss: 6.727099895477295\n",
            "1928: loss: 6.729567527770996\n",
            "1929: loss: 6.717573165893555\n",
            "1930: loss: 6.822183132171631\n",
            "1931: loss: 6.8259477615356445\n",
            "1932: loss: 6.718752384185791\n",
            "1933: loss: 6.764097213745117\n",
            "1934: loss: 6.733835697174072\n",
            "1935: loss: 6.782225131988525\n",
            "1936: loss: 6.81892204284668\n",
            "1937: loss: 6.683668613433838\n",
            "1938: loss: 6.755313873291016\n",
            "1939: loss: 6.788324356079102\n",
            "1940: loss: 6.783720970153809\n",
            "1940: valid loss 6.7648468017578125\n",
            "1941: loss: 6.810181617736816\n",
            "1942: loss: 6.710916996002197\n",
            "1943: loss: 6.808495998382568\n",
            "1944: loss: 6.684936046600342\n",
            "1945: loss: 6.774728775024414\n",
            "1946: loss: 6.736699104309082\n",
            "1947: loss: 6.701870918273926\n",
            "1948: loss: 6.795960426330566\n",
            "1949: loss: 6.778208255767822\n",
            "1950: loss: 6.780557632446289\n",
            "1950: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "1951: loss: 6.859585285186768\n",
            "1952: loss: 6.729197978973389\n",
            "1953: loss: 6.7105607986450195\n",
            "1954: loss: 6.75833797454834\n",
            "1955: loss: 6.67156457901001\n",
            "1956: loss: 6.816978454589844\n",
            "1957: loss: 6.796923637390137\n",
            "1958: loss: 6.672887325286865\n",
            "1959: loss: 6.755629062652588\n",
            "1960: loss: 6.762567520141602\n",
            "1960: valid loss 6.691830158233643\n",
            "1961: loss: 6.753790855407715\n",
            "1962: loss: 6.753040790557861\n",
            "1963: loss: 6.681795597076416\n",
            "1964: loss: 6.777960300445557\n",
            "1965: loss: 6.8450422286987305\n",
            "1966: loss: 6.748509883880615\n",
            "1967: loss: 6.753381252288818\n",
            "1968: loss: 6.784364223480225\n",
            "1969: loss: 6.77782678604126\n",
            "1970: loss: 6.788898944854736\n",
            "1971: loss: 6.790862560272217\n",
            "1972: loss: 6.824494361877441\n",
            "1973: loss: 6.7392191886901855\n",
            "1974: loss: 6.820251941680908\n",
            "1975: loss: 6.70476770401001\n",
            "1976: loss: 6.69405460357666\n",
            "1977: loss: 6.656794548034668\n",
            "1978: loss: 6.8270087242126465\n",
            "1979: loss: 6.77588415145874\n",
            "1980: loss: 6.7478461265563965\n",
            "1980: valid loss 6.739358901977539\n",
            "1981: loss: 6.686384201049805\n",
            "1982: loss: 6.634721279144287\n",
            "1983: loss: 6.745932102203369\n",
            "1984: loss: 6.819465637207031\n",
            "1985: loss: 6.738566875457764\n",
            "1986: loss: 6.8095526695251465\n",
            "1987: loss: 6.695868968963623\n",
            "1988: loss: 6.802278995513916\n",
            "1989: loss: 6.7701520919799805\n",
            "1990: loss: 6.806482315063477\n",
            "1991: loss: 6.76876974105835\n",
            "1992: loss: 6.797773361206055\n",
            "1993: loss: 6.7660298347473145\n",
            "1994: loss: 6.700891971588135\n",
            "1995: loss: 6.736738681793213\n",
            "1996: loss: 6.812278747558594\n",
            "1997: loss: 6.723325729370117\n",
            "1998: loss: 6.793529510498047\n",
            "1999: loss: 6.803905010223389\n",
            "2000: loss: 6.805514812469482\n",
            "2000: valid loss 6.678399085998535\n",
            "2000: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "2001: loss: 6.802879333496094\n",
            "2002: loss: 6.8264570236206055\n",
            "2003: loss: 6.733870506286621\n",
            "2004: loss: 6.804327487945557\n",
            "2005: loss: 6.716724395751953\n",
            "2006: loss: 6.759314060211182\n",
            "2007: loss: 6.810286045074463\n",
            "2008: loss: 6.747093677520752\n",
            "2009: loss: 6.588987827301025\n",
            "2010: loss: 6.78076696395874\n",
            "2011: loss: 6.793015480041504\n",
            "2012: loss: 6.740783214569092\n",
            "2013: loss: 6.713275909423828\n",
            "2014: loss: 6.782660961151123\n",
            "2015: loss: 6.723213195800781\n",
            "2016: loss: 6.803469657897949\n",
            "2017: loss: 6.849462985992432\n",
            "2018: loss: 6.67605447769165\n",
            "2019: loss: 6.777599334716797\n",
            "2020: loss: 6.7163543701171875\n",
            "2020: valid loss 6.836160182952881\n",
            "2021: loss: 6.661483287811279\n",
            "2022: loss: 6.681934833526611\n",
            "2023: loss: 6.822006702423096\n",
            "2024: loss: 6.679018497467041\n",
            "2025: loss: 6.771778106689453\n",
            "2026: loss: 6.721468925476074\n",
            "2027: loss: 6.817976474761963\n",
            "2028: loss: 6.722723484039307\n",
            "2029: loss: 6.7729411125183105\n",
            "2030: loss: 6.75552225112915\n",
            "2031: loss: 6.7025322914123535\n",
            "2032: loss: 6.73610258102417\n",
            "2033: loss: 6.703829765319824\n",
            "2034: loss: 6.751461029052734\n",
            "2035: loss: 6.731700420379639\n",
            "2036: loss: 6.7151713371276855\n",
            "2037: loss: 6.745388507843018\n",
            "2038: loss: 6.718496799468994\n",
            "2039: loss: 6.782531261444092\n",
            "2040: loss: 6.84273624420166\n",
            "2040: valid loss 6.808364391326904\n",
            "2041: loss: 6.81282377243042\n",
            "2042: loss: 6.669041156768799\n",
            "2043: loss: 6.803413391113281\n",
            "2044: loss: 6.763582706451416\n",
            "2045: loss: 6.702176094055176\n",
            "2046: loss: 6.718659400939941\n",
            "2047: loss: 6.669408798217773\n",
            "2048: loss: 6.756097316741943\n",
            "2049: loss: 6.781796932220459\n",
            "2050: loss: 6.774333953857422\n",
            "2050: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "2051: loss: 6.7710700035095215\n",
            "2052: loss: 6.743495464324951\n",
            "2053: loss: 6.757436275482178\n",
            "2054: loss: 6.7559285163879395\n",
            "2055: loss: 6.689069747924805\n",
            "2056: loss: 6.644044876098633\n",
            "2057: loss: 6.734487533569336\n",
            "2058: loss: 6.8214545249938965\n",
            "2059: loss: 6.762916564941406\n",
            "2060: loss: 6.8279337882995605\n",
            "2060: valid loss 6.747143268585205\n",
            "2061: loss: 6.66639518737793\n",
            "2062: loss: 6.813661098480225\n",
            "2063: loss: 6.7535271644592285\n",
            "2064: loss: 6.697971343994141\n",
            "2065: loss: 6.726825714111328\n",
            "2066: loss: 6.795584678649902\n",
            "2067: loss: 6.823726654052734\n",
            "2068: loss: 6.78420877456665\n",
            "2069: loss: 6.843079566955566\n",
            "2070: loss: 6.663837432861328\n",
            "2071: loss: 6.756019115447998\n",
            "2072: loss: 6.845612049102783\n",
            "2073: loss: 6.709493637084961\n",
            "2074: loss: 6.784397602081299\n",
            "2075: loss: 6.790832996368408\n",
            "2076: loss: 6.679737091064453\n",
            "2077: loss: 6.774905204772949\n",
            "2078: loss: 6.7454705238342285\n",
            "2079: loss: 6.851150989532471\n",
            "2080: loss: 6.687867641448975\n",
            "2080: valid loss 6.831550121307373\n",
            "2081: loss: 6.692919731140137\n",
            "2082: loss: 6.782517433166504\n",
            "2083: loss: 6.774333953857422\n",
            "2084: loss: 6.6763434410095215\n",
            "2085: loss: 6.755445957183838\n",
            "2086: loss: 6.763570785522461\n",
            "2087: loss: 6.756126403808594\n",
            "2088: loss: 6.760745048522949\n",
            "2089: loss: 6.773902416229248\n",
            "2090: loss: 6.784668445587158\n",
            "2091: loss: 6.749337196350098\n",
            "2092: loss: 6.733485221862793\n",
            "2093: loss: 6.732532024383545\n",
            "2094: loss: 6.783947467803955\n",
            "2095: loss: 6.691200256347656\n",
            "2096: loss: 6.749180316925049\n",
            "2097: loss: 6.754879474639893\n",
            "2098: loss: 6.750527858734131\n",
            "2099: loss: 6.746329307556152\n",
            "2100: loss: 6.797737121582031\n",
            "2100: valid loss 6.7707109451293945\n",
            "2100: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "2101: loss: 6.774379253387451\n",
            "2102: loss: 6.74514102935791\n",
            "2103: loss: 6.852835178375244\n",
            "2104: loss: 6.654189109802246\n",
            "2105: loss: 6.798917293548584\n",
            "2106: loss: 6.695824146270752\n",
            "2107: loss: 6.755346775054932\n",
            "2108: loss: 6.792891025543213\n",
            "2109: loss: 6.770113468170166\n",
            "2110: loss: 6.802955150604248\n",
            "2111: loss: 6.847769260406494\n",
            "2112: loss: 6.781783103942871\n",
            "2113: loss: 6.7329206466674805\n",
            "2114: loss: 6.7810378074646\n",
            "2115: loss: 6.788797855377197\n",
            "2116: loss: 6.867913722991943\n",
            "2117: loss: 6.776276588439941\n",
            "2118: loss: 6.832879543304443\n",
            "2119: loss: 6.691967010498047\n",
            "2120: loss: 6.731481075286865\n",
            "2120: valid loss 6.806312084197998\n",
            "2121: loss: 6.695019721984863\n",
            "2122: loss: 6.8084282875061035\n",
            "2123: loss: 6.835409164428711\n",
            "2124: loss: 6.764570713043213\n",
            "2125: loss: 6.723330974578857\n",
            "2126: loss: 6.7646074295043945\n",
            "2127: loss: 6.685988903045654\n",
            "2128: loss: 6.830990314483643\n",
            "2129: loss: 6.750483989715576\n",
            "2130: loss: 6.7126665115356445\n",
            "2131: loss: 6.734772682189941\n",
            "2132: loss: 6.801380634307861\n",
            "2133: loss: 6.77952241897583\n",
            "2134: loss: 6.7039384841918945\n",
            "2135: loss: 6.812039852142334\n",
            "2136: loss: 6.759705066680908\n",
            "2137: loss: 6.824386119842529\n",
            "2138: loss: 6.792539119720459\n",
            "2139: loss: 6.765187740325928\n",
            "2140: loss: 6.796376705169678\n",
            "2140: valid loss 6.761265277862549\n",
            "2141: loss: 6.846343040466309\n",
            "2142: loss: 6.784299850463867\n",
            "2143: loss: 6.726444244384766\n",
            "2144: loss: 6.744231224060059\n",
            "2145: loss: 6.7760443687438965\n",
            "2146: loss: 6.776328086853027\n",
            "2147: loss: 6.703299045562744\n",
            "2148: loss: 6.703891277313232\n",
            "2149: loss: 6.691186428070068\n",
            "2150: loss: 6.785361289978027\n",
            "2150: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_coarse\n",
            "2151: loss: 6.708462238311768\n",
            "2152: loss: 6.796247959136963\n",
            "2153: loss: 6.776034832000732\n",
            "2154: loss: 6.731738567352295\n",
            "2155: loss: 6.800012111663818\n",
            "2156: loss: 6.765544414520264\n",
            "2157: loss: 6.768727779388428\n",
            "2158: loss: 6.791951656341553\n",
            "2159: loss: 6.693914413452148\n",
            "2160: loss: 6.734503746032715\n",
            "2160: valid loss 6.819248676300049\n",
            "2161: loss: 6.7300944328308105\n",
            "2162: loss: 6.735919952392578\n",
            "2163: loss: 6.818822383880615\n",
            "2164: loss: 6.79013204574585\n",
            "2165: loss: 6.801791667938232\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "coarse_transformer = CoarseTransformer(\n",
        "    num_semantic_tokens = wav2vec.codebook_size,\n",
        "    codebook_size = 1024,\n",
        "    num_coarse_quantizers = 3,\n",
        "    dim = config[\"embedding_dim\"],\n",
        "    depth = config[\"depth\"],\n",
        "    heads = config[\"heads\"],\n",
        "    audio_text_condition = True,\n",
        "    attn_dropout = config[\"attn_dropout\"],\n",
        "    ff_dropout = config[\"ff_dropout\"],\n",
        ")\n",
        "\n",
        "coarse_trainer = CoarseTransformerTrainer(\n",
        "    transformer = coarse_transformer,\n",
        "    codec = soundstream,\n",
        "    wav2vec = wav2vec,\n",
        "    audio_conditioner = quantizer,\n",
        "    folder = dataset_folder,\n",
        "    lr=config[\"lr\"],\n",
        "    batch_size = config[\"batch_size\"],\n",
        "    data_max_length_seconds = config.get(\"data_max_length_seconds\"),\n",
        "    data_max_length = config.get(\"data_max_length\"),\n",
        "    save_results_every = VAL_EVERY_STEPS,\n",
        "    wd = config[\"wd\"],\n",
        "    grad_accum_every = config[\"grad_accum_every\"],\n",
        "    max_grad_norm = config[\"max_grad_norm\"],\n",
        "    save_model_every = 50,\n",
        "    num_train_steps = STEPS,\n",
        "    results_folder = RESULTS_ROOT_PATH+'/results_coarse',\n",
        "    force_clear_prev_results = False,\n",
        "    accelerate_kwargs = get_accelerate_kwargs(config)\n",
        ")\n",
        "\n",
        "scheduler = get_scheduler(coarse_trainer.optim, config)\n",
        "\n",
        "if load_ckpt:\n",
        "  coarse_trainer.load(coarse_load_path)\n",
        "\n",
        "if train:\n",
        "  custom_train(coarse_trainer,\n",
        "               config,\n",
        "               scheduler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRvj7qOJWzmw"
      },
      "source": [
        "### FineTransformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  if train: \n",
        "    free_gpu_memory(fine_transformer)\n",
        "    free_gpu_memory(coarse_transformer)\n",
        "    del coarse_transformer, coarse_trainer\n",
        "except:\n",
        "  pass\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "kacUP_8DHOVy"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZRaEhRRKWg8F",
        "outputId": "2ffe7953-2328-401c-d340-cf62115a12ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training with dataset of 207 samples and validating with randomly splitted 11 samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230501_083023-1gkfhyxn</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ols/fine/runs/1gkfhyxn' target=\"_blank\">whole-terrain-14</a></strong> to <a href='https://wandb.ai/ols/fine' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ols/fine' target=\"_blank\">https://wandb.ai/ols/fine</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ols/fine/runs/1gkfhyxn' target=\"_blank\">https://wandb.ai/ols/fine/runs/1gkfhyxn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: loss: 101.54593658447266\n",
            "0: valid loss 322.3030700683594\n",
            "0: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_fine\n",
            "1: loss: 308.6904296875\n",
            "2: loss: 107.06201934814453\n",
            "3: loss: 117.20203399658203\n",
            "4: loss: 98.0593490600586\n",
            "5: loss: 86.17723846435547\n",
            "6: loss: 73.23721313476562\n",
            "7: loss: 60.25212860107422\n",
            "8: loss: 65.65185546875\n",
            "9: loss: 39.11012268066406\n",
            "10: loss: 56.667179107666016\n",
            "11: loss: 35.663360595703125\n",
            "12: loss: 78.9594955444336\n",
            "13: loss: 73.133544921875\n",
            "14: loss: 56.949462890625\n",
            "15: loss: 68.40687561035156\n",
            "16: loss: 65.73347473144531\n",
            "17: loss: 64.81417083740234\n",
            "18: loss: 50.48391342163086\n",
            "19: loss: 61.67243957519531\n",
            "20: loss: 60.393409729003906\n",
            "20: valid loss 46.88066864013672\n",
            "21: loss: 58.63340377807617\n",
            "22: loss: 56.05731964111328\n",
            "23: loss: 55.43968963623047\n",
            "24: loss: 44.234622955322266\n",
            "25: loss: 54.661869049072266\n",
            "26: loss: 53.57736587524414\n",
            "27: loss: 51.458099365234375\n",
            "28: loss: 41.613739013671875\n",
            "29: loss: 39.04848098754883\n",
            "30: loss: 56.880130767822266\n",
            "31: loss: 50.06425476074219\n",
            "32: loss: 48.549739837646484\n",
            "33: loss: 40.27046203613281\n",
            "34: loss: 39.27682876586914\n",
            "35: loss: 48.03751754760742\n",
            "36: loss: 46.42497253417969\n",
            "37: loss: 46.30478286743164\n",
            "38: loss: 34.83402633666992\n",
            "39: loss: 34.300479888916016\n",
            "40: loss: 44.926856994628906\n",
            "40: valid loss 27.98839569091797\n",
            "41: loss: 7.091862678527832\n",
            "42: loss: 34.75084686279297\n",
            "43: loss: 33.68757247924805\n",
            "44: loss: 43.99396896362305\n",
            "45: loss: 41.96709442138672\n",
            "46: loss: 40.95492172241211\n",
            "47: loss: 34.27244567871094\n",
            "48: loss: 40.20986557006836\n",
            "49: loss: 36.647979736328125\n",
            "50: loss: 38.32140350341797\n",
            "50: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_fine\n",
            "51: loss: 38.10813522338867\n",
            "52: loss: 30.82183074951172\n",
            "53: loss: 29.589771270751953\n",
            "54: loss: 25.747716903686523\n",
            "55: loss: 60.991546630859375\n",
            "56: loss: 107.84825897216797\n",
            "57: loss: 60.84410858154297\n",
            "58: loss: 50.3091926574707\n",
            "59: loss: 43.72136306762695\n",
            "60: loss: 40.57718276977539\n",
            "60: valid loss 27.952335357666016\n",
            "61: loss: 38.04367446899414\n",
            "62: loss: 34.67672348022461\n",
            "63: loss: 36.83267593383789\n",
            "64: loss: 36.964115142822266\n",
            "65: loss: 35.14218521118164\n",
            "66: loss: 34.19615936279297\n",
            "67: loss: 32.84956359863281\n",
            "68: loss: 33.64310836791992\n",
            "69: loss: 33.64011001586914\n",
            "70: loss: 28.103317260742188\n",
            "71: loss: 27.03510093688965\n",
            "72: loss: 36.34697723388672\n",
            "73: loss: 26.54912567138672\n",
            "74: loss: 25.102813720703125\n",
            "75: loss: 32.670021057128906\n",
            "76: loss: 30.927976608276367\n",
            "77: loss: 35.97976303100586\n",
            "78: loss: 31.487688064575195\n",
            "79: loss: 48.286720275878906\n",
            "80: loss: 29.75590705871582\n",
            "80: valid loss 18.163923263549805\n",
            "81: loss: 29.10959243774414\n",
            "82: loss: 25.634033203125\n",
            "Epoch 00083: reducing learning rate of group 0 to 7.0000e-04.\n",
            "83: loss: 29.79680824279785\n",
            "84: loss: 30.923871994018555\n",
            "85: loss: 29.530113220214844\n",
            "86: loss: 29.354372024536133\n",
            "87: loss: 27.784128189086914\n",
            "88: loss: 26.663299560546875\n",
            "89: loss: 33.78031921386719\n",
            "90: loss: 25.12476921081543\n",
            "91: loss: 25.26650619506836\n",
            "92: loss: 31.315317153930664\n",
            "93: loss: 21.62797737121582\n",
            "94: loss: 28.764007568359375\n",
            "95: loss: 27.340526580810547\n",
            "96: loss: 20.663633346557617\n",
            "97: loss: 24.493616104125977\n",
            "98: loss: 16.158313751220703\n",
            "99: loss: 33.04817199707031\n",
            "100: loss: 33.83627700805664\n",
            "100: valid loss 20.291929244995117\n",
            "100: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_fine\n",
            "101: loss: 30.748950958251953\n",
            "102: loss: 22.339340209960938\n",
            "103: loss: 28.463298797607422\n",
            "104: loss: 23.336654663085938\n",
            "105: loss: 26.889570236206055\n",
            "106: loss: 22.145456314086914\n",
            "107: loss: 20.956422805786133\n",
            "108: loss: 28.54277801513672\n",
            "109: loss: 26.90386390686035\n",
            "110: loss: 25.530187606811523\n",
            "111: loss: 25.652904510498047\n",
            "112: loss: 25.274200439453125\n",
            "113: loss: 22.414445877075195\n",
            "114: loss: 21.13325309753418\n",
            "115: loss: 27.0208683013916\n",
            "116: loss: 20.317359924316406\n",
            "117: loss: 26.65433692932129\n",
            "118: loss: 25.022705078125\n",
            "119: loss: 21.16033172607422\n",
            "120: loss: 23.655366897583008\n",
            "120: valid loss 14.237567901611328\n",
            "121: loss: 23.021902084350586\n",
            "122: loss: 16.631118774414062\n",
            "123: loss: 23.750778198242188\n",
            "124: loss: 23.150365829467773\n",
            "125: loss: 22.338420867919922\n",
            "126: loss: 20.25139617919922\n",
            "127: loss: 22.63002586364746\n",
            "128: loss: 21.799518585205078\n",
            "Epoch 00129: reducing learning rate of group 0 to 4.9000e-04.\n",
            "129: loss: 20.920202255249023\n",
            "130: loss: 21.37647247314453\n",
            "131: loss: 20.840909957885742\n",
            "132: loss: 20.32550048828125\n",
            "133: loss: 20.45925521850586\n",
            "134: loss: 20.581867218017578\n",
            "135: loss: 21.862674713134766\n",
            "136: loss: 17.914289474487305\n",
            "137: loss: 21.511898040771484\n",
            "138: loss: 11.115537643432617\n",
            "139: loss: 18.137001037597656\n",
            "140: loss: 17.43406867980957\n",
            "140: valid loss 19.17742156982422\n",
            "141: loss: 22.793725967407227\n",
            "142: loss: 22.193965911865234\n",
            "143: loss: 21.03949737548828\n",
            "144: loss: 18.54038429260254\n",
            "145: loss: 20.37346649169922\n",
            "146: loss: 21.110132217407227\n",
            "147: loss: 20.31513786315918\n",
            "148: loss: 19.649879455566406\n",
            "149: loss: 19.400306701660156\n",
            "150: loss: 20.662742614746094\n",
            "150: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_fine\n",
            "151: loss: 19.557018280029297\n",
            "152: loss: 18.303110122680664\n",
            "153: loss: 20.36765480041504\n",
            "154: loss: 19.91145896911621\n",
            "155: loss: 16.033292770385742\n",
            "156: loss: 15.951553344726562\n",
            "157: loss: 15.407651901245117\n",
            "158: loss: 21.567501068115234\n",
            "159: loss: 22.64746856689453\n",
            "160: loss: 15.505062103271484\n",
            "160: valid loss 14.33497142791748\n",
            "161: loss: 20.542104721069336\n",
            "162: loss: 16.351552963256836\n",
            "163: loss: 19.90839195251465\n",
            "164: loss: 19.2335262298584\n",
            "165: loss: 18.375591278076172\n",
            "166: loss: 16.602672576904297\n",
            "167: loss: 19.629558563232422\n",
            "168: loss: 19.08083724975586\n",
            "169: loss: 19.71873664855957\n",
            "170: loss: 16.819171905517578\n",
            "171: loss: 19.342674255371094\n",
            "172: loss: 15.372527122497559\n",
            "173: loss: 18.990943908691406\n",
            "174: loss: 18.988508224487305\n",
            "Epoch 00175: reducing learning rate of group 0 to 3.4300e-04.\n",
            "175: loss: 15.587932586669922\n",
            "176: loss: 18.941879272460938\n",
            "177: loss: 18.349864959716797\n",
            "178: loss: 18.420452117919922\n",
            "179: loss: 18.27713966369629\n",
            "180: loss: 17.20871925354004\n",
            "180: valid loss 7.482067108154297\n",
            "181: loss: 17.57640838623047\n",
            "182: loss: 18.137483596801758\n",
            "183: loss: 18.363422393798828\n",
            "184: loss: 18.378599166870117\n",
            "185: loss: 18.19538116455078\n",
            "186: loss: 18.398176193237305\n",
            "187: loss: 17.776790618896484\n",
            "188: loss: 16.357933044433594\n",
            "189: loss: 17.982925415039062\n",
            "190: loss: 14.96727466583252\n",
            "191: loss: 14.298111915588379\n",
            "192: loss: 20.357789993286133\n",
            "193: loss: 22.005464553833008\n",
            "194: loss: 9.40433406829834\n",
            "195: loss: 14.287806510925293\n",
            "196: loss: 14.433679580688477\n",
            "197: loss: 16.363391876220703\n",
            "198: loss: 19.852109909057617\n",
            "199: loss: 14.700423240661621\n",
            "200: loss: 17.981491088867188\n",
            "200: valid loss 9.353034019470215\n",
            "200: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_fine\n",
            "201: loss: 18.33018684387207\n",
            "202: loss: 17.675325393676758\n",
            "203: loss: 17.641399383544922\n",
            "204: loss: 17.19489097595215\n",
            "205: loss: 15.972131729125977\n",
            "206: loss: 15.216907501220703\n",
            "207: loss: 15.508025169372559\n",
            "208: loss: 18.887453079223633\n",
            "209: loss: 18.721248626708984\n",
            "210: loss: 13.988896369934082\n",
            "211: loss: 15.700525283813477\n",
            "212: loss: 23.198177337646484\n",
            "213: loss: 19.362974166870117\n",
            "214: loss: 20.853858947753906\n",
            "215: loss: 15.213871955871582\n",
            "216: loss: 15.155878067016602\n",
            "217: loss: 14.520464897155762\n",
            "218: loss: 14.819108009338379\n",
            "219: loss: 19.297134399414062\n",
            "220: loss: 19.103965759277344\n",
            "220: valid loss 11.03951644897461\n",
            "Epoch 00221: reducing learning rate of group 0 to 2.4010e-04.\n",
            "221: loss: 17.5862979888916\n",
            "222: loss: 17.920047760009766\n",
            "223: loss: 17.506929397583008\n",
            "224: loss: 14.333512306213379\n",
            "225: loss: 17.441783905029297\n",
            "226: loss: 17.546424865722656\n",
            "227: loss: 17.96479034423828\n",
            "228: loss: 16.804119110107422\n",
            "229: loss: 13.621474266052246\n",
            "230: loss: 16.67193603515625\n",
            "231: loss: 13.599534034729004\n",
            "232: loss: 13.100022315979004\n",
            "233: loss: 17.610368728637695\n",
            "234: loss: 17.17656135559082\n",
            "235: loss: 16.965972900390625\n",
            "236: loss: 12.325187683105469\n",
            "237: loss: 12.176156997680664\n",
            "238: loss: 16.764623641967773\n",
            "239: loss: 8.538427352905273\n",
            "240: loss: 16.598854064941406\n",
            "240: valid loss 8.277867317199707\n",
            "241: loss: 16.813159942626953\n",
            "242: loss: 16.13669776916504\n",
            "243: loss: 20.29470443725586\n",
            "244: loss: 16.358444213867188\n",
            "245: loss: 16.13723373413086\n",
            "246: loss: 16.12298583984375\n",
            "247: loss: 16.10546875\n",
            "248: loss: 11.615431785583496\n",
            "249: loss: 16.106342315673828\n",
            "250: loss: 12.669283866882324\n",
            "250: saving model to /content/gdrive/MyDrive/IDL_Project/models/results_fine\n",
            "251: loss: 16.11626625061035\n",
            "252: loss: 12.20798397064209\n",
            "253: loss: 15.71507453918457\n",
            "254: loss: 11.664981842041016\n",
            "255: loss: 11.45191764831543\n",
            "256: loss: 11.050459861755371\n",
            "257: loss: 10.94775390625\n",
            "258: loss: 15.308424949645996\n",
            "259: loss: 11.030890464782715\n",
            "260: loss: 15.61223316192627\n",
            "260: valid loss 6.513073921203613\n",
            "261: loss: 15.035343170166016\n",
            "262: loss: 14.936589241027832\n",
            "263: loss: 15.235963821411133\n",
            "264: loss: 15.17475700378418\n",
            "265: loss: 14.871689796447754\n",
            "266: loss: 7.528777122497559\n",
            "Epoch 00267: reducing learning rate of group 0 to 1.6807e-04.\n",
            "267: loss: 10.185773849487305\n",
            "268: loss: 6.416925430297852\n",
            "269: loss: 14.26892375946045\n",
            "270: loss: 12.58237075805664\n",
            "271: loss: 14.631062507629395\n",
            "272: loss: 14.514212608337402\n",
            "273: loss: 14.197354316711426\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 38>\u001b[0m:\u001b[94m39\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92mcustom_train\u001b[0m:\u001b[94m15\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/audiolm_pytorch/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1212\u001b[0m in \u001b[92mtrain_step\u001b[0m            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1209 \u001b[0m\u001b[2m│   │   │   \u001b[0mdata_kwargs = \u001b[96mself\u001b[0m.data_tuple_to_kwargs(\u001b[96mnext\u001b[0m(\u001b[96mself\u001b[0m.dl_iter))                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1210 \u001b[0m\u001b[2m│   │   │   \u001b[0mloss = \u001b[96mself\u001b[0m.train_wrapper(**data_kwargs, return_loss = \u001b[94mTrue\u001b[0m)                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1211 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1212 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.accelerator.backward(loss / \u001b[96mself\u001b[0m.grad_accum_every)                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1213 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1214 \u001b[0m\u001b[2m│   │   │   \u001b[0maccum_log(logs, {\u001b[33m'\u001b[0m\u001b[33mloss\u001b[0m\u001b[33m'\u001b[0m: loss.item() / \u001b[96mself\u001b[0m.grad_accum_every})                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1215 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/accelerate/\u001b[0m\u001b[1;33maccelerator.py\u001b[0m:\u001b[94m1683\u001b[0m in \u001b[92mbackward\u001b[0m               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1680 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mself\u001b[0m.scaler \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1681 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.scaler.scale(loss).backward(**kwargs)                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1682 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1683 \u001b[2m│   │   │   \u001b[0mloss.backward(**kwargs)                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1684 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1685 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92munscale_gradients\u001b[0m(\u001b[96mself\u001b[0m, optimizer=\u001b[94mNone\u001b[0m):                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1686 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/\u001b[0m\u001b[1;33m_tensor.py\u001b[0m:\u001b[94m487\u001b[0m in \u001b[92mbackward\u001b[0m                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 484 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcreate_graph=create_graph,                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 485 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minputs=inputs,                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 486 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 487 \u001b[2m│   │   \u001b[0mtorch.autograd.backward(                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 488 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, gradient, retain_graph, create_graph, inputs=inputs                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 489 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 490 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/autograd/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m200\u001b[0m in \u001b[92mbackward\u001b[0m               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# The reason we repeat same the comment below is that\u001b[0m                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# some Python versions print out the first line of a multi-line function\u001b[0m               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# calls in the traceback and some print out the last line\u001b[0m                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m200 \u001b[2m│   \u001b[0mVariable._execution_engine.run_backward(  \u001b[2m# Calls into the C++ engine to run the bac\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m201 \u001b[0m\u001b[2m│   │   \u001b[0mtensors, grad_tensors_, retain_graph, create_graph, inputs,                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   │   \u001b[0mallow_unreachable=\u001b[94mTrue\u001b[0m, accumulate_grad=\u001b[94mTrue\u001b[0m)  \u001b[2m# Calls into the C++ engine to ru\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 38&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">39</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">custom_train</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">15</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/audiolm_pytorch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1212</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_step</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1209 │   │   │   </span>data_kwargs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.data_tuple_to_kwargs(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">next</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dl_iter))                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1210 │   │   │   </span>loss = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.train_wrapper(**data_kwargs, return_loss = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1211 │   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1212 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.backward(loss / <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.grad_accum_every)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1213 │   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1214 │   │   │   </span>accum_log(logs, {<span style=\"color: #808000; text-decoration-color: #808000\">'loss'</span>: loss.item() / <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.grad_accum_every})                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1215 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">accelerator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1683</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1680 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1681 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler.scale(loss).backward(**kwargs)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1682 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1683 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>loss.backward(**kwargs)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1684 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1685 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">unscale_gradients</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, optimizer=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>):                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1686 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">487</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 484 │   │   │   │   </span>create_graph=create_graph,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 485 │   │   │   │   </span>inputs=inputs,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 486 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 487 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch.autograd.backward(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 488 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, gradient, retain_graph, create_graph, inputs=inputs                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 489 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 490 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">200</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197 │   # The reason we repeat same the comment below is that</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 │   # some Python versions print out the first line of a multi-line function</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 │   # calls in the traceback and some print out the last line</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>200 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>Variable._execution_engine.run_backward(  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to run the bac</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">201 │   │   </span>tensors, grad_tensors_, retain_graph, create_graph, inputs,                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">202 │   │   </span>allow_unreachable=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, accumulate_grad=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to ru</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">203 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "fine_transformer = FineTransformer(\n",
        "    num_coarse_quantizers = 3,\n",
        "    num_fine_quantizers = 5,\n",
        "    codebook_size = 1024,\n",
        "    dim = 1024,\n",
        "    depth = 6,\n",
        "    audio_text_condition = True,\n",
        "    attn_dropout = config[\"attn_dropout\"],\n",
        "    ff_dropout = config[\"ff_dropout\"],\n",
        ")\n",
        "\n",
        "fine_trainer = FineTransformerTrainer(\n",
        "    transformer = fine_transformer,\n",
        "    codec = soundstream,\n",
        "    audio_conditioner = quantizer,\n",
        "    folder = dataset_folder,\n",
        "    lr=config[\"lr\"],\n",
        "    batch_size = config[\"batch_size\"],\n",
        "    data_max_length_seconds = config.get(\"data_max_length_seconds\"),\n",
        "    data_max_length = config.get(\"data_max_length\"),\n",
        "    save_results_every = VAL_EVERY_STEPS,\n",
        "    wd = config[\"wd\"],\n",
        "    grad_accum_every = config[\"grad_accum_every\"],\n",
        "    max_grad_norm = config[\"max_grad_norm\"],\n",
        "    save_model_every = 50,\n",
        "    num_train_steps = STEPS,\n",
        "    results_folder = RESULTS_ROOT_PATH+'/results_fine',\n",
        "    force_clear_prev_results = False,\n",
        "    accelerate_kwargs = get_accelerate_kwargs(config)\n",
        ")\n",
        "\n",
        "scheduler = get_scheduler(fine_trainer.optim, config)\n",
        "\n",
        "if load_ckpt:\n",
        "  fine_trainer.load(fine_load_path)\n",
        "\n",
        "if train:\n",
        "  custom_train(fine_trainer,\n",
        "               config,\n",
        "               scheduler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoHgkgA3XKXH"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiY1uTyic2vv"
      },
      "outputs": [],
      "source": [
        "#!nvidia-smi --gpu-reset\n",
        "#!sudo rmmod nvidia_uvm ; sudo modprobe nvidia_uvm\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzghrux5WinW",
        "outputId": "4d4bddf7-8562-44b4-e361-126a64d8e3b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "generating semantic: 100%|██████████| 2048/2048 [05:16<00:00,  6.46it/s]\n",
            "generating coarse: 100%|██████████| 512/512 [14:33<00:00,  1.71s/it]\n",
            "generating fine: 100%|██████████| 512/512 [26:12<00:00,  3.07s/it]\n"
          ]
        }
      ],
      "source": [
        "# Everything together\n",
        "audiolm = AudioLM(\n",
        "    wav2vec = wav2vec,\n",
        "    codec = soundstream,\n",
        "    semantic_transformer = semantic_transformer,\n",
        "    coarse_transformer = coarse_transformer,\n",
        "    fine_transformer = fine_transformer\n",
        ")\n",
        "\n",
        "text_embeddings = quantizer(texts=[\"Experimental high quality metal song with flute\", \"\"])[0:1]\n",
        "seconds_to_generate = 10\n",
        "generated_wav = audiolm(text_embeds=text_embeddings, batch_size = 1, max_length=seconds_to_generate * wav2vec.target_sample_hz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rQPHTSRngEr"
      },
      "outputs": [],
      "source": [
        "output_path = RESULTS_ROOT_PATH + \"/generated/out1.wav\"\n",
        "sample_rate = 44100\n",
        "torchaudio.save(output_path, generated_wav.cpu(), sample_rate)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "QBaqCz5jb_l_",
        "eEFSss2wqCtL",
        "oiEBo6goqFRE",
        "PhK_3FSVqF2t",
        "jBxNK5cKW--_",
        "T7GiyBcBWiZV",
        "aKAFNMrqpMBC",
        "uhKGvSDSC-Mr",
        "lqjN28L4Wc5Q"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f1960d391f8a4ab3bd375daf781e7cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d887cd8b7b3f4e4f91afe9fdec5b74d2",
              "IPY_MODEL_217ae3c37be743128194700a2eed146f"
            ],
            "layout": "IPY_MODEL_bd0624db5611477683b193fa9fa4da7b"
          }
        },
        "d887cd8b7b3f4e4f91afe9fdec5b74d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b51ae5afdce3498db172fbf31b787377",
            "placeholder": "​",
            "style": "IPY_MODEL_62b7f7b6421045a3ba7cbed71b496107",
            "value": "0.014 MB of 0.014 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "217ae3c37be743128194700a2eed146f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54ac48515c63477592ca6af47bed4cae",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78a3cb842060468683370d9da6fdcad8",
            "value": 1
          }
        },
        "bd0624db5611477683b193fa9fa4da7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b51ae5afdce3498db172fbf31b787377": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62b7f7b6421045a3ba7cbed71b496107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54ac48515c63477592ca6af47bed4cae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78a3cb842060468683370d9da6fdcad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03c5c35192a14cef8af9371388f83602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b19a5a45243249938cba2d23d09ee494",
              "IPY_MODEL_a3378fc8820642598d34dfe081e04cb9"
            ],
            "layout": "IPY_MODEL_0a55105b36594142b78f6fde2db55e38"
          }
        },
        "b19a5a45243249938cba2d23d09ee494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58b69b72e9dd407389bc7b3ad43ac356",
            "placeholder": "​",
            "style": "IPY_MODEL_c84d870a56544315a9b9cefac5ba829a",
            "value": "0.033 MB of 0.035 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "a3378fc8820642598d34dfe081e04cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22f48152a5cf4656a2b03ae69bc958ca",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d74fa8b95484c7886575a93a366b9b6",
            "value": 0.9642255776078615
          }
        },
        "0a55105b36594142b78f6fde2db55e38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58b69b72e9dd407389bc7b3ad43ac356": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c84d870a56544315a9b9cefac5ba829a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22f48152a5cf4656a2b03ae69bc958ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d74fa8b95484c7886575a93a366b9b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}